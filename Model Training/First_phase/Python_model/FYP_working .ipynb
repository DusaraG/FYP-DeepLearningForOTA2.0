{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d1t9MwKcF0L"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xCUL62ObyvP"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam,SGD\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tensorflow.keras.metrics import MeanSquaredError\n",
        "from tensorflow.keras.callbacks import Callback, TensorBoard, EarlyStopping\n",
        "from IPython.display import clear_output\n",
        "import datetime\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import convolve\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "from tensorflow.keras.layers import Input,Conv1D, Dense, Flatten, Embedding, Reshape, Softmax,LayerNormalization, MultiHeadAttention, Add, Dropout,Normalization\n",
        "from tensorflow.keras import Sequential\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import Callback, TensorBoard\n",
        "from IPython.display import clear_output\n",
        "from tensorflow.keras.layers import Dense, LSTM, GRU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctyb2PyyUKUB"
      },
      "source": [
        "# Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTlEUj8iUBAJ"
      },
      "outputs": [],
      "source": [
        "Number_channel_uses = 1 # it defines the number of symbols per messages. at a time one symbol can be transmitted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjYVqighRYIx"
      },
      "outputs": [],
      "source": [
        "Eb_No = 10  # This should be a variable so that it can be used in the dictionary\n",
        "from scipy.stats import truncnorm\n",
        "from scipy.stats import uniform\n",
        "channel_parameters = {\n",
        "    \"r\"        : 4,                # For upsampling -> number of complex samples per symbol\n",
        "    \"Eb_No\"    : Eb_No,            # Energy per bit to noise power spectral density ratio\n",
        "    \"roll_off\" : 0.35,             # Roll off factor\n",
        "    \"num_taps\" : 31,               # L -> Number of taps (odd) for RRC filter\n",
        "    \"f_s\"      : 25e4,             # Sampling frequency\n",
        "    \"T_bound\"  : 1/25e4,           # 1/f_s (symbol duration in seconds)\n",
        "    \"time_delay\" : np.random.uniform(-1,1),  # Random time delay in the range [-1, 1]\n",
        "    \"CFO\"      : 5e3,              # Carrier Frequency Offset in Hz\n",
        "    \"CFO_std\"  : 5e3/25e4,         # Normalized Carrier Frequency Offset\n",
        "    \"noise_std\": 10**(-1.0 * Eb_No / 10),  # Noise standard deviation, calculated from Eb_No\n",
        "    \"phase_off\": uniform.rvs(scale=2*np.pi)  # Random phase offset in the range [0, 2π]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cfFtgnPRtdZ"
      },
      "source": [
        "# Real to complex conversion and pulse shaping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-P18yQa9jLc0"
      },
      "outputs": [],
      "source": [
        "# upsampling\n",
        "\n",
        "# Function to perform upsampling by a factor of r\n",
        "def upsampling(inp, r):\n",
        "    com_reshape = tf.reshape(inp, [-1, 1])\n",
        "    padding = tf.constant([[0, 0], [0, r - 1]])\n",
        "    upsampled = tf.pad(com_reshape, padding, mode=\"CONSTANT\")\n",
        "    upsampled = tf.reshape(upsampled, [-1])  # Flatten back to 1D\n",
        "    return upsampled\n",
        "\n",
        "# Function to perform upsampling on IQ signals\n",
        "def upsample_iq(inp, r):\n",
        "    real = inp[:, 0]  # Real part\n",
        "    imag = inp[:, 1]  # Imaginary part\n",
        "\n",
        "    # Upsample both real and imaginary parts\n",
        "    real_up = upsampling(real, r)\n",
        "    imag_up = upsampling(imag, r)\n",
        "\n",
        "    # Combine the upsampled real and imaginary parts\n",
        "    upsampled = tf.stack([real_up, imag_up], axis=1)\n",
        "    return upsampled\n",
        "\n",
        "# Function to do pulse shaping with NRRC code\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from scipy.signal import lfilter\n",
        "\n",
        "# Function to create a normalized RRC filter\n",
        "def rrc_filter(alpha, sps, num_taps, ts = 1):\n",
        "    \"\"\"\n",
        "    Create a root-raised cosine (RRC) filter.\n",
        "\n",
        "    Args:\n",
        "        ts: Sampling period (default is 1).\n",
        "        alpha: Roll-off factor (0 <= alpha <= 1).\n",
        "        sps: Samples per symbol (upsampling factor).\n",
        "        num_taps: Number of filter taps (should be odd).\n",
        "\n",
        "    Returns:\n",
        "        RRC filter coefficients.\n",
        "    \"\"\"\n",
        "    t = np.linspace(-num_taps//2, num_taps//2 + 1,num_taps) - 2\n",
        "    rrc = np.zeros_like(t)\n",
        "\n",
        "    for i in range(len(t)):\n",
        "        if t[i] == 0.0:\n",
        "            rrc[i] = (1.0 - alpha + 4 * alpha / np.pi)/ts\n",
        "        elif np.abs(t[i]) == ts / (4 * alpha):\n",
        "            rrc[i] = (alpha /( np.sqrt(2)*ts)) * \\\n",
        "                     ((1 + 2/np.pi) * np.sin(np.pi / (4 * alpha)) +\n",
        "                      (1 - 2/np.pi) * np.cos(np.pi / (4 * alpha)))\n",
        "        else:\n",
        "            rrc[i] = (np.sin(np.pi * (t[i]/ts) * (1 - alpha)) +\n",
        "                      4 * alpha * (t[i]/ts) * np.cos(np.pi * (t[i]/ts) * (1 + alpha))) / \\\n",
        "                     (np.pi * t[i] * (1 - (4 * alpha * (t[i]/ts))**2))\n",
        "\n",
        "    # Normalize filter coefficients to ensure unit energy\n",
        "    rrc = rrc / np.sqrt(np.sum(rrc**2))\n",
        "    rrc = tf.constant(rrc, dtype=tf.float32)\n",
        "    # plt.stem(t,rrc)  # Plot for visualization\n",
        "    # plt.title(f\"Time_delay = {10}\")\n",
        "    return rrc\n",
        "\n",
        "\n",
        "# Function to apply upsampling and filtering using conv1d\n",
        "def upsample_and_filter(signal, r, alpha, num_taps):\n",
        "    # Upsample the signal\n",
        "    upsampled_signal = upsample_iq(signal, r)\n",
        "\n",
        "    # Create the RRC filter\n",
        "    rrc = rrc_filter(alpha, r, num_taps)\n",
        "\n",
        "    # Add a batch and channel dimension for conv1d\n",
        "    upsampled_signal = tf.expand_dims(upsampled_signal, axis=0)  # Shape: (1, length, 2)\n",
        "    rrc = tf.reshape(rrc, [-1, 1, 1])  # Shape: (filter_length, 1, 1)\n",
        "\n",
        "    padding_size = num_taps//2\n",
        "    paddings = tf.constant([[0, 0], [padding_size, padding_size], [0, 0]])\n",
        "    padded_real = tf.pad(upsampled_signal[:, :, 0:1], paddings, \"CONSTANT\")\n",
        "    padded_imag = tf.pad(upsampled_signal[:, :, 1:2], paddings, \"CONSTANT\")\n",
        "    upsampled_signal = tf.concat([padded_real, padded_imag], axis=2)\n",
        "    print('upsampled shape', upsampled_signal.shape)\n",
        "    # Apply the RRC filter using conv1d\n",
        "    real_filtered = tf.nn.conv1d(upsampled_signal[:, :, 0:1], rrc, stride=1, padding='SAME')\n",
        "    imag_filtered = tf.nn.conv1d(upsampled_signal[:, :, 1:2], rrc, stride=1, padding='SAME')\n",
        "\n",
        "    # Combine filtered real and imaginary parts\n",
        "    filtered_signal = tf.concat([real_filtered, imag_filtered], axis=2)\n",
        "    filtered_signal = tf.squeeze(filtered_signal, axis=0)  # Remove the batch dimension\n",
        "\n",
        "    return filtered_signal\n",
        "\n",
        "def time_offset(sampling_time = 10 ):\n",
        "  t_offset = np.random.uniform(-sampling_time//2, sampling_time//2)\n",
        "  return t_offset\n",
        "\n",
        "# def signal_sample(received_signal,fs=1,s_rate = 10,num_taps\n",
        "\n",
        "# def signal_sample(received_signal,fs=1,s_rate = 10,num_taps):\n",
        "#     sampling_rate = s_rate*fs\n",
        "#     signal_sample = received_signal[::sampling_rate]\n",
        "\n",
        "#     x_axis = np.arange(-num_taps//2, num_taps//2 + 1) / s_rate\n",
        "#     plt.stem(x_axis[:len(signal_sample)], signal_sample)  # Plot for visualization\n",
        "#     plt.title(f\"Time_delay = {10}\")\n",
        "#     return signal_sample\n",
        "\n",
        "\n",
        "def pulse_shape_decode(received_signal, fs, alpha, num_taps):\n",
        "    # fs  = sampling frequency\n",
        "    # get the samples from received signal tapping\n",
        "\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "\n",
        "# Define parameters\n",
        "r = 4  # Upsampling factor\n",
        "alpha = 0.35  # Roll-off factor\n",
        "num_taps = 2  # Number of filter taps (should be odd)\n",
        "\n",
        "# # Example input: Complex signal with real and imaginary parts\n",
        "# input_signal = tf.constant([[1.0, -1.0]])\n",
        "\n",
        "# # Apply upsampling and RRC filtering\n",
        "# filtered_signal = upsample_and_filter(input_signal, r, alpha, num_taps)\n",
        "\n",
        "# filtered_signal_real = filtered_signal[:, 0].numpy()\n",
        "# # sampled_signal = signal_sample(filtered_signal_real,fs=1,s_rate = 10)\n",
        "\n",
        "\n",
        "# # Generate x-axis data with matching length\n",
        "# x_axis = np.arange(-num_taps//2, num_taps//2 + 1) / r\n",
        "\n",
        "# plt.stem(x_axis[:len(filtered_signal_real)], filtered_signal_real)  # Plot for visualization\n",
        "# plt.title(f\"Time_delay = {10}\")\n",
        "# print(\"Filtered Signal:\")\n",
        "# print(len(filtered_signal))\n",
        "\n",
        "\n",
        "# Example input: Complex signal with real and imaginary parts\n",
        "input_signal = tf.constant([[1.0, -1.0]])  # Example input signal with 2 samples\n",
        "\n",
        "print(f\"Input signal length: {len(input_signal)}\")\n",
        "\n",
        "# Apply upsampling and RRC filtering\n",
        "filtered_signal = upsample_and_filter(input_signal, r, alpha, num_taps)\n",
        "\n",
        "# Print lengths\n",
        "upsampled_signal_length = len(upsample_iq(input_signal, r))\n",
        "expected_output_length = upsampled_signal_length + num_taps - 1\n",
        "print(f\"Upsampled signal length: {upsampled_signal_length}\")\n",
        "print(f\"Expected output length: {expected_output_length}\")\n",
        "print(f\"Actual filtered signal length: {len(filtered_signal)}\")\n",
        "\n",
        "# Visualize the filtered signal\n",
        "filtered_signal_real = filtered_signal[:, 0].numpy()\n",
        "\n",
        "# Generate x-axis data with matching length\n",
        "x_axis = np.arange(len(filtered_signal_real))\n",
        "\n",
        "plt.stem(x_axis, filtered_signal_real)  # Plot for visualization\n",
        "plt.title(f\"Filtered Signal with Time_delay = {10}\")\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puZ_hL-rjBPL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import lfilter\n",
        "\n",
        "# function to create the complex values\n",
        "def real_to_complex_tensor(inp_tensor):\n",
        "  inp_tensor = tf.reshape(inp_tensor, [-1, 2])\n",
        "  real_part = inp_tensor[:, 0]\n",
        "  imag_part = inp_tensor[:, 1]\n",
        "  complex_tensor = tf.complex(real_part, imag_part)\n",
        "  return complex_tensor\n",
        "\n",
        "def complex_to_real_tensor(inp_tensor):\n",
        "   real_part , imag_part = tf.math.real(inp_tensor), tf.math.imag(inp_tensor)\n",
        "   real_part = tf.reshape(real_part,[-1,1])\n",
        "   imag_part = tf.reshape(imag_part,[-1,1])\n",
        "   return tf.reshape(tf.concat([real_part,imag_part],1),[-1])\n",
        "\n",
        "# RRC Filter Design\n",
        "class NRRC_filter(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self,beta,span,sps,input):\n",
        "    super(NRRC_filter, self).__init__(**kwargs)\n",
        "    self.beta = beta\n",
        "    self.span = span\n",
        "    self.sps = sps\n",
        "    self.input = input\n",
        "\n",
        "  def build(self,beta, span, sps):\n",
        "        \"\"\"\n",
        "        Create a Root Raised Cosine (RRC) filter (FIR) impulse response.\n",
        "\n",
        "        Parameters:\n",
        "        beta : Roll-off factor (0 <= beta <= 1)\n",
        "        span : Filter span in symbols\n",
        "        sps : Samples per symbol\n",
        "\n",
        "        Returns:\n",
        "        h_rrc : RRC filter coefficients (impulse response)\n",
        "        \"\"\"\n",
        "        t = np.linspace(-span / 2, span / 2, span * sps + 1)\n",
        "        h_rrc = np.zeros_like(t)\n",
        "\n",
        "        for i in range(len(t)):\n",
        "            if t[i] == 0.0:\n",
        "                h_rrc[i] = 1.0 - beta + (4 * beta / np.pi)\n",
        "            elif abs(t[i]) == 1 / (4 * beta):\n",
        "                h_rrc[i] = (beta / np.sqrt(2)) * (((1 + 2 / np.pi) * np.sin(np.pi / (4 * beta))) +\n",
        "                                                  ((1 - 2 / np.pi) * np.cos(np.pi / (4 * beta))))\n",
        "            else:\n",
        "                h_rrc[i] = (np.sin(np.pi * t[i] * (1 - beta)) +\n",
        "                            4 * beta * t[i] * np.cos(np.pi * t[i] * (1 + beta))) / \\\n",
        "                          (np.pi * t[i] * (1 - (4 * beta * t[i]) ** 2))\n",
        "\n",
        "        # Normalize filter energy to 1\n",
        "        h_rrc = h_rrc / np.sqrt(np.sum(h_rrc ** 2))\n",
        "        return h_rrc\n",
        "\n",
        "  def call(self, input):\n",
        "\n",
        "      \"\"\"\n",
        "      Apply pulse shaping to a bitstream using a given filter.\n",
        "\n",
        "      Parameters:\n",
        "      bitstream : Input bitstream (BPSK symbols)\n",
        "      h_rrc : RRC filter coefficients\n",
        "      sps : Samples per symbol\n",
        "\n",
        "      Returns:\n",
        "      shaped_signal : Pulse-shaped signal\n",
        "      \"\"\"\n",
        "      # Upsample the bitstream (insert zeros between symbols)\n",
        "      upsampled = np.zeros(len(input) * sps)\n",
        "      upsampled[::sps] = input\n",
        "\n",
        "      # Convolve with the RRC filter\n",
        "      shaped_signal = lfilter(h_rrc, 1.0, input)\n",
        "      return shaped_signal\n",
        "\n",
        "  def get_config(self):\n",
        "      config = super(NRRC_filter, self).get_config()\n",
        "      config.update({'beta': self.beta, 'span': self.span, 'sps': self.sps})\n",
        "      return config\n",
        "# Pulse Shaping\n",
        "def pulse_shaping(bitstream, h_rrc, sps):\n",
        "    \"\"\"\n",
        "    Apply pulse shaping to a bitstream using a given filter.\n",
        "\n",
        "    Parameters:\n",
        "    bitstream : Input bitstream (BPSK symbols)\n",
        "    h_rrc : RRC filter coefficients\n",
        "    sps : Samples per symbol\n",
        "\n",
        "    Returns:\n",
        "    shaped_signal : Pulse-shaped signal\n",
        "    \"\"\"\n",
        "    # Upsample the bitstream (insert zeros between symbols)\n",
        "    upsampled = np.zeros(len(bitstream) * sps)\n",
        "    upsampled[::sps] = bitstream\n",
        "\n",
        "    # Convolve with the RRC filter\n",
        "    shaped_signal = lfilter(h_rrc, 1.0, bitstream)\n",
        "    return shaped_signal\n",
        "\n",
        "# Parameters\n",
        "beta = 0.35  # Roll-off factor\n",
        "span = 31    # Filter span (in symbols)\n",
        "sps = 4      # Samples per symbol\n",
        "num_bits = 100  # Number of bits\n",
        "\n",
        "# Generate a random bitstream (BPSK symbols: -1, 1)\n",
        "bitstream = 2 * np.random.randint(0, 2, num_bits) - 1\n",
        "\n",
        "# Create the RRC filter\n",
        "h_rrc = rrc_filter(beta, span, sps)\n",
        "\n",
        "# Perform pulse shaping\n",
        "shaped_signal = pulse_shaping(bitstream, h_rrc, sps)\n",
        "\n",
        "# Normalize the shaped signal\n",
        "shaped_signal /= np.max(np.abs(shaped_signal))\n",
        "\n",
        "# Plot the original bitstream and the pulse-shaped signal\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "#plt.stem(np.arange(len(bitstream)), bitstream, 'b', markerfmt='bo', basefmt=\" \", use_line_collection=True) to resolve error\n",
        "plt.stem(np.arange(len(bitstream)), bitstream, 'b', markerfmt='bo', basefmt=\" \")\n",
        "plt.title('Original Bitstream')\n",
        "plt.xlabel('Bit Index')\n",
        "plt.ylabel('Amplitude')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(shaped_signal, 'r')\n",
        "plt.title('Pulse-Shaped Signal (Normalized RRC)')\n",
        "plt.xlabel('Sample Index')\n",
        "plt.ylabel('Amplitude')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVvu_VFTR_J6"
      },
      "source": [
        "# implementation of AE with noise channel working."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "uzN0ljm-PzO_"
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense\n",
        "# import numpy as np\n",
        "# import math\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# Dataset Parameters\n",
        "N = 4  # Number of channel uses\n",
        "M = 16  # Number of total messages that can be transmitted\n",
        "K = int(math.ceil(np.log2(M)))  # Block size\n",
        "l = 6\n",
        "Eb_No = 10\n",
        "batch_size = (2*l+1)*320\n",
        "\n",
        "# Create Dataset in one-hot vector\n",
        "alphabet_size = pow(2, K)\n",
        "alphabet = np.eye(alphabet_size, dtype='float32')\n",
        "\n",
        "train_dataset = np.tile(alphabet, (batch_size, 1))\n",
        "test_dataset = np.tile(alphabet, (batch_size * 10, 1))\n",
        "\n",
        "# Custom Callback for Real-time Plotting\n",
        "class PlottingCallback(Callback):\n",
        "    def __init__(self):\n",
        "        super(PlottingCallback, self).__init__()\n",
        "        self.history = {'accuracy': [], 'val_accuracy': [], 'loss': [], 'val_loss': []}\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Update history\n",
        "        self.history['accuracy'].append(logs.get('accuracy'))\n",
        "        self.history['val_accuracy'].append(logs.get('val_accuracy'))\n",
        "        self.history['loss'].append(logs.get('loss'))\n",
        "        self.history['val_loss'].append(logs.get('val_loss'))\n",
        "\n",
        "        # Clear previous output\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        # Plot training and validation accuracy\n",
        "        plt.figure(figsize=(12, 5))\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(self.history['accuracy'], label='Training Accuracy')\n",
        "        plt.plot(self.history['val_accuracy'], label='Validation Accuracy')\n",
        "        plt.title('Accuracy over Epochs')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "\n",
        "        # Plot training and validation loss\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(self.history['loss'], label='Training Loss')\n",
        "        plt.plot(self.history['val_loss'], label='Validation Loss')\n",
        "        plt.title('Loss over Epochs')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "# Normalization Layer\n",
        "class Normalization(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(Normalization, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, input):\n",
        "        shape = tf.shape(input)\n",
        "        out = tf.nn.l2_normalize(tf.reshape(input, (-1, 2)), axis=-1, epsilon=1e-5)\n",
        "        # out = tf.nn.l2_normalize(tf.reshape(input, (-1, 2*N)), axis=-1, epsilon=1e-5)                                # to normalize the power of symbol\n",
        "        # out = tf.nn.l2_normalize(tf.reshape(input, (-1, shape[-1])), axis=-1, epsilon=1e-5)  # to normalize the power of all the signal\n",
        "        out = tf.reshape(out, (-1,2*N))\n",
        "        print(\" Normalize each input power to 1,shape \",out.shape)\n",
        "        return out\n",
        "\n",
        "    def get_config(self):\n",
        "        return super(Normalization, self).get_config()\n",
        "\n",
        "# Custom Noise Layer\n",
        "class CustomNoise(tf.keras.layers.Layer):\n",
        "    def __init__(self, mean=0.0, stddev=10**(-1.0*Eb_No), **kwargs):\n",
        "        super(CustomNoise, self).__init__(**kwargs)\n",
        "        self.mean = mean\n",
        "        self.stddev = stddev\n",
        "\n",
        "    def call(self, inputs):\n",
        "        noise = tf.random.normal(shape=tf.shape(inputs), mean=self.mean, stddev=self.stddev)\n",
        "        return inputs + noise\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "# class RealToComplexPair(tf.keras.layers.Layer):\n",
        "#     def __init__(self, **kwargs):\n",
        "#         super(RealToComplexPair, self).__init__(**kwargs)\n",
        "\n",
        "#     def call(self, inputs):\n",
        "#         # Get the inner dimension size\n",
        "#         inner_dimension = inputs.shape[-1] // 2  # Assuming the last dimension is even\n",
        "\n",
        "#         # Create indices for real and imaginary parts\n",
        "#         real_indices = tf.range(0, 2 * inner_dimension, 2)\n",
        "#         imag_indices = tf.range(1, 2 * inner_dimension, 2)\n",
        "\n",
        "#         # Extract real and imaginary parts using the indices\n",
        "#         real_part = tf.gather(inputs, real_indices, axis=-1)\n",
        "#         imag_part = tf.gather(inputs, imag_indices, axis=-1)\n",
        "\n",
        "#         # Combine the real and imaginary parts into a complex tensor\n",
        "#         complex_tensor = tf.complex(real_part, imag_part)\n",
        "#         return complex_tensor\n",
        "\n",
        "#     def compute_output_shape(self, input_shape):\n",
        "#         # Output shape will have half the last dimension (as complex numbers)\n",
        "#         return input_shape[:-1] + (input_shape[-1] // 2,)\n",
        "\n",
        "#     def get_config(self):\n",
        "#         config = super(RealToComplexPair, self).get_config()\n",
        "#         return config\n",
        "\n",
        "\n",
        "\n",
        "class AE:\n",
        "    def __init__(self, train_data=train_dataset, test_data=test_dataset, input_dim=K, enc_dim=N, act_fun='tanh'):\n",
        "        self.train_data = train_data\n",
        "        self.test_data = test_data\n",
        "        self.input_dim = input_dim\n",
        "        self.enc_dim = enc_dim\n",
        "        self.act_fun = act_fun\n",
        "\n",
        "    def AE_implement(self):\n",
        "        autoencoder = Sequential([\n",
        "            Dense(2**(self.input_dim), activation=self.act_fun, name=\"Input\"),\n",
        "            Dense(2**(self.input_dim), activation=self.act_fun, name=\"encoder\"),\n",
        "            Dense(2**(self.input_dim), activation=self.act_fun, name=\"middle1\"),\n",
        "            Dense(self.enc_dim * 2, activation=self.act_fun, name='middle2'),\n",
        "\n",
        "            # Convert to complex tensor\n",
        "            # RealToComplexPair(name = 'real2complex'),\n",
        "\n",
        "            # Normalization Layer\n",
        "            Normalization(name = 'normalization'),\n",
        "\n",
        "            # Channel Layer\n",
        "            StochasticChannelv3_cts_tr(name = 'stc'),\n",
        "            # NormalizedRRCFilterLayer( ),\n",
        "            CustomNoise(name = 'noise'),\n",
        "            SD(name = 'sd'),\n",
        "            # CustomNoise(\n",
        "\n",
        "            # Decoder layers\n",
        "            Dense(self.enc_dim * 4, activation=self.act_fun, name=\"decoder1\"),\n",
        "            Dense(2**(self.input_dim), activation=self.act_fun, name='decoder2'),\n",
        "            Dense(2**(self.input_dim), activation='softmax', name='Output')\n",
        "        ])\n",
        "\n",
        "        autoencoder.compile(optimizer=Adam(learning_rate=1e-2), loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "        return autoencoder\n",
        "\n",
        "    def train(self, epochs=20, batch_size=64):\n",
        "        autoencoder = self.AE_implement()\n",
        "        # autoencoder.fit(self.train_data, self.train_data,\n",
        "        #                 epochs=epochs, batch_size=batch_size,\n",
        "        #                 validation_data=(self.test_data, self.test_data))\n",
        "        # # return autoencoder\n",
        "\n",
        "        # TensorBoard setup\n",
        "        log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "        tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "        print(self.test_data.shape)\n",
        "\n",
        "        history = autoencoder.fit(self.train_data, self.train_data,\n",
        "                                  epochs=epochs, batch_size=(2*l+1)*16,\n",
        "                                  validation_data=(self.test_data, self.test_data),\n",
        "                                  callbacks=[PlottingCallback(), tensorboard_callback])\n",
        "        return autoencoder, history\n",
        "\n",
        "# Instantiate the AE class and train the model\n",
        "ae = AE(train_data=train_dataset[:], test_data=test_dataset[:16*13], input_dim=K, enc_dim=N, act_fun='relu')\n",
        "autoencoder_model = ae.train(epochs=10, batch_size=(2*l+1))\n",
        "# print(\"This is the sample input dimension \",len(train_dataset[0]))\n",
        "# Evaluate the model on the test data\n",
        "# print(train_dataset.shape)\n",
        "# print(test_dataset)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "C58NhxRBM7fj"
      },
      "outputs": [],
      "source": [
        "%reload_ext tensorboard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs/fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3OZYo4gKKwe"
      },
      "outputs": [],
      "source": [
        "enc = tf.constant([[1,1,1,1,0,0,1,0,1,0,1,1,0,1,0,1],\n",
        "                    [0,1,0,1,0,0,0,1,0,1,1,1,0,1,1,0]],\n",
        "                   dtype=tf.float32) # enc has been redefined with the correct shape\n",
        "print(enc.shape)\n",
        "# Instantiate the layer\n",
        "output = autoencoder_model[0](test_dataset[:12*13])\n",
        "\n",
        "# Apply the layer to the input\n",
        "# output = channel_layer(enc)\n",
        "\n",
        "# Print the shapes and output\n",
        "print(output.shape)\n",
        "\n",
        "print(output)\n",
        "# accuracy = autoencoder_model[0].evaluate(enc,enc, batch_size = 2)\n",
        "# print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRsgdzptvm4o"
      },
      "source": [
        "## plot the outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGpZ0TnUsPa2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have your input and output from the autoencoder\n",
        "# Example:\n",
        "# input_data = your_input_data   # Shape (156, 16)\n",
        "# output_data = autoencoder.predict(your_input_data)  # Shape (156, 16)\n",
        "\n",
        "def plot_autoencoder_performance(input_data, output_data, num_samples=5):\n",
        "    # Ensure the number of samples to plot does not exceed the number of available samples\n",
        "    num_samples = min(num_samples, input_data.shape[0])\n",
        "\n",
        "    # Create subplots\n",
        "    fig, axs = plt.subplots(num_samples, 2, figsize=(10, num_samples * 3))\n",
        "    fig.suptitle('Autoencoder Input vs Output', fontsize=16)\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        # Plot input data (original data)\n",
        "        axs[i, 0].plot(input_data[i], color='blue')\n",
        "        axs[i, 0].set_title(f\"Input {i+1}\")\n",
        "\n",
        "        # Plot output data (reconstructed data)\n",
        "        axs[i, 1].plot(output_data[i], color='red')\n",
        "        axs[i, 1].set_title(f\"Output {i+1}\")\n",
        "\n",
        "        # Adding labels\n",
        "        axs[i, 0].set_ylabel('Amplitude')\n",
        "        axs[i, 1].set_ylabel('Amplitude')\n",
        "\n",
        "    # Adding x-axis labels\n",
        "    axs[-1, 0].set_xlabel('Feature Index')\n",
        "    axs[-1, 1].set_xlabel('Feature Index')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.93)  # Adjust for title\n",
        "    plt.show()\n",
        "\n",
        "# Call the plotting function with input and output data\n",
        "plot_autoencoder_performance(test_dataset[:12*13], output, num_samples=5)  # Adjust num_samples as needed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrS89pPetyio"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have your input and output from the autoencoder\n",
        "# Example:\n",
        "# input_data = your_input_data   # Shape (156, 16)\n",
        "# output_data = autoencoder.predict(your_input_data)  # Shape (156, 16)\n",
        "\n",
        "def plot_constellation(input_data, output_data, num_samples=5):\n",
        "    # Ensure the number of samples to plot does not exceed the number of available samples\n",
        "    num_samples = min(num_samples, input_data.shape[0])\n",
        "\n",
        "    # Create subplots for constellation\n",
        "    fig, axs = plt.subplots(num_samples, 2, figsize=(10, num_samples * 5))\n",
        "    fig.suptitle('Autoencoder Input vs Output Constellation', fontsize=16)\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        # Extract real and imaginary parts for input and output\n",
        "        input_real = input_data[i, ::2]   # Real parts from even indices\n",
        "        input_imag = input_data[i, 1::2]  # Imaginary parts from odd indices\n",
        "        output_real = output_data[i, ::2]  # Real parts from even indices\n",
        "        output_imag = output_data[i, 1::2]  # Imaginary parts from odd indices\n",
        "\n",
        "        # Plot input constellation\n",
        "        axs[i, 0].scatter(input_real, input_imag, color='blue', s=50, label='Input')\n",
        "        axs[i, 0].set_title(f\"Input Constellation {i+1}\")\n",
        "        axs[i, 0].set_xlabel('Real')\n",
        "        axs[i, 0].set_ylabel('Imaginary')\n",
        "        axs[i, 0].grid(True)\n",
        "\n",
        "        # Plot output constellation\n",
        "        axs[i, 1].scatter(output_real, output_imag, color='red', s=50, label='Output')\n",
        "        axs[i, 1].set_title(f\"Output Constellation {i+1}\")\n",
        "        axs[i, 1].set_xlabel('Real')\n",
        "        axs[i, 1].set_ylabel('Imaginary')\n",
        "        axs[i, 1].grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.93)  # Adjust for title\n",
        "    plt.show()\n",
        "\n",
        "# Call the plotting function with input and output data\n",
        "plot_constellation(test_dataset[:12*13], output, num_samples=5)  # Adjust num_samples as needed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Bi-wtO_zO7bW"
      },
      "outputs": [],
      "source": [
        "autoencoder_model[0].summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iX7xG947h8xQ"
      },
      "source": [
        "# Stochastic Channel layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmI_Dqtzh8xR"
      },
      "outputs": [],
      "source": [
        "# Custom Noise Layer\n",
        "class CustomNoise(tf.keras.layers.Layer):\n",
        "    def __init__(self, mean=0.0, stddev=10**(-1.0*Eb_No), **kwargs):\n",
        "        super(CustomNoise, self).__init__(**kwargs)\n",
        "        self.mean = mean\n",
        "        self.stddev = stddev\n",
        "\n",
        "    def call(self, inputs):\n",
        "        noise = tf.random.normal(shape=tf.shape(inputs), mean=self.mean, stddev=self.stddev)\n",
        "        return inputs + noise\n",
        "\n",
        "class StochasticChannel(tf.keras.layers.Layer):\n",
        "    def __init__(self, roll_off=0.35, num_taps=101, time_delay=0, rate=1, **kwargs):\n",
        "        super(StochasticChannel, self).__init__(**kwargs)\n",
        "        self.num_taps = num_taps\n",
        "        self.time_delay = time_delay\n",
        "        self.rate = rate\n",
        "        self.roll_off = roll_off\n",
        "        # self.Noise_layer  = CustomNoise(mean=0.0,stddev=channel_parameters['noise_std'])\n",
        "\n",
        "    def upsampling(self, input):\n",
        "        input = tf.reshape(input, [-1, 1])\n",
        "        padding = tf.constant([[0, 0], [0, self.rate - 1]])\n",
        "        upsampled = tf.pad(input, padding, \"CONSTANT\")\n",
        "        print(\"shape after upsamping:\", input.shape)\n",
        "        return tf.reshape(upsampled, [-1])\n",
        "\n",
        "    def upsample_iq(self, input):\n",
        "        inner_dimension = ( input.shape[1])\n",
        "        N = inner_dimension//2\n",
        "        Real, Imag = [],[]\n",
        "        for i in range(N):\n",
        "          real_t,imag_t = input[:,2*i],input[:,2*i+1]\n",
        "          Real.extend(real_t)\n",
        "          Imag.extend(imag_t)\n",
        "        input = tf.stack([Real, Imag], axis=1)\n",
        "\n",
        "\n",
        "        # Create indices for real and imaginary parts\n",
        "        real_indices = tf.range(0, inner_dimension-1, 2)\n",
        "        imag_indices = tf.range(1, inner_dimension, 2)\n",
        "\n",
        "        # # Extract real and imaginary parts using the indices\n",
        "        # real_part = tf.gather(input[:], real_indices, axis=-1)\n",
        "        # imag_part = tf.gather(input[:], imag_indices, axis=-1)\n",
        "\n",
        "        # Convert indices to numpy for slicing\n",
        "        real_indices = real_indices.numpy()\n",
        "        imag_indices = imag_indices.numpy()\n",
        "\n",
        "        real = input[:, real_indices]\n",
        "        imag = input[:, imag_indices]\n",
        "        print(\"input dimension:\", input.shape)\n",
        "        real_up = self.upsampling(real)\n",
        "        imag_up = self.upsampling(imag)\n",
        "        return tf.stack([real_up, imag_up], axis=1)\n",
        "\n",
        "    def rrc_filter(self):\n",
        "        \"\"\"\n",
        "        Create a root-raised cosine (RRC) filter.\n",
        "\n",
        "        Returns:\n",
        "            RRC filter coefficients.\n",
        "        \"\"\"\n",
        "        t = np.linspace(-self.num_taps // 2, self.num_taps // 2, self.num_taps)\n",
        "        rrc = np.zeros_like(t)\n",
        "\n",
        "        for i in range(len(t)):\n",
        "            if t[i] == 0.0:\n",
        "                rrc[i] = (1.0 - self.roll_off + 4 * self.roll_off / np.pi)\n",
        "            elif np.abs(t[i]) == 1 / (4 * self.roll_off):\n",
        "                rrc[i] = (self.roll_off / (np.sqrt(2))) * \\\n",
        "                         ((1 + 2 / np.pi) * np.sin(np.pi / (4 * self.roll_off)) +\n",
        "                          (1 - 2 / np.pi) * np.cos(np.pi / (4 * self.roll_off)))\n",
        "            else:\n",
        "                rrc[i] = (np.sin(np.pi * (t[i]) * (1 - self.roll_off)) +\n",
        "                          4 * self.roll_off * (t[i]) * np.cos(np.pi * (t[i]) * (1 + self.roll_off))) / \\\n",
        "                         (np.pi * t[i] * (1 - (4 * self.roll_off * (t[i])) ** 2))\n",
        "\n",
        "        # Normalize filter coefficients to ensure unit energy\n",
        "        rrc = rrc / np.sqrt(np.sum(rrc ** 2))\n",
        "        rrc = tf.constant(rrc, dtype=tf.float32)\n",
        "        return rrc\n",
        "\n",
        "    def upsample_and_filter(self, input):\n",
        "        # Reshape the input dimension\n",
        "        # input = tf.reshape(input, [-1, 2])\n",
        "\n",
        "        # Upsample the signal\n",
        "        upsampled_signal = self.upsample_iq(input)\n",
        "\n",
        "        # Create the RRC filter\n",
        "        rrc = self.rrc_filter()\n",
        "\n",
        "        # Add a batch and channel dimension for conv1d\n",
        "        upsampled_signal = tf.expand_dims(upsampled_signal, axis=0)  # Shape: (1, length, 2)\n",
        "        rrc = tf.reshape(rrc, [-1, 1, 1])  # Shape: (filter_length, 1, 1)\n",
        "\n",
        "        padding_size = self.num_taps // 2\n",
        "        paddings = tf.constant([[0, 0], [padding_size, padding_size], [0, 0]])\n",
        "        padded_real = tf.pad(upsampled_signal[:, :, 0:1], paddings, \"CONSTANT\")\n",
        "        padded_imag = tf.pad(upsampled_signal[:, :, 1:2], paddings, \"CONSTANT\")\n",
        "        padded_signal = tf.concat([padded_real, padded_imag], axis=2)\n",
        "\n",
        "        # Apply the RRC filter using conv1d\n",
        "        real_filtered = tf.nn.conv1d(padded_signal[:, :, 0:1], rrc, stride=1, padding='VALID')\n",
        "        imag_filtered = tf.nn.conv1d(padded_signal[:, :, 1:2], rrc, stride=1, padding='VALID')\n",
        "\n",
        "        # Combine filtered real and imaginary parts\n",
        "        filtered_signal = tf.concat([real_filtered, imag_filtered], axis=2)\n",
        "        print(\"input shape; \",input.shape)\n",
        "        print(\"shape after filtering:\", filtered_signal.shape)\n",
        "        filtered_signal = tf.squeeze(filtered_signal, axis=0)  # Remove the batch dimension\n",
        "        print(\"shape after squeeze:\", filtered_signal[0])\n",
        "\n",
        "        return filtered_signal\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Apply upsampling and RRC filtering\n",
        "        filtered_signal = self.upsample_and_filter(inputs)\n",
        "\n",
        "        # Log the filtered signal for TensorBoard visualization\n",
        "        with tf.summary.create_file_writer('logs/stochastic_channel').as_default():\n",
        "            tf.summary.histogram(\"Filtered Signal\", filtered_signal, step=0)\n",
        "\n",
        "        return filtered_signal\n",
        "\n",
        "y = StochasticChannel()(train_dataset)\n",
        "print(train_dataset.shape)\n",
        "print(\"-------------------------------------------------------------\")\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zvfb4uPEVLA"
      },
      "source": [
        "# partially working stochastic channel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Egt3C_dlklw-"
      },
      "outputs": [],
      "source": [
        "# input_layer = autoencoder_model[0].get_layer('Input')\n",
        "# before_channel = Model(inputs=input_layer.input,  # Use KerasTensor as input\n",
        "#                        outputs=autoencoder_model[0].get_layer('normalization').output)\n",
        "# enc = before_channel(train_dataset)\n",
        "# tf.Tensor(\n",
        "# [1.        0.        0.        1.        0.7818562 0.6234588 0.\n",
        "# 0.       ], shape=(8,), dtype=float32)\n",
        "\n",
        "\n",
        "# Function to create a normalized RRC filter\n",
        "# def rrc_filter(alpha=.35, sps=1, num_taps=15, ts = 1):\n",
        "#     \"\"\"\n",
        "#     Create a root-raised cosine (RRC) filter.\n",
        "\n",
        "#     Args:\n",
        "#         ts: Sampling period (default is 1).\n",
        "#         alpha: Roll-off factor (0 <= alpha <= 1).\n",
        "#         sps: Samples per symbol (upsampling factor).\n",
        "#         num_taps: Number of filter taps (should be odd).\n",
        "\n",
        "#     Returns:\n",
        "#         RRC filter coefficients.\n",
        "#     \"\"\"\n",
        "#     t = np.linspace(-num_taps//2, num_taps//2 + 1,num_taps)\n",
        "#     rrc = np.zeros_like(t)\n",
        "\n",
        "#     for i in range(len(t)):\n",
        "#         if t[i] == 0.0:\n",
        "#             rrc[i] = (1.0 - alpha + 4 * alpha / np.pi)/ts\n",
        "#         elif np.abs(t[i]) == ts / (4 * alpha):\n",
        "#             rrc[i] = (alpha /( np.sqrt(2)*ts)) * \\\n",
        "#                      ((1 + 2/np.pi) * np.sin(np.pi / (4 * alpha)) +\n",
        "#                       (1 - 2/np.pi) * np.cos(np.pi / (4 * alpha)))\n",
        "#         else:\n",
        "#             rrc[i] = (np.sin(np.pi * (t[i]/ts) * (1 - alpha)) +\n",
        "#                       4 * alpha * (t[i]/ts) * np.cos(np.pi * (t[i]/ts) * (1 + alpha))) / \\\n",
        "#                      (np.pi * t[i] * (1 - (4 * alpha * (t[i]/ts))**2))\n",
        "\n",
        "#     # Normalize filter coefficients to ensure unit energy\n",
        "#     rrc = rrc / np.sqrt(np.sum(rrc**2))\n",
        "#     rrc = tf.constant(rrc, dtype=tf.float32)\n",
        "#     # plt.stem(t,rrc)  # Plot for visualization\n",
        "#     # plt.title(f\"Time_delay = {10}\")\n",
        "#     return rrc\n",
        "\n",
        "# # print(enc[0])\n",
        "\n",
        "# def real_to_complex_tensor(inp_tensor):\n",
        "#     # Reshape the tensor to group adjacent real and imaginary parts\n",
        "#     batch_size = inp_tensor.shape[0]   # Number of batches\n",
        "#     inner_dim = inp_tensor.shape[1]    # Inner dimension size\n",
        "\n",
        "#     # Debugging: Print the input shape\n",
        "#     print(f\"Input tensor shape: {inp_tensor.shape}\")\n",
        "#     print(f\"Batch size: {batch_size}, Inner dimension: {inner_dim}\")\n",
        "#     print(\"-------------------------------------------------------------\")\n",
        "\n",
        "#     # If inner_dim is odd, pad the input\n",
        "#     if inner_dim % 2 != 0:\n",
        "#         inp_tensor = tf.pad(inp_tensor, [[0, 0], [0, 1]])\n",
        "#         inner_dim += 1  # Adjust the inner_dim to account for padding\n",
        "#     # Ensure that the inner dimension is even (for real and imaginary pairs)\n",
        "#     assert inner_dim % 2 == 0, \"Inner dimension must be even for real and imaginary pairs.\"\n",
        "\n",
        "#     # Reshape the tensor to separate real and imaginary parts\n",
        "#     reshaped_tensor = tf.reshape(inp_tensor, [batch_size, inner_dim // 2, 2])\n",
        "\n",
        "#     rrc = rrc_filter()\n",
        "#     rrc = tf.reshape(rrc, [-1, 1, 1])  # Shape: (filter_length, 1, 1) for conv1d\n",
        "\n",
        "#     # Extract real and imaginary parts\n",
        "#     real_part = reshaped_tensor[:, :, 0]\n",
        "#     real_part = upsample(real_part, 4)\n",
        "\n",
        "#     imag_part = reshaped_tensor[:, :, 1]\n",
        "#     imag_part = upsample(imag_part, 4)\n",
        "\n",
        "#     # Add a channel dimension to match conv1d's 3D input requirement\n",
        "#     real_part = tf.expand_dims(real_part, axis=-1)  # Shape: (batch_size, time_length, 1)\n",
        "#     imag_part = tf.expand_dims(imag_part, axis=-1)  # Shape: (batch_size, time_length, 1)\n",
        "\n",
        "#     # Apply the RRC filter using conv1d (expects [batch_size, width, channels])\n",
        "#     real_filtered = tf.nn.conv1d(real_part, rrc, stride=1, padding='VALID')\n",
        "#     imag_filtered = tf.nn.conv1d(imag_part, rrc, stride=1, padding='VALID')\n",
        "\n",
        "#     real_filtered = tf.squeeze(real_filtered, axis=-1)  # Shape: (batch_size, time_length)\n",
        "#     imag_filtered = tf.squeeze(imag_filtered, axis=-1)  # Shape: (batch_size, time_length)\n",
        "\n",
        "#     # Interleave real and imaginary parts\n",
        "#     interleaved = tf.stack([real_filtered, imag_filtered], axis=-1)  # Shape: (batch_size, time_length, 2)\n",
        "#     print(f\"Interleaved shape: {interleaved.shape}\")\n",
        "#     interleaved = tf.reshape(interleaved, [batch_size, -1])  # Flatten to (batch_size, time_length*2)\n",
        "#     print(f\"Flattened shape: {interleaved.shape}\")\n",
        "#     return interleaved\n",
        "# def complex_to_real_tensor(inp_tensor):\n",
        "#     # Debugging: Print the input shape\n",
        "#     print(f\"Input tensor shape: {inp_tensor.shape}\")\n",
        "#     # Ensure that the input tensor is of shape [2, n]\n",
        "#     assert inp_tensor.shape[0] == 2, \"The first dimension must be 2 (real and imaginary parts).\"\n",
        "\n",
        "#     # Get real part (first row) and imaginary part (second row)\n",
        "#     real_part = inp_tensor[0, :]  # Shape: [n]\n",
        "#     imag_part = inp_tensor[1, :]  # Shape: [n]\n",
        "\n",
        "#     # Stack real and imaginary parts together and interleave them\n",
        "#     combined = tf.stack([real_part, imag_part], axis=-1)  # Shape: [n, 2]\n",
        "\n",
        "#     # Reshape to interleave the real and imaginary parts into one dimension\n",
        "#     interleaved = tf.reshape(combined, [-1])  # Shape: [2*n], interleaving real and imaginary\n",
        "\n",
        "#     return interleaved\n",
        "\n",
        "# # Test input tensor (e.g., batch of 2 samples with 4 real values each)\n",
        "# # For example, real values are [1, 2, 3, 4], to be grouped as (1+2j, 3+4j)\n",
        "# # enc = tf.constant([[1, 2, 3, 4], [5, 6, 7, 8]], dtype=tf.float32)\n",
        "# def upsample(input_tensor, r=4):\n",
        "#     \"\"\"\n",
        "#     Function to upsample a tensor by adding r-1 zeros between each element along the last axis.\n",
        "#     \"\"\"\n",
        "#     # Expand dimensions of the input to insert the zeros\n",
        "#     input_shape = tf.shape(input_tensor)\n",
        "#     expanded_input = tf.expand_dims(input_tensor, axis=-1)  # Add an extra dimension\n",
        "\n",
        "#     # Create a tensor of zeros with the same shape as input, but r times the last dimension\n",
        "#     zero_padding = tf.zeros_like(expanded_input)  # Tensor of zeros\n",
        "#     zero_padding = tf.tile(zero_padding, [1, 1, r-1])  # Repeat the zeros r-1 times\n",
        "\n",
        "#     # Concatenate input and zero_padding along the last dimension\n",
        "#     upsampled = tf.concat([expanded_input, zero_padding], axis=-1)\n",
        "\n",
        "#     # Reshape to flatten the added dimension\n",
        "#     new_shape = [input_shape[0], input_shape[1] * r]\n",
        "#     upsampled_flat = tf.reshape(upsampled, new_shape)\n",
        "#     return upsampled_flat\n",
        "\"\"\"-------------------------------------------------------------------------------------------------------------------------------Creating Layer -----------------------\"\"\"\n",
        "class StochasticChannelv2(tf.keras.layers.Layer):\n",
        "    def __init__(self, roll_off=0.35, num_taps=3, time_delay=0, rate=1, ts=1, **kwargs):\n",
        "        super(StochasticChannelv2, self).__init__(**kwargs)\n",
        "        self.num_taps = num_taps\n",
        "        self.time_delay = time_delay\n",
        "        self.rate = rate\n",
        "        self.roll_off = roll_off\n",
        "        self.ts = ts  # Define ts (sampling period) as an instance attribute\n",
        "\n",
        "    def upsample(self, input_tensor):\n",
        "        \"\"\"\n",
        "        Function to upsample a tensor by adding (rate - 1) zeros between each element along the last axis.\n",
        "        \"\"\"\n",
        "        # Expand dimensions of the input to insert the zeros\n",
        "        input_shape = tf.shape(input_tensor)\n",
        "        expanded_input = tf.expand_dims(input_tensor, axis=-1)  # Add an extra dimension\n",
        "\n",
        "        # Create a tensor of zeros with the same shape as input, but rate times the last dimension\n",
        "        zero_padding = tf.zeros_like(expanded_input)  # Tensor of zeros\n",
        "        zero_padding = tf.tile(zero_padding, [1, 1, self.rate - 1])  # Repeat the zeros rate-1 times\n",
        "\n",
        "        # Concatenate input and zero_padding along the last dimension\n",
        "        upsampled = tf.concat([expanded_input, zero_padding], axis=-1)\n",
        "\n",
        "        # Reshape to flatten the added dimension\n",
        "        new_shape = [input_shape[0], input_shape[1] * self.rate]\n",
        "        upsampled_flat = tf.reshape(upsampled, new_shape)\n",
        "        return upsampled_flat\n",
        "\n",
        "    def real_to_complex_tensor(self, inp_tensor):\n",
        "        # Reshape the tensor to group adjacent real and imaginary parts\n",
        "        batch_size = inp_tensor.shape[0]   # Number of batches\n",
        "        inner_dim = inp_tensor.shape[1]    # Inner dimension size\n",
        "\n",
        "        # Ensure that the inner dimension is even (for real and imaginary pairs)\n",
        "        assert inner_dim % 2 == 0, \"Inner dimension must be even for real and imaginary pairs.\"\n",
        "\n",
        "        # Reshape the tensor to separate real and imaginary parts\n",
        "        reshaped_tensor = tf.reshape(inp_tensor, [batch_size, inner_dim // 2, 2])\n",
        "\n",
        "        rrc = self.rrc_filter()\n",
        "        rrc = tf.reshape(rrc, [-1, 1, 1])  # Shape: (filter_length, 1, 1) for conv1d\n",
        "\n",
        "        # Extract real and imaginary parts\n",
        "        real_part = reshaped_tensor[:, :, 0]\n",
        "        real_part = self.upsample(real_part)  # Use self.upsample\n",
        "\n",
        "        imag_part = reshaped_tensor[:, :, 1]\n",
        "        imag_part = self.upsample(imag_part)  # Use self.upsample\n",
        "\n",
        "        # Add a channel dimension to match conv1d's 3D input requirement\n",
        "        real_part = tf.expand_dims(real_part, axis=-1)  # Shape: (batch_size, time_length, 1)\n",
        "        imag_part = tf.expand_dims(imag_part, axis=-1)  # Shape: (batch_size, time_length, 1)\n",
        "\n",
        "        # Apply the RRC filter using conv1d (expects [batch_size, width, channels])\n",
        "        real_filtered = tf.nn.conv1d(real_part, rrc, stride=1, padding='VALID')\n",
        "        imag_filtered = tf.nn.conv1d(imag_part, rrc, stride=1, padding='VALID')\n",
        "\n",
        "        real_filtered = tf.squeeze(real_filtered, axis=-1)  # Shape: (batch_size, time_length)\n",
        "        imag_filtered = tf.squeeze(imag_filtered, axis=-1)  # Shape: (batch_size, time_length)\n",
        "\n",
        "        # Interleave real and imaginary parts\n",
        "        interleaved = tf.stack([real_filtered, imag_filtered], axis=-1)  # Shape: (batch_size, time_length, 2)\n",
        "        interleaved = tf.reshape(interleaved, [batch_size, -1])  # Flatten to (batch_size, time_length*2)\n",
        "\n",
        "        return interleaved\n",
        "\n",
        "    # Function to create a normalized RRC filter\n",
        "    def rrc_filter(self):\n",
        "        \"\"\"\n",
        "        Create a root-raised cosine (RRC) filter.\n",
        "        \"\"\"\n",
        "        t = np.linspace(-self.num_taps // 2, self.num_taps // 2 + 1, self.num_taps)\n",
        "        rrc = np.zeros_like(t)\n",
        "\n",
        "        for i in range(len(t)):\n",
        "            if t[i] == 0.0:\n",
        "                rrc[i] = (1.0 - self.roll_off + 4 * self.roll_off / np.pi) / self.ts\n",
        "            elif np.abs(t[i]) == self.ts / (4 * self.roll_off):\n",
        "                rrc[i] = (self.roll_off / (np.sqrt(2) * self.ts)) * \\\n",
        "                         ((1 + 2 / np.pi) * np.sin(np.pi / (4 * self.roll_off)) +\n",
        "                          (1 - 2 / np.pi) * np.cos(np.pi / (4 * self.roll_off)))\n",
        "            else:\n",
        "                rrc[i] = (np.sin(np.pi * (t[i] / self.ts) * (1 - self.roll_off)) +\n",
        "                          4 * self.roll_off * (t[i] / self.ts) * np.cos(np.pi * (t[i] / self.ts) * (1 + self.roll_off))) / \\\n",
        "                         (np.pi * t[i] * (1 - (4 * self.roll_off * (t[i] / self.ts)) ** 2))\n",
        "\n",
        "        # Normalize filter coefficients to ensure unit energy\n",
        "        rrc = rrc / np.sqrt(np.sum(rrc ** 2))\n",
        "        rrc = tf.constant(rrc, dtype=tf.float32)\n",
        "        return rrc\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Apply upsampling and RRC filtering\n",
        "        batch_size = tf.shape(inputs)[0]  # Batch size\n",
        "        inner_dim = tf.shape(inputs)[1]   # Inner dimension size\n",
        "\n",
        "        reshaped_tensor = tf.reshape(inputs, [batch_size, inner_dim // 2, 2])\n",
        "        upsampled_signal = self.upsample(inputs)\n",
        "        output = self.real_to_complex_tensor(upsampled_signal)  # Use self.real_to_complex_tensor here\n",
        "        return output\n",
        "\n",
        "\n",
        "\n",
        "# Convert real to complex tensor\n",
        "\n",
        "y = StochasticChannelv2()(train_dataset)\n",
        "print(train_dataset.shape)\n",
        "print(\"-------------------------------------------------------------\")\n",
        "print(y.shape)   # this will print the output of single data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SvJzvReoBKI"
      },
      "source": [
        "# Stochastic Channel version 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwhwvvTxmR5W"
      },
      "outputs": [],
      "source": [
        "class StochasticChannelv3(tf.keras.layers.Layer):\n",
        "    def __init__(self, roll_off=0.35, num_taps=31, time_delay=2, r=4, ts=1, **kwargs):\n",
        "        super(StochasticChannelv3, self).__init__(**kwargs)\n",
        "        self.num_taps = num_taps\n",
        "        self.time_delay = time_delay\n",
        "        self.r = r  # Upsampling factor\n",
        "        self.roll_off = roll_off  # Roll-off factor\n",
        "        self.ts = ts  # Sampling period (default is 1)\n",
        "\n",
        "    def upsampling(self, inp):\n",
        "        com_reshape = tf.reshape(inp, [-1, 1])\n",
        "        padding = tf.constant([[0, 0], [0, self.r - 1]])  # Access self.r\n",
        "        upsampled = tf.pad(com_reshape, padding, mode=\"CONSTANT\")\n",
        "        upsampled = tf.reshape(upsampled, [-1])  # Flatten back to 1D\n",
        "        return upsampled\n",
        "\n",
        "    def upsample_iq(self, inp):\n",
        "        real = inp[:, 0]  # Real part\n",
        "        imag = inp[:, 1]  # Imaginary part\n",
        "\n",
        "        real_up = self.upsampling(real)\n",
        "        imag_up = self.upsampling(imag)\n",
        "\n",
        "        upsampled = tf.stack([real_up, imag_up], axis=1)\n",
        "        return upsampled\n",
        "\n",
        "    def rrc_filter(self):\n",
        "        t = np.linspace(-self.num_taps // 2, self.num_taps // 2 + 1, self.num_taps) - self.time_offset()\n",
        "        rrc = np.zeros_like(t)\n",
        "\n",
        "        for i in range(len(t)):\n",
        "            if t[i] == 0.0:\n",
        "                rrc[i] = (1.0 - self.roll_off + 4 * self.roll_off / np.pi) / self.ts\n",
        "            elif np.abs(t[i]) == self.ts / (4 * self.roll_off):\n",
        "                rrc[i] = (self.roll_off / (np.sqrt(2) * self.ts)) * \\\n",
        "                         ((1 + 2 / np.pi) * np.sin(np.pi / (4 * self.roll_off)) +\n",
        "                          (1 - 2 / np.pi) * np.cos(np.pi / (4 * self.roll_off)))\n",
        "            else:\n",
        "                rrc[i] = (np.sin(np.pi * (t[i] / self.ts) * (1 - self.roll_off)) +\n",
        "                          4 * self.roll_off * (t[i] / self.ts) * np.cos(np.pi * (t[i] / self.ts) * (1 + self.roll_off))) / \\\n",
        "                         (np.pi * t[i] * (1 - (4 * self.roll_off * (t[i] / self.ts)) ** 2))\n",
        "\n",
        "        rrc = rrc / np.sqrt(np.sum(rrc ** 2))\n",
        "        rrc = tf.constant(rrc, dtype=tf.float32)\n",
        "        return rrc\n",
        "\n",
        "    def upsample_and_filter(self, signal):\n",
        "        upsampled_signal = self.upsample_iq(signal)\n",
        "        rrc = self.rrc_filter()\n",
        "\n",
        "        upsampled_signal = tf.expand_dims(upsampled_signal, axis=0)  # Shape: (1, length, 2)\n",
        "        rrc = tf.reshape(rrc, [-1, 1, 1])  # Shape: (filter_length, 1, 1)\n",
        "\n",
        "        padding_size = self.num_taps // 2\n",
        "        paddings = tf.constant([[0, 0], [padding_size, padding_size], [0, 0]])\n",
        "        padded_real = tf.pad(upsampled_signal[:, :, 0:1], paddings, \"CONSTANT\")\n",
        "        padded_imag = tf.pad(upsampled_signal[:, :, 1:2], paddings, \"CONSTANT\")\n",
        "        upsampled_signal = tf.concat([padded_real, padded_imag], axis=2)\n",
        "\n",
        "        real_filtered = tf.nn.conv1d(upsampled_signal[:, :, 0:1], rrc, stride=1, padding='SAME')\n",
        "        imag_filtered = tf.nn.conv1d(upsampled_signal[:, :, 1:2], rrc, stride=1, padding='SAME')\n",
        "\n",
        "        filtered_signal = tf.concat([real_filtered, imag_filtered], axis=2)\n",
        "        filtered_signal = tf.squeeze(filtered_signal, axis=0)  # Remove the batch dimension\n",
        "        return filtered_signal\n",
        "\n",
        "    def time_offset(self, sampling_time=10):\n",
        "        # t_offset = np.random.uniform(-sampling_time // 2, sampling_time // 2)\n",
        "        t_offset = 0\n",
        "        # t_offset = 0\n",
        "        return t_offset\n",
        "\n",
        "    # def call(self, inputs):\n",
        "    #     f = inputs.shape[1]//2\n",
        "    #     inputs = tf.reshape(inputs, [-1, 2])  # Reshape to pairs of real and imaginary\n",
        "    #     output = []\n",
        "    #     for i in inputs:\n",
        "    #         i = tf.reshape(i, [-1, 2])  # Reshape input pairs as necessary\n",
        "    #         print(i.shape)\n",
        "    #         filtered_signal = self.upsample_and_filter(i)\n",
        "    #         filtered_signal = tf.reshape(filtered_signal, [2,-1])  # Flatten the filtered signal\n",
        "    #         output.append(filtered_signal)\n",
        "\n",
        "    #     stacked_tensor = tf.stack(output, axis=0)  # Stack the filtered signals\n",
        "    #     stacked_tensor = tf.reshape(stacked_tensor, [stacked_tensor.shape[0]//f, -1])  # Reshape back to original shape\n",
        "    #     return stacked_tensor # here each data have real part and then follow by complex part. eg [real components , imaginary parts]\n",
        "\n",
        "    # def call(self, inputs):\n",
        "    #     batch_size = tf.shape(inputs)[0]\n",
        "    #     f = inputs.shape[1] // 2\n",
        "    #     def slice_sample(sample):\n",
        "    #       array = [tf.reshape(i,[-1,2]) for i in sample ]\n",
        "    #       out = [self.upsample_and_filter(j) for j in array]\n",
        "    #       return tf.stack(out, axis=0)\n",
        "    #     # Reshape to pairs of real and imaginary parts\n",
        "    #     inputs = tf.reshape(inputs, [batch_size, -1, 2])  # Shape: (batch_size, num_pairs, 2)\n",
        "    #     print(inputs.shape)\n",
        "    #     # Define a function to process each sample\n",
        "    #     \"\"\" this below also  working but not able to integrate in model\"\"\"\n",
        "    #     # def process_sample(sample):\n",
        "    #     #     filtered_signal = slice_sample(sample)\n",
        "    #     #     # filtered_signal = self.upsample_and_filter(sample)  # Process each sample\n",
        "    #     #     return filtered_signal\n",
        "    #     def process_sample(sample):\n",
        "    #         a = tf.reshape(sample[0,:],[1,2])\n",
        "    #         b = tf.reshape(sample[1,:],[1,2])\n",
        "    #         c = tf.reshape(sample[2,:],[1,2])\n",
        "    #         d = tf.reshape(sample[3,:],[1,2])\n",
        "    #         fil_a, fil_b, fil_c,fil_d= self.upsample_and_filter(a), self.upsample_and_filter(b), self.upsample_and_filter(c), self.upsample_and_filter(d)\n",
        "    #         filtered_signal = tf.stack([fil_a, fil_b, fil_c, fil_d], axis=0)\n",
        "    #         return filtered_signal\n",
        "\n",
        "    #     # Apply the function to each sample in the batch\n",
        "    #     output = tf.map_fn(process_sample, inputs, dtype=tf.float32)  # Shape: (batch_size, num_filtered_samples, 2)\n",
        "\n",
        "    #     # Reshape back to original shape if necessary\n",
        "    #     output = tf.reshape(output, [batch_size, -1])\n",
        "\n",
        "    #     return output\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        f = inputs.shape[1] // 2\n",
        "\n",
        "        # Reshape to pairs of real and imaginary parts\n",
        "        inputs = tf.reshape(inputs, [batch_size, -1, 2])  # Shape: (batch_size, num_pairs, 2)\n",
        "\n",
        "        # Define a function to process each sample\n",
        "        def process_sample(sample):\n",
        "            filtered_signal = self.upsample_and_filter(sample)  # Process each sample\n",
        "            return filtered_signal\n",
        "\n",
        "        # Apply the function to each sample in the batch\n",
        "        output = tf.map_fn(process_sample, inputs, dtype=tf.float32)  # Shape: (batch_size, num_filtered_samples, 2)\n",
        "\n",
        "        # Reshape back to original shape if necessary\n",
        "        output = tf.reshape(output, [batch_size, -1])\n",
        "\n",
        "        return output\n",
        "\n",
        "small = Model(inputs = autoencoder_model[0].get_layer('Input').input, outputs = autoencoder_model[0].get_layer('normalization').output)\n",
        "p_out = small.predict(train_dataset[:1],batch_size = 1)\n",
        "print(p_out)\n",
        "print(p_out.shape)\n",
        "v_out = StochasticChannelv3()(p_out)\n",
        "print(p_out.shape)\n",
        "print(\"-------------------------------------------------------------\")\n",
        "print(v_out.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mP0F-0iGZymQ"
      },
      "source": [
        "## stochastic channel for one message at a time for rrc filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3puH4JrZyCF"
      },
      "outputs": [],
      "source": [
        "class StochasticChannelv3(tf.keras.layers.Layer):\n",
        "    def __init__(self, roll_off=0.35, num_taps=31, time_delay=2, r=4, ts=.5e-6, **kwargs):\n",
        "        super(StochasticChannelv3, self).__init__(**kwargs)\n",
        "        self.num_taps = num_taps\n",
        "        self.time_delay = time_delay\n",
        "        self.r = r  # Upsampling factor\n",
        "        self.roll_off = roll_off  # Roll-off factor\n",
        "        self.ts = ts  # Sampling period (default is 1)\n",
        "\n",
        "    def upsampling(self, inp):\n",
        "        com_reshape = tf.reshape(inp, [-1, 1])\n",
        "        padding = tf.constant([[0, 0], [0, self.r - 1]])  # Access self.r\n",
        "        upsampled = tf.pad(com_reshape, padding, mode=\"CONSTANT\")\n",
        "        upsampled = tf.reshape(upsampled, [-1])  # Flatten back to 1D\n",
        "        print(upsampled.shape)\n",
        "        return upsampled\n",
        "\n",
        "    def upsample_iq(self, inp):\n",
        "        real = inp[:, 0]  # Real part\n",
        "        imag = inp[:, 1]  # Imaginary part\n",
        "\n",
        "        real_up = self.upsampling(real)\n",
        "        imag_up = self.upsampling(imag)\n",
        "\n",
        "        upsampled = tf.stack([real_up, imag_up], axis=1)\n",
        "        return upsampled\n",
        "\n",
        "    def rrc_filter(self):\n",
        "        t = np.linspace(-self.num_taps // 2, self.num_taps // 2 + 1, self.num_taps) - self.time_offset()\n",
        "        rrc = np.zeros_like(t)\n",
        "\n",
        "        for i in range(len(t)):\n",
        "            if t[i] == 0.0:\n",
        "                rrc[i] = (1.0 - self.roll_off + 4 * self.roll_off / np.pi) / self.ts\n",
        "            elif np.abs(t[i]) == self.ts / (4 * self.roll_off):\n",
        "                rrc[i] = (self.roll_off / (np.sqrt(2) * self.ts)) * \\\n",
        "                         ((1 + 2 / np.pi) * np.sin(np.pi / (4 * self.roll_off)) +\n",
        "                          (1 - 2 / np.pi) * np.cos(np.pi / (4 * self.roll_off)))\n",
        "            else:\n",
        "                rrc[i] = (np.sin(np.pi * (t[i] / self.ts) * (1 - self.roll_off)) +\n",
        "                          4 * self.roll_off * (t[i] / self.ts) * np.cos(np.pi * (t[i] / self.ts) * (1 + self.roll_off))) / \\\n",
        "                         (np.pi * t[i] * (1 - (4 * self.roll_off * (t[i] / self.ts)) ** 2))\n",
        "\n",
        "        rrc = rrc / np.sqrt(np.sum(rrc ** 2))\n",
        "        rrc = tf.constant(rrc, dtype=tf.float32)\n",
        "        return rrc\n",
        "\n",
        "    def upsample_and_filter(self, signal):\n",
        "        upsampled_signal = self.upsample_iq(signal)\n",
        "        rrc = self.rrc_filter()\n",
        "\n",
        "        upsampled_signal = tf.expand_dims(upsampled_signal, axis=0)  # Shape: (1, length, 2)\n",
        "        rrc = tf.reshape(rrc, [-1, 1, 1])  # Shape: (filter_length, 1, 1)\n",
        "\n",
        "        padding_size = self.num_taps // 2\n",
        "        paddings = tf.constant([[0, 0], [padding_size, padding_size], [0, 0]])\n",
        "        padded_real = tf.pad(upsampled_signal[:, :, 0:1], paddings, \"CONSTANT\")\n",
        "        padded_imag = tf.pad(upsampled_signal[:, :, 1:2], paddings, \"CONSTANT\")\n",
        "        upsampled_signal = tf.concat([padded_real, padded_imag], axis=2)\n",
        "        real_filtered = tf.nn.conv1d(upsampled_signal[:, :, 0:1], rrc, stride=1, padding='SAME')\n",
        "        imag_filtered = tf.nn.conv1d(upsampled_signal[:, :, 1:2], rrc, stride=1, padding='SAME')\n",
        "\n",
        "        filtered_signal = tf.concat([real_filtered, imag_filtered], axis=2)\n",
        "        filtered_signal = tf.squeeze(filtered_signal, axis=0)  # Remove the batch dimension\n",
        "        return filtered_signal\n",
        "\n",
        "    def time_offset(self, sampling_time=10):\n",
        "        t_offset = np.random.uniform(-sampling_time // 2, sampling_time // 2)\n",
        "        return t_offset\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        f = inputs.shape[1] // 2\n",
        "\n",
        "        # Reshape to pairs of real and imaginary parts\n",
        "        inputs = tf.reshape(inputs, [batch_size, -1, 2])  # Shape: (batch_size, num_pairs, 2)\n",
        "\n",
        "        # Define a function to process each sample\n",
        "        def process_sample(sample):\n",
        "            filtered_signal = self.upsample_and_filter(sample)  # Process each sample\n",
        "            return filtered_signal\n",
        "\n",
        "        # Apply the function to each sample in the batch\n",
        "        output = tf.map_fn(process_sample, inputs, dtype=tf.float32)  # Shape: (batch_size, num_filtered_samples, 2)\n",
        "\n",
        "        # Reshape back to original shape if necessary\n",
        "        output = tf.reshape(output, [batch_size, -1])\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTUthTyGbFYa"
      },
      "source": [
        "## stochastic channel for continuous transmission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3gDIgDQbJsn"
      },
      "outputs": [],
      "source": [
        "  \"\"\"\n",
        "  When using this make sure that batch size is divisible by 2*l+1\n",
        "  \"\"\"\n",
        "class StochasticChannelv3_cts_tr(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, roll_off=0.35, num_taps=31, time_delay=2, r=4, ts=.5e-6,l = 6, **kwargs):\n",
        "        super(StochasticChannelv3_cts_tr, self).__init__(**kwargs)\n",
        "        self.num_taps = num_taps\n",
        "        self.time_delay = time_delay\n",
        "        self.r = r  # Upsampling factor\n",
        "        self.roll_off = roll_off  # Roll-off factor\n",
        "        self.ts = ts  # Sampling period (default is 1)\n",
        "        self.l = l\n",
        "\n",
        "    def upsampling(self, inp):\n",
        "        com_reshape = tf.reshape(inp, [-1, 1])\n",
        "        padding = tf.constant([[0, 0], [0, self.r - 1]])  # Access self.r\n",
        "        upsampled = tf.pad(com_reshape, padding, mode=\"CONSTANT\")\n",
        "        upsampled = tf.reshape(upsampled, [-1])  # Flatten back to 1D\n",
        "        return upsampled\n",
        "\n",
        "    def upsample_iq(self, inp):\n",
        "        real = inp[:, 0]  # Real part\n",
        "        imag = inp[:, 1]  # Imaginary part\n",
        "\n",
        "        real_up = self.upsampling(real)\n",
        "        imag_up = self.upsampling(imag)\n",
        "        upsampled = tf.stack([real_up, imag_up], axis=1)\n",
        "        return upsampled\n",
        "\n",
        "    def rrc_filter(self):\n",
        "        print(\"time offset for this task\", self.time_offset())\n",
        "        t = np.linspace(-self.num_taps // 2, self.num_taps // 2 + 1, self.num_taps) - self.time_offset()\n",
        "        rrc = np.zeros_like(t)\n",
        "\n",
        "        for i in range(len(t)):\n",
        "            if t[i] == 0.0:\n",
        "                rrc[i] = (1.0 - self.roll_off + 4 * self.roll_off / np.pi) / self.ts\n",
        "            elif np.abs(t[i]) == self.ts / (4 * self.roll_off):\n",
        "                rrc[i] = (self.roll_off / (np.sqrt(2) * self.ts)) * \\\n",
        "                         ((1 + 2 / np.pi) * np.sin(np.pi / (4 * self.roll_off)) +\n",
        "                          (1 - 2 / np.pi) * np.cos(np.pi / (4 * self.roll_off)))\n",
        "            else:\n",
        "                rrc[i] = (np.sin(np.pi * (t[i] / self.ts) * (1 - self.roll_off)) +\n",
        "                          4 * self.roll_off * (t[i] / self.ts) * np.cos(np.pi * (t[i] / self.ts) * (1 + self.roll_off))) / \\\n",
        "                         (np.pi * t[i] * (1 - (4 * self.roll_off * (t[i] / self.ts)) ** 2))\n",
        "\n",
        "        rrc = rrc / np.sqrt(np.sum(rrc ** 2))\n",
        "        rrc = tf.constant(rrc, dtype=tf.float32)\n",
        "        return rrc\n",
        "\n",
        "    def upsample_and_filter(self, signal):\n",
        "        upsampled_signal = self.upsample_iq(signal)\n",
        "        rrc = self.rrc_filter()\n",
        "\n",
        "\n",
        "        upsampled_signal = tf.expand_dims(upsampled_signal, axis=0)  # Shape: (1, length, 2)\n",
        "        rrc = tf.reshape(rrc, [-1, 1, 1])  # Shape: (filter_length, 1, 1)\n",
        "\n",
        "        padding_size = self.num_taps // 2\n",
        "        paddings = tf.constant([[0, 0], [padding_size, padding_size], [0, 0]])\n",
        "        padded_real = tf.pad(upsampled_signal[:, :, 0:1], paddings, \"CONSTANT\")\n",
        "        padded_imag = tf.pad(upsampled_signal[:, :, 1:2], paddings, \"CONSTANT\")\n",
        "        upsampled_signal = tf.concat([padded_real, padded_imag], axis=2)\n",
        "        real_filtered = tf.nn.conv1d(upsampled_signal[:, :, 0:1], rrc, stride=1, padding='SAME')\n",
        "        imag_filtered = tf.nn.conv1d(upsampled_signal[:, :, 1:2], rrc, stride=1, padding='SAME')\n",
        "\n",
        "        filtered_signal = tf.concat([real_filtered, imag_filtered], axis=2)\n",
        "        filtered_signal = tf.squeeze(filtered_signal, axis=0)  # Remove the batch dimension\n",
        "        return filtered_signal\n",
        "\n",
        "    def time_offset(self, sampling_time=10):\n",
        "        t_offset = np.random.uniform(-sampling_time // 2, sampling_time // 2)\n",
        "        return 0\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        f = inputs.shape[1] // 2\n",
        "        beta = batch_size//(2*self.l+1)\n",
        "        out= []\n",
        "        for i in range(beta):\n",
        "          x = inputs[(2*self.l+1)*i:(2*self.l+1)*(i+1)]\n",
        "          # c = tf.concat(tf.unstack(x, axis=1), axis=0)  # Unstack along axis=1 and concatenate\n",
        "          out.append(x)\n",
        "        inputs = tf.stack(out, axis=0)\n",
        "\n",
        "        # Reshape to pairs of real and imaginary parts\n",
        "        inputs = tf.reshape(inputs, [batch_size//(2*self.l+1), -1, 2])  # Shape: (batch_size, num_pairs, 2)\n",
        "\n",
        "\n",
        "        # Define a function to process each sample\n",
        "        def process_sample(sample):\n",
        "            filtered_signal = self.upsample_and_filter(sample)  # Process each sample\n",
        "            return filtered_signal\n",
        "\n",
        "        # Apply the function to each sample in the batch\n",
        "        output = tf.map_fn(process_sample, inputs, dtype=tf.float32)  # Shape: (batch_size, num_filtered_samples, 2)\n",
        "\n",
        "        # Reshape back to original shape if necessary\n",
        "        output = tf.reshape(output, [batch_size//(2*self.l+1), -1])\n",
        "\n",
        "        return output\n",
        "\n",
        "    # def call(self, inputs):\n",
        "    #     batch_size = tf.shape(inputs)[0]\n",
        "    #     group_size = 2 * self.l + 1  # Define the group size\n",
        "\n",
        "    #     # Reshape inputs into groups of (2 * l + 1)\n",
        "    #     # This creates a tensor of shape (beta, group_size, input_dim)\n",
        "    #     beta = batch_size // group_size\n",
        "    #     # inputs = tf.reshape(inputs, [beta, group_size, -1])  # Reshape without a for loop\n",
        "    #     print('input shape before the sub grpups ',inputs.shape)\n",
        "    #     # Reshape to pairs of real and imaginary parts\n",
        "    #     inputs = tf.reshape(inputs, [beta, -1, 2])  # Shape: (batch_size, num_pairs, 2)\n",
        "\n",
        "    #     # need to create the window\n",
        "\n",
        "    #     # Define a function to process each sample\n",
        "    #     def process_sample(sample):\n",
        "    #         filtered_signal = self.upsample_and_filter(sample)  # Process each sample\n",
        "    #         return filtered_signal\n",
        "\n",
        "    #     # Apply the function to each sample in the batch using tf.map_fn\n",
        "    #     output = tf.map_fn(process_sample, inputs, dtype=tf.float32)\n",
        "\n",
        "\n",
        "    #     # Reshape back to original shape if necessary\n",
        "    #     output = tf.reshape(output, [beta, -1])\n",
        "    #     print('output shape after do the sub group', output.shape)\n",
        "\n",
        "    #     # # include slidcer to the model\n",
        "    #     # k1 = self.r * 4 + (self.num_taps + 1) // 2\n",
        "    #     # k2 = 2 * self.l * self.r * 4 + (self.num_taps - 1) // 2\n",
        "    #     # seq_len = k2 - k1 + 1\n",
        "    #     # print(f\"k1: {k1}, k2: {k2}, seq_len: {seq_len}\")\n",
        "    #     # output = output[:, k1:(k2+1)]\n",
        "    #     # print(output.shape)\n",
        "\n",
        "    #     return output\n",
        "\n",
        "    def call(self, inputs,return_offset=False):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        input_dim = tf.shape(inputs)[1]\n",
        "\n",
        "        # Ensure group_size divides batch_size evenly\n",
        "        group_size = 2 * self.l + 1  # e.g., 13\n",
        "        # if batch_size % group_size != 0:\n",
        "        #     raise ValueError(f\"Batch size ({batch_size}) must be divisible by group size ({group_size}).\")\n",
        "\n",
        "        # Reshape inputs into groups without changing the batch size\n",
        "        num_groups = batch_size // group_size\n",
        "        inputs = tf.reshape(inputs, [num_groups, group_size, input_dim])\n",
        "\n",
        "        # Merge group_size into the features dimension\n",
        "        inputs = tf.reshape(inputs, [batch_size // group_size, group_size * input_dim])\n",
        "\n",
        "        # Reshape to pairs of real and imaginary parts\n",
        "        inputs = tf.reshape(inputs, [batch_size // group_size, -1, 2])\n",
        "\n",
        "        # Define a function to process each sample\n",
        "        def process_sample(sample):\n",
        "            filtered_signal = self.upsample_and_filter(sample)\n",
        "            return filtered_signal\n",
        "\n",
        "        # Apply the function to each sample in the batch using tf.map_fn\n",
        "        output = tf.map_fn(process_sample, inputs, dtype=tf.float32)\n",
        "\n",
        "        # Reshape back to original batch size\n",
        "        output = tf.reshape(output, [batch_size // group_size, -1])\n",
        "\n",
        "        # Expand the output to match the original batch size\n",
        "        output = tf.tile(output, [group_size, 1])\n",
        "        print(output.shape)\n",
        "        batch_time_offset = self.time_offset()\n",
        "        # include slidcer to the model\n",
        "        k1 = self.r * 4 + (self.num_taps + 1) // 2\n",
        "        k2 = 2 * self.l * self.r * 4 + (self.num_taps - 1) // 2\n",
        "        seq_len = k2 - k1 + 1\n",
        "        print(f\"k1: {k1}, k2: {k2}, seq_len: {seq_len}\")\n",
        "        in_dim = output.shape[1]\n",
        "\n",
        "        output_1 = output[:, k1-1:k2]\n",
        "        output_2 = output[:, in_dim//2+k1-1:in_dim//2+k2]\n",
        "        print(output_1.shape)\n",
        "        print(output_2.shape)\n",
        "        output = tf.concat([output_1, output_2],axis = 1)\n",
        "        print(output.shape)\n",
        "        if return_offset:\n",
        "            # If we need to return the time offset (for training the offset estimator)\n",
        "            return output, batch_time_offset\n",
        "        else:\n",
        "            # If we're just passing through the autoencoder\n",
        "            return output\n",
        "        return output\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAZwtBRvdElo"
      },
      "source": [
        "## testing purpose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3krlFhrfdHgD"
      },
      "outputs": [],
      "source": [
        "small = Model(inputs = autoencoder_model[0].get_layer('Input').input, outputs = autoencoder_model[0].get_layer('normalization').output)\n",
        "test_1 = small.predict(train_dataset[:13*21],batch_size = 1)\n",
        "print(test_1.shape)\n",
        "print(\"-------------------------------------------------------------\")\n",
        "out_test = StochasticChannelv3_cts_tr(num_taps = 31,l=0)(test_1)\n",
        "print(out_test.shape)\n",
        "\n",
        "rx_model = Model(inputs = autoencoder_model[0].get_layer('noise').input, outputs = autoencoder_model[0].get_layer('Output').output)\n",
        "rx_model.summary()\n",
        "\n",
        "\n",
        "# out_test_reshaped = tf.reshape(out_test, [-1, 92])  # Adjust shape as needed\n",
        "# test_2 = rx_model.predict(out_test_reshaped, batch_size=1)\n",
        "# print(test_2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1ktXY7sE33-"
      },
      "outputs": [],
      "source": [
        "class rx:\n",
        "    def __init__(self, train_data=train_dataset, test_data=test_dataset, input_dim=K, enc_dim=N, act_fun='tanh'):\n",
        "        self.train_data = train_data\n",
        "        self.test_data = test_data\n",
        "        self.input_dim = input_dim\n",
        "        self.enc_dim = enc_dim\n",
        "        self.act_fun = act_fun\n",
        "\n",
        "    def AE_implement(self):\n",
        "        autoencoder = Sequential([\n",
        "\n",
        "            # NormalizedRRCFilterLayer( ),\n",
        "            CustomNoise(name = 'noise'),\n",
        "\n",
        "            # Decoder layers\n",
        "            Dense(self.enc_dim * 4, activation=self.act_fun, name=\"decoder1\"),\n",
        "            Dense(2**(self.input_dim), activation=self.act_fun, name='decoder2'),\n",
        "            Dense(2**(self.input_dim), activation='softmax', name='Output')\n",
        "        ])\n",
        "\n",
        "        autoencoder.compile(optimizer=Adam(learning_rate=1e-2), loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "        return autoencoder\n",
        "\n",
        "    def train(self, epochs=20, batch_size=64):\n",
        "        autoencoder = self.AE_implement()\n",
        "        # autoencoder.fit(self.train_data, self.train_data,\n",
        "        #                 epochs=epochs, batch_size=batch_size,\n",
        "        #                 validation_data=(self.test_data, self.test_data))\n",
        "        # # return autoencoder\n",
        "\n",
        "        # TensorBoard setup\n",
        "        log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "        tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "        print(self.test_data.shape)\n",
        "\n",
        "        history = autoencoder.fit(self.train_data, self.train_data,\n",
        "                                  epochs=epochs, batch_size=1*13,\n",
        "                                  validation_data=(self.test_data, self.test_data),\n",
        "                                  callbacks=[PlottingCallback(), tensorboard_callback])\n",
        "        return autoencoder, history\n",
        "\n",
        "rx_model = rx(train_data=out_test, test_data=test_dataset[:13*13], input_dim=K, enc_dim=N, act_fun='relu')\n",
        "rxc,_ = rx_model.train(epochs=5, batch_size=13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fw7MO6Mkp3xZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Example tensors (1D tensors with d elements)\n",
        "tensor1 = tf.constant([1.0, 2.0, 3.0, 4.0])\n",
        "tensor2 = tf.constant([5.0, 6.0, 7.0, 8.0])\n",
        "\n",
        "# Concatenate along the last axis to get a 1D tensor with size 2d\n",
        "concatenated_tensor = tf.concat([tensor1, tensor2], axis=0)\n",
        "\n",
        "# Reshape to a 1x(2d) tensor\n",
        "concatenated_tensor_reshaped = tf.reshape(concatenated_tensor, [1, -1])\n",
        "\n",
        "print(\"Concatenated 1x(2d) tensor:\")\n",
        "print(concatenated_tensor_reshaped)\n",
        "print(f\"Shape of concatenated tensor: {concatenated_tensor_reshaped.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZJqa7ji7qo0"
      },
      "outputs": [],
      "source": [
        "print(type(v_out[0]))\n",
        "v = tf.reshape(v_out[0], [-1, 2])\n",
        "print(v.shape)\n",
        "# Assuming v_out is a NumPy array or a Tensor that can be converted to a NumPy array\n",
        "# Convert TensorFlow tensor to NumPy array if necessary\n",
        "v_out_np = v.numpy() if isinstance(v, tf.Tensor) else v\n",
        "\n",
        "# Plot the signal\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# If v_out[0] has both real and imaginary parts, plot them separately\n",
        "if v_out_np.ndim == 2 and v_out_np.shape[1] == 2:  # Shape (num_samples, 2)\n",
        "    plt.plot(v_out_np[:, 0], label='Real Part')\n",
        "    plt.plot(v_out_np[:, 1], label='Imaginary Part')\n",
        "    plt.legend()\n",
        "else:\n",
        "    # If it's 1D, just plot the signal\n",
        "    plt.plot(v_out_np)\n",
        "\n",
        "plt.title(\"Plot of v_out[0]\")\n",
        "plt.xlabel(\"Sample Index\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6ZEdfDsI6gI"
      },
      "source": [
        "# slicer operation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyqLgn-JwBwr"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class Slicer(tf.keras.layers.Layer):\n",
        "    def __init__(self, output_dim=12, l=6, rate=4, n=4, L=31):\n",
        "        super(Slicer, self).__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.l = l\n",
        "        self.rate = rate\n",
        "        self.n = n\n",
        "        self.L = L  # number of taps\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Ensure inputs are complex or structured in real-imaginary pairs\n",
        "        # if tf.is_tensor(inputs):\n",
        "            # Get batch size dynamically\n",
        "            batch_size = tf.shape(inputs)[0]\n",
        "\n",
        "            # Define k1, k2, seq_len based on your parameters\n",
        "            k1 = self.rate * self.n + (self.L + 1) // 2\n",
        "            k2 = 2 * self.l * self.rate * self.n + (self.L - 1) // 2\n",
        "            seq_len = k2 - k1 + 1\n",
        "            print(f\"k1: {k1}, k2: {k2}, seq_len: {seq_len}\")\n",
        "\n",
        "\n",
        "\n",
        "            # Print the shape or value of sliced output for debugging\n",
        "            print(f\"Sliced output shape: {sliced_output.shape}\")\n",
        "            print(f\"Sample sliced output[0]: {sliced_output[0]}\")\n",
        "\n",
        "            return sliced_output\n",
        "\n",
        "\n",
        "v = Slicer(test_dataset)\n",
        "print(v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qR0RdF7zI9Xx"
      },
      "outputs": [],
      "source": [
        "slice_input = v_out\n",
        "slice_input = tf.reshape(slice_input, [slice_input.shape[0], slice_input.shape[2]*2])\n",
        "print(slice_input.shape)\n",
        "rate = 4\n",
        "n = 4\n",
        "L = 31\n",
        "l =  6\n",
        "def slicer(inp):\n",
        "  inp = tf.reshape(inp, [-1, inp.shape[1]*2])\n",
        "  k1 = rate*n + (L+1)//2\n",
        "  k2 = 2*l*rate*n + (L-1)//2\n",
        "  seq_len = k2 - k1 +1\n",
        "  print(k1,k2,seq_len)\n",
        "  print(inp.shape[0])\n",
        "  out = []\n",
        "  for i in range(1,inp.shape[0]//seq_len):\n",
        "    sliced = inp[(i-1)*seq_len:i*seq_len, :]\n",
        "\n",
        "    out.append(sliced)\n",
        "  return out\n",
        "\n",
        "slice_out = slicer(slice_input)\n",
        "tensor_stack = tf.stack(slice_out[1:],axis =0)\n",
        "print(slice_input.shape)\n",
        "print(tensor_stack.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zpkh3cKCxQzL"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class StochasticChannel(tf.keras.layers.Layer):\n",
        "    def __init__(self, roll_off=0.35, num_taps=101, time_delay=0, rate=1, **kwargs):\n",
        "        super(StochasticChannel, self).__init__(**kwargs)\n",
        "        self.num_taps = num_taps\n",
        "        self.time_delay = time_delay\n",
        "        self.rate = rate\n",
        "        self.roll_off = roll_off\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Call the real_to_complex_tensor method and return the result\n",
        "        return self.real_to_complex_tensor(inputs)\n",
        "\n",
        "# Assuming `enc` is your input tensor\n",
        "stochastic_channel = StochasticChannel(rate=2, roll_off=0.35, num_taps=101)\n",
        "y = real_to_complex_tensor(test_dataset)\n",
        "print((y))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rM2qUxDbNTUW"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-commpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCLx5dvYNOKQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from commpy.filters import rrcosfilter\n",
        "from scipy.signal import convolve\n",
        "\n",
        "# Define parameters for the RRC filter\n",
        "alpha = 0.35  # Roll-off factor\n",
        "sps = 8       # Samples per symbol (oversampling factor)\n",
        "num_taps = 101  # Number of filter taps (should be odd)\n",
        "Ts = 1        # Symbol period\n",
        "\n",
        "# Generate the RRC filter\n",
        "taps, t = rrcosfilter(num_taps, alpha, Ts, sps)\n",
        "\n",
        "# Generate a random signal with shape (5120, 8) or use your signal here\n",
        "signal = np.random.randn(5120, 8)  # Example: random signal\n",
        "\n",
        "# Initialize a matrix to hold the filtered signal output\n",
        "filtered_signal = np.zeros((signal.shape[0], signal.shape[1]+ num_taps - 1))\n",
        "\n",
        "# Apply the RRC filter to each column (i.e., each signal channel)\n",
        "for i in range(signal.shape[0]):\n",
        "    filtered_signal[i,:] = convolve(signal[i,:], taps, mode='full')\n",
        "\n",
        "# Check the dimensions of the filtered signal\n",
        "print(f\"Input signal shape: {signal.shape}\")\n",
        "print(f\"Filtered signal shape: {filtered_signal.shape}\")\n",
        "print(f\"Expected shape: {(signal.shape[0] , signal.shape[1]+ len(taps) - 1)}\")\n",
        "\n",
        "# Plotting the first column of the filtered signal for visualization\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(filtered_signal[:,0])\n",
        "plt.title(\"Filtered Signal (Column 1) - Full Convolution with RRC Filter\")\n",
        "plt.xlabel(\"Samples\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWssqDE2aidM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from scipy.signal import convolve\n",
        "from commpy.filters import rrcosfilter\n",
        "\n",
        "import tensorflow as tf\n",
        "from commpy.filters import rrcosfilter\n",
        "\n",
        "class NormalizedRRCFilterLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, alpha=0.35, sps=1, num_taps=101, ts=1, upsample_factor=4):\n",
        "        \"\"\"\n",
        "        Initialize the layer with RRC filter parameters and upsampling factor.\n",
        "\n",
        "        Args:\n",
        "            alpha: Roll-off factor (0 <= alpha <= 1).\n",
        "            sps: Samples per symbol (upsampling factor).\n",
        "            num_taps: Number of filter taps (should be odd).\n",
        "            ts: Sampling period (default is 1).\n",
        "            upsample_factor: The factor by which to upsample the input signals.\n",
        "        \"\"\"\n",
        "        super(NormalizedRRCFilterLayer, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.sps = sps\n",
        "        self.num_taps = num_taps\n",
        "        self.ts = ts\n",
        "        self.upsample_factor = upsample_factor\n",
        "\n",
        "        # Create the RRC filter when the layer is initialized\n",
        "        self.rrc_taps, _ = self.create_rrc_filter()\n",
        "\n",
        "    def create_rrc_filter(self):\n",
        "        \"\"\"Generate the RRC filter coefficients using commpy.\"\"\"\n",
        "        taps, _ = rrcosfilter(self.num_taps, self.alpha, self.ts, self.sps)\n",
        "        taps = tf.convert_to_tensor(taps, dtype=tf.float32)\n",
        "        return taps, _\n",
        "\n",
        "    def upsample(self, input_tensor):\n",
        "        \"\"\"Upsample the input tensor by inserting r-1 zeros between each element.\"\"\"\n",
        "        input_shape = tf.shape(input_tensor)\n",
        "        expanded_input = tf.expand_dims(input_tensor, axis=-1)  # Add an extra dimension\n",
        "\n",
        "        # Create a tensor of zeros with the same shape as input, but r times the last dimension\n",
        "        zero_padding = tf.zeros_like(expanded_input)\n",
        "        zero_padding = tf.tile(zero_padding, [1, 1, self.upsample_factor-1])  # Repeat the zeros r-1 times\n",
        "\n",
        "        # Concatenate input and zero_padding along the last dimension\n",
        "        upsampled = tf.concat([expanded_input, zero_padding], axis=-1)\n",
        "\n",
        "        # Reshape to flatten the added dimension\n",
        "        new_shape = [input_shape[0], input_shape[1] * self.upsample_factor]\n",
        "        upsampled_flat = tf.reshape(upsampled, new_shape)\n",
        "        return upsampled_flat\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"Forward pass for the layer, converting real to complex and applying RRC filter.\"\"\"\n",
        "        batch_size = tf.shape(inputs)[0]  # Batch size\n",
        "        inner_dim = tf.shape(inputs)[1]   # Inner dimension size\n",
        "        print( inner_dim, batch_size)\n",
        "        # Ensure that the inner dimension is even\n",
        "        # assert inner_dim % 2 == 0, \"Inner dimension must be even for real and imaginary pairs.\"\n",
        "\n",
        "        # Reshape the input tensor to separate real and imaginary parts\n",
        "        reshaped_tensor = tf.reshape(inputs, [batch_size, inner_dim // 2, 2])\n",
        "\n",
        "        # Extract real and imaginary parts\n",
        "        real_part = reshaped_tensor[:, :, 0]\n",
        "        imag_part = reshaped_tensor[:, :, 1]\n",
        "\n",
        "        # Upsample real and imaginary parts\n",
        "        real_part = self.upsample(real_part)\n",
        "        imag_part = self.upsample(imag_part)\n",
        "\n",
        "        # Reshape taps for 1D convolution\n",
        "        rrc_taps = tf.reshape(self.rrc_taps, [-1, 1, 1])  # Shape: (filter_length, 1, 1)\n",
        "\n",
        "        # Add an extra dimension to real and imaginary parts for conv1d\n",
        "        real_part = tf.expand_dims(real_part, axis=-1)\n",
        "        imag_part = tf.expand_dims(imag_part, axis=-1)\n",
        "\n",
        "        # Apply the RRC filter using TensorFlow's conv1d\n",
        "        real_filtered = tf.nn.conv1d( rrc_taps,real_part, stride=1, padding='VALID')\n",
        "        imag_filtered = tf.nn.conv1d( rrc_taps,imag_part, stride=1, padding='VALID')\n",
        "\n",
        "        # Remove the extra dimension\n",
        "        real_filtered = tf.squeeze(real_filtered, axis=-1)\n",
        "        imag_filtered = tf.squeeze(imag_filtered, axis=-1)\n",
        "\n",
        "        # Interleave real and imaginary parts\n",
        "        interleaved = tf.stack([real_filtered, imag_filtered], axis=-1)  # Shape: (batch_size, time_length, 2)\n",
        "        interleaved = tf.reshape(interleaved, [batch_size, -1])  # Flatten to (batch_size, time_length*2)\n",
        "\n",
        "        return interleaved\n",
        "\n",
        "\n",
        "class NormalizedRRCFilterLayer_v2(tf.keras.layers.Layer):\n",
        "    def __init__(self, alpha=0.35, sps=1, num_taps=101, ts=1, upsample_factor=4):\n",
        "        \"\"\"\n",
        "        Initialize the layer with RRC filter parameters and upsampling factor.\n",
        "\n",
        "        Args:\n",
        "            alpha: Roll-off factor (0 <= alpha <= 1).\n",
        "            sps: Samples per symbol (upsampling factor).\n",
        "            num_taps: Number of filter taps (should be odd).\n",
        "            ts: Sampling period (default is 1).\n",
        "            upsample_factor: The factor by which to upsample the input signals.\n",
        "        \"\"\"\n",
        "        super(NormalizedRRCFilterLayer_v2, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.sps = sps\n",
        "        self.num_taps = num_taps\n",
        "        self.ts = ts\n",
        "        self.upsample_factor = upsample_factor\n",
        "\n",
        "        # Create the RRC filter when the layer is initialized\n",
        "        self.rrc_taps, _ = self.create_rrc_filter()\n",
        "\n",
        "    def create_rrc_filter(self):\n",
        "        \"\"\"Generate the RRC filter coefficients using commpy.\"\"\"\n",
        "        taps, _ = rrcosfilter(self.num_taps, self.alpha, self.ts, self.sps)\n",
        "        return taps, _\n",
        "\n",
        "    def upsample(self, input_tensor):\n",
        "        \"\"\"Upsample the input tensor by inserting r-1 zeros between each element.\"\"\"\n",
        "        input_shape = tf.shape(input_tensor)\n",
        "        expanded_input = tf.expand_dims(input_tensor, axis=-1)  # Add an extra dimension\n",
        "\n",
        "        # Create a tensor of zeros with the same shape as input, but r times the last dimension\n",
        "        zero_padding = tf.zeros_like(expanded_input)\n",
        "        zero_padding = tf.tile(zero_padding, [1, 1, self.upsample_factor-1])  # Repeat the zeros r-1 times\n",
        "\n",
        "        # Concatenate input and zero_padding along the last dimension\n",
        "        upsampled = tf.concat([expanded_input, zero_padding], axis=-1)\n",
        "\n",
        "        # Reshape to flatten the added dimension\n",
        "        new_shape = [input_shape[0], input_shape[1] * self.upsample_factor]\n",
        "        upsampled_flat = tf.reshape(upsampled, new_shape)\n",
        "        return upsampled_flat\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"Forward pass for the layer, converting real to complex and applying RRC filter.\"\"\"\n",
        "        batch_size = tf.shape(inputs)[0]  # Batch size\n",
        "        inner_dim = tf.shape(inputs)[1]   # Inner dimension size\n",
        "        print( inner_dim, batch_size)\n",
        "        # Ensure that the inner dimension is even\n",
        "        # assert inner_dim % 2 == 0, \"Inner dimension must be even for real and imaginary pairs.\"\n",
        "\n",
        "        # Reshape the input tensor to separate real and imaginary parts\n",
        "        reshaped_tensor = tf.reshape(inputs, [batch_size, inner_dim // 2, 2])\n",
        "\n",
        "        # Extract real and imaginary parts\n",
        "        real_part = reshaped_tensor[:, :, 0]\n",
        "        imag_part = reshaped_tensor[:, :, 1]\n",
        "\n",
        "        # Upsample real and imaginary parts\n",
        "        real_part = self.upsample(real_part)\n",
        "        imag_part = self.upsample(imag_part)\n",
        "\n",
        "        # Convert tensors to NumPy arrays for filtering\n",
        "        real_part_np = real_part.numpy()\n",
        "        imag_part_np = imag_part.numpy()\n",
        "\n",
        "        # Apply the RRC filter using scipy's convolve\n",
        "        real_filtered_np = np.array([convolve(real_part_np[i], self.rrc_taps, mode='full') for i in range(real_part_np.shape[0])])\n",
        "        imag_filtered_np = np.array([convolve(imag_part_np[i], self.rrc_taps, mode='full') for i in range(imag_part_np.shape[0])])\n",
        "\n",
        "        # Convert the filtered signals back to TensorFlow tensors\n",
        "        real_filtered = tf.convert_to_tensor(real_filtered_np, dtype=tf.float32)\n",
        "        imag_filtered = tf.convert_to_tensor(imag_filtered_np, dtype=tf.float32)\n",
        "\n",
        "        # Interleave real and imaginary parts\n",
        "        interleaved = tf.stack([real_filtered, imag_filtered], axis=-1)  # Shape: (batch_size, time_length, 2)\n",
        "        interleaved = tf.reshape(interleaved, [batch_size, -1])  # Flatten to (batch_size, time_length*2)\n",
        "\n",
        "        return interleaved\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUBOznL2kLi8"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Initialize the RRC filter layer\n",
        "normalized_rrc_layer = NormalizedRRCFilterLayer_v2()\n",
        "enc = before_channel(train_dataset)\n",
        "# Apply the layer to the test input\n",
        "output = normalized_rrc_layer(enc)\n",
        "\n",
        "# Check the output shape and print it\n",
        "print(\"Output shape:\", output.shape)\n",
        "# Plotting the first column of the filtered signal for visualization\n",
        "plt.figure(figsize=(6, 2))\n",
        "plt.plot(enc[10,:])\n",
        "plt.title(\"Input Signal\")\n",
        "plt.xlabel(\"Samples\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "# Plotting the first column of the filtered signal for visualization\n",
        "plt.figure(figsize=(6, 2))\n",
        "plt.plot(output[10,:])\n",
        "plt.title(\"Filtered Signal (Column 1) - Full Convolution with RRC Filter\")\n",
        "plt.xlabel(\"Samples\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awqTKieORLvu"
      },
      "source": [
        "# offset estimation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePgBiBPkUGH-"
      },
      "outputs": [],
      "source": [
        "# Initializing parameters\n",
        "k = 8\n",
        "NUM_CHANNEL_USES = 4\n",
        "\n",
        "sampling_factor = 4 # r\n",
        "N_msg = 2*NUM_CHANNEL_USES*sampling_factor  # complex numbers converted into real\n",
        "l = 6\n",
        "N_seq =(2*l-1)*N_msg\n",
        "frame_size = 100*N_msg\n",
        "q = 1   # strides = 1 (considered all values as real -> moving half of a complex number)\n",
        "\n",
        "block_size = 32    # num of messages for frames we use, out of this, we use 1/4 as pilots and 3/4 as messages\n",
        "n_blocks_train = 10**4  ################\n",
        "n_blocks_val = 10**3\n",
        "\n",
        "n_train = block_size * n_blocks_train\n",
        "n_val   = block_size * n_blocks_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fskqoITUJc1"
      },
      "outputs": [],
      "source": [
        "def create_2d_array(arr, window_size, stride):\n",
        "    num_windows = (len(arr) - window_size) // stride + 1\n",
        "    shape = (num_windows, window_size)\n",
        "    strides = (arr.strides[0] * stride, arr.strides[0])\n",
        "    return np.lib.stride_tricks.as_strided(arr, shape=shape, strides=strides)\n",
        "\n",
        "arr = np.array([1,2,3,4,5,6,7,8,9,10])\n",
        "window_size = 7\n",
        "stride = 1\n",
        "\n",
        "result = create_2d_array(arr, window_size, stride)\n",
        "print(result)\n",
        "\n",
        "def create_2d_array_tf(arr, window_size, stride):\n",
        "    num_windows = (arr.shape[0] - window_size) // stride + 1\n",
        "    windows = []\n",
        "    for i in range(num_windows):\n",
        "        window = arr[i * stride:i * stride + window_size]\n",
        "        windows.append(window)\n",
        "    return tf.stack(windows)\n",
        "\n",
        "arr = tf.constant([1,2,3,4,5,6,7,8,9,10], dtype=tf.int32)\n",
        "window_size = 7\n",
        "stride = 1\n",
        "\n",
        "result = create_2d_array_tf(arr, window_size, stride)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYVK7gU7L0lK"
      },
      "source": [
        "## possible ways of training\n",
        "end to end training for OE.\n",
        "\n",
        "training OE in isolated fashion:input will be output of transmitter of autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1EISZr4L_Wm"
      },
      "outputs": [],
      "source": [
        "out = autoencoder_model[0].get_layer('stc').output\n",
        "oe = OE_model.train()\n",
        "print(out.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pap1uh3kSaIm"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras import metrics\n",
        "\n",
        "class OffsetEstimator(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.OE = Sequential([\n",
        "            Input(shape=(N_seq,), name='OE_input'),\n",
        "            Dense(256, activation='relu', name='dense_layer_1'),\n",
        "            Dense(256, activation='relu', name='dense_layer_2'),\n",
        "            Dense(256, activation='relu', name='dense_layer_3'),\n",
        "            Dense(N_msg, activation='softmax', name='dense_layer_4'),\n",
        "        ])\n",
        "        self.loss_tracker = metrics.Mean(name=\"loss\")\n",
        "        self.mae_metric = metrics.MeanAbsoluteError(name=\"mae\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        tau_vec_matrix = self.OE(inputs, training=False)\n",
        "        print(tau_vec_matrix)\n",
        "        tau_sum_vec = tf.reduce_sum(circular_shift(tau_vec_matrix), axis=0) / tf.cast(tf.shape(tau_vec_matrix)[0], tf.float32)\n",
        "        print(tau_sum_vec)\n",
        "        r = tf.math.argmax(tau_sum_vec, axis=0)\n",
        "        i = tf.cast(r, tf.float32) - 1 - N_msg*(tf.math.floor((tf.cast(r, tf.float32) - 1) / (N_msg / 2)))\n",
        "        return i\n",
        "\n",
        "    def compile(self, optimizer):\n",
        "        super().compile()\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "    def train_step(self, data):\n",
        "        inputs, frame_offset = data\n",
        "        with tf.GradientTape() as tape:\n",
        "            tau_vec_matrix = self.OE(inputs, training=True)\n",
        "            tau_sum_vec = tf.reduce_sum(circular_shift(tau_vec_matrix), axis=0) / tf.cast(tf.shape(tau_vec_matrix)[0], tf.float32)\n",
        "            r = tf.math.argmax(tau_sum_vec, axis=0)\n",
        "            i = tf.cast(r, tf.float32) - 1 - tf.math.floor((tf.cast(r, tf.float32) - 1) / (N_msg / 2))\n",
        "            # Convert frame_offset to float32 for consistency\n",
        "            frame_offset = tf.cast(frame_offset, tf.float32)\n",
        "            loss = tf.keras.losses.mean_squared_error(frame_offset, i)\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        self.mae_metric.update_state(i, frame_offset)\n",
        "        return {\"loss\": self.loss_tracker.result(), \"mae\": self.mae_metric.result()}\n",
        "\n",
        "    # def test_step(self, data):\n",
        "    #     inputs, frame_offset = data\n",
        "    #     tau_vec_matrix = self.OE(inputs, training=False)\n",
        "    #     tau_sum_vec = tf.reduce_sum(circular_shift(tau_vec_matrix), axis=0) / tf.cast(tf.shape(tau_vec_matrix)[0], tf.float32)\n",
        "    #     r = tf.math.argmax(tau_sum_vec, axis=0)\n",
        "    #     i = tf.cast(r, tf.float32) - 1 - tf.math.floor((tf.cast(r, tf.float32) - 1) / (N_msg / 2))\n",
        "    #     frame_offset = tf.cast(frame_offset, tf.float32)\n",
        "    #     loss = tf.keras.losses.mean_squared_error(frame_offset, i)\n",
        "    #     self.loss_tracker.update_state(loss)\n",
        "    #     self.mae_metric.update_state(i, frame_offset)\n",
        "    #     return {\"loss\": self.loss_tracker.result(), \"mae\": self.mae_metric.result()}\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.loss_tracker, self.mae_metric]\n",
        "\n",
        "# Define the circular_shift function\n",
        "def circular_shift(tensor):\n",
        "    shape = tensor.shape\n",
        "    rows = shape[0]\n",
        "    shifted_tensor = tf.stack([tf.roll(tensor[i, :], shift=i, axis=0) for i in range(rows)])\n",
        "    return shifted_tensor\n",
        "\n",
        "# Initialize the OffsetEstimator model\n",
        "OE_model = OffsetEstimator()\n",
        "OE_model.compile(optimizer=tf.keras.optimizers.Adam())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "6v0fprAabUXe"
      },
      "outputs": [],
      "source": [
        "def get_frame_offset(frame):\n",
        "    frame = np.array(frame, dtype=np.float32)  # Ensure data type consistency\n",
        "    seq_matrix = create_2d_array(frame, N_seq, q)\n",
        "    seq_matrix_tf = tf.constant(seq_matrix, dtype=tf.float32)\n",
        "    i_b = OE_model(seq_matrix_tf)  # Frame offset index value\n",
        "    return i_b\n",
        "\n",
        "# Example frame (replace with actual data)\n",
        "frame = np.random.rand(frame_size).astype(np.float32)  # Ensure data type consistency\n",
        "\n",
        "# Get the frame offset\n",
        "i_b = get_frame_offset(frame)\n",
        "\n",
        "print(\"Estimated Frame Offset:\", i_b.numpy())  # Convert tensor to numpy for printing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0z_eeHuOUtRJ"
      },
      "outputs": [],
      "source": [
        "class FE_PE(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Feature Extractor: Takes an input of size (N_msg * N_seq)\n",
        "        self.feature_extractor = Sequential([\n",
        "            Input(shape=(N_msg * N_seq,), name='feature_extractor_input'),\n",
        "            Dense(8, activation='linear', name='feature_extract')\n",
        "        ])\n",
        "\n",
        "        # Phase Estimator: Takes the same input, but could eventually use the extracted features\n",
        "        self.phase_estimator = Sequential([\n",
        "            Input(shape=(N_msg * N_seq,), name='phase_estimator_input'),\n",
        "            Dense(2, activation='linear', name='phase_estimator')\n",
        "        ])\n",
        "\n",
        "        # Define loss tracker and MAE for metrics\n",
        "        self.loss_tracker = metrics.Mean(name=\"loss\")\n",
        "        self.mae_metric = metrics.MeanAbsoluteError(name=\"mae\")\n",
        "    def complex_to_real_tensor(inp_tensor):\n",
        "        # Debugging: Print the input shape\n",
        "        print(f\"Input tensor shape: {inp_tensor.shape}\")\n",
        "        # Ensure that the input tensor is of shape [2, n]\n",
        "        assert inp_tensor.shape[0] == 2, \"The first dimension must be 2 (real and imaginary parts).\"\n",
        "\n",
        "        # Get real part (first row) and imaginary part (second row)\n",
        "        real_part = inp_tensor[0, :]  # Shape: [n]\n",
        "        imag_part = inp_tensor[1, :]  # Shape: [n]\n",
        "\n",
        "        # Stack real and imaginary parts together and interleave them\n",
        "        combined = tf.stack([real_part, imag_part], axis=-1)  # Shape: [n, 2]\n",
        "\n",
        "        # Reshape to interleave the real and imaginary parts into one dimension\n",
        "        interleaved = tf.reshape(combined, [-1])  # Shape: [2*n], interleaving real and imaginary\n",
        "\n",
        "        return interleaved\n",
        "    def call(self, inputs):\n",
        "        # Forward pass: First extract features, then estimate phase\n",
        "        # inputs = complex_to_real_tensor(inputs)\n",
        "        features = self.feature_extractor(inputs)\n",
        "        # features = real_to_complex_tensor(features)\n",
        "        phase_estimation = self.phase_estimator(inputs)\n",
        "        # phase_estimation = real_to_complex_tensor(phase_estimation)\n",
        "        return features, phase_estimation\n",
        "\n",
        "    def compile(self, optimizer):\n",
        "        super().compile()\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # Custom training loop: inputs, true phase values\n",
        "        inputs, true_phase = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass\n",
        "            features, predicted_phase = self(inputs)\n",
        "\n",
        "            # Calculate loss (using Mean Squared Error for phase estimation)\n",
        "            true_phase = tf.cast(true_phase, tf.float32)\n",
        "            loss = tf.keras.losses.mean_squared_error(true_phase, predicted_phase)\n",
        "\n",
        "        # Compute gradients and apply them\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "\n",
        "        # Update loss and MAE metrics\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        self.mae_metric.update_state(predicted_phase, true_phase)\n",
        "\n",
        "        return {\"loss\": self.loss_tracker.result(), \"mae\": self.mae_metric.result()}\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        # Return the metrics for tracking\n",
        "        return [self.loss_tracker, self.mae_metric]\n",
        "\n",
        "# Initialize model\n",
        "FE_PE_model = FE_PE()\n",
        "FE_PE_model.compile(optimizer=tf.keras.optimizers.Adam())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyyTaRAzFEr3"
      },
      "outputs": [],
      "source": [
        "autoencoder_model[0].summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "VogvmitwGQWU"
      },
      "outputs": [],
      "source": [
        "input_layer = autoencoder_model[0].get_layer('Input')\n",
        "before_channel = Model(inputs=input_layer.input,  # Use KerasTensor as input\n",
        "                       outputs=autoencoder_model[0].get_layer('stc').output)\n",
        "enc = before_channel(test_dataset)\n",
        "print(enc.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WlyGvxcObA2"
      },
      "source": [
        "# phase and feature extractor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mldrE9BHOg_7"
      },
      "outputs": [],
      "source": [
        "class SD(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self,l=6,n=4,r=4,**kwargs):\n",
        "       super(SD, self).__init__(**kwargs)\n",
        "       self.l = l\n",
        "       self.n = n\n",
        "       self.r = r\n",
        "       with tf.name_scope(\" fe\"):\n",
        "          self.fe = Sequential([\n",
        "              Dense(256, activation='relu', name='initial'),\n",
        "              Dense(8, activation='linear', name='feature extractor')\n",
        "          ]\n",
        "        )\n",
        "       with tf.name_scope(\" pe\"):\n",
        "          self.pe = Sequential([\n",
        "              Dense(256, activation='relu', name='initial'),\n",
        "              Dense(2, activation='linear', name='phase_estimator')\n",
        "          ]\n",
        "        )\n",
        "          return pe\n",
        "\n",
        "    # def fe(self):\n",
        "    #   fe = Sequential([\n",
        "    #       Dense(256, activation='relu', name='initial'),\n",
        "    #       Dense(8, activation='linear', name='feature extractor')\n",
        "    #   ]\n",
        "    #   )\n",
        "\n",
        "    #   # fe.compile(optimizer=Adam(learning_rate=1e-2), loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "    #   return fe\n",
        "\n",
        "    # def pe(self):\n",
        "    #   pe = Sequential([\n",
        "    #       Dense(256, activation='relu', name='initial'),\n",
        "    #       Dense(2, activation='linear', name='phase_estimator')\n",
        "    #   ]\n",
        "    #   )\n",
        "\n",
        "      # pe.compile(optimizer=Adam(learning_rate=1e-2), loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "\n",
        "    def mini_slicer(self, inputs):\n",
        "      in_dim = tf.shape(inputs)[1]\n",
        "      N_msg = self.r*self.n\n",
        "      l1 = 1+ (self.l-1)*N_msg - self.r\n",
        "      l2 = self.l*N_msg+self.r\n",
        "      out_1= inputs[:,l1-1:l2]\n",
        "      out_2 = inputs[:,in_dim//2+l1-1:in_dim//2+l2]\n",
        "      output = tf.concat([out_1,out_2], axis = 1)\n",
        "      print('mini slice output shape', output.shape)\n",
        "      return output\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Get the input dimension (before slicing)\n",
        "        in_dim = inputs.shape[1]\n",
        "\n",
        "        # Create feature extractor and phase estimator models\n",
        "        with tf.name_scope(\"fe\"):\n",
        "            feature_extract_model = self.fe()\n",
        "        with tf.name_scope(\"pe\"):\n",
        "            phase_estimate_model = self.pe()\n",
        "\n",
        "        # Process the inputs using mini_slicer (this changes the shape of inputs)\n",
        "        inputs = self.mini_slicer(inputs)\n",
        "\n",
        "        # Update real and imag slices based on new input shape (after mini_slicer)\n",
        "        half_dim = tf.shape(inputs)[1] // 2  # Get new half dimension after slicing\n",
        "        real = inputs[:, :half_dim]  # First half of sliced inputs as real part (batch_size, 48)\n",
        "        imag = inputs[:, half_dim:]  # Second half as imaginary part (batch_size, 48)\n",
        "\n",
        "        # Pass the sliced inputs to the phase estimator model to get h\n",
        "        h = phase_estimate_model(inputs)  # h has shape (batch_size, 2)\n",
        "        h_real = h[:, 0]  # Extract real part of h\n",
        "        h_imag = h[:, 1]  # Extract imaginary part of h\n",
        "\n",
        "        h_real = tf.expand_dims(h_real, axis=1)\n",
        "        h_imag = tf.expand_dims(h_imag, axis=1)\n",
        "        # Perform element-wise multiplication\n",
        "        h_real_ex = tf.tile(h_real, [1, half_dim])\n",
        "        h_imag_ex = tf.tile(h_imag, [1, half_dim])\n",
        "        real_mul = real * h_real_ex   #multiply same value of real part to every component of the input\n",
        "        imag_mul = imag * h_imag_ex\n",
        "        print(h_real_ex[0])\n",
        "        # Apply the feature extractor model to real_mul (as an example)\n",
        "        feature_extract_output = feature_extract_model(inputs)\n",
        "\n",
        "        output = tf.concat([real_mul, imag_mul, feature_extract_output], axis=1)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFG9mTC-_Nn1"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "class SD(tf.keras.layers.Layer):\n",
        "    def __init__(self, l=6, n=4, r=4, **kwargs):\n",
        "        super(SD, self).__init__(**kwargs)\n",
        "        self.l = l\n",
        "        self.n = n\n",
        "        self.r = r\n",
        "\n",
        "        with tf.name_scope(\"fe\"):\n",
        "            self.fe = Sequential([\n",
        "                Dense(256, activation='relu', name='initial'),\n",
        "                Dense(8, activation='linear', name='feature_extractor')\n",
        "            ])\n",
        "\n",
        "        with tf.name_scope(\"pe\"):\n",
        "            self.pe = Sequential([\n",
        "                Dense(256, activation='relu', name='initial'),\n",
        "                Dense(2, activation='linear', name='phase_estimator')\n",
        "            ])\n",
        "\n",
        "    def mini_slicer(self, inputs):\n",
        "        in_dim = tf.shape(inputs)[1]\n",
        "        N_msg = self.r * self.n\n",
        "        l1 = 1 + (self.l - 1) * N_msg - self.r\n",
        "        l2 = self.l * N_msg + self.r\n",
        "        out_1 = inputs[:, l1-1:l2]\n",
        "        out_2 = inputs[:, in_dim // 2 + l1-1:in_dim // 2 + l2]\n",
        "        output = tf.concat([out_1, out_2], axis=1)\n",
        "        print('mini slice output shape', output.shape)\n",
        "        return output\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Get the input dimension (before slicing)\n",
        "        in_dim = inputs.shape[1]\n",
        "\n",
        "        # Process the inputs using mini_slicer (this changes the shape of inputs)\n",
        "        inputs = self.mini_slicer(inputs)\n",
        "\n",
        "        # Update real and imag slices based on new input shape (after mini_slicer)\n",
        "        half_dim = tf.shape(inputs)[1] // 2  # Get new half dimension after slicing\n",
        "        real = inputs[:, :half_dim]  # First half of sliced inputs as real part\n",
        "        imag = inputs[:, half_dim:]  # Second half as imaginary part\n",
        "\n",
        "        # Pass the sliced inputs to the phase estimator model to get h\n",
        "        h = self.pe(inputs)  # h has shape (batch_size, 2)\n",
        "        h_real = h[:, 0]  # Extract real part of h\n",
        "        h_imag = h[:, 1]  # Extract imaginary part of h\n",
        "\n",
        "        h_real = tf.expand_dims(h_real, axis=1)\n",
        "        h_imag = tf.expand_dims(h_imag, axis=1)\n",
        "\n",
        "        # Perform element-wise multiplication\n",
        "        h_real_ex = tf.tile(h_real, [1, half_dim])\n",
        "        h_imag_ex = tf.tile(h_imag, [1, half_dim])\n",
        "        real_mul = real * h_real_ex  # Multiply same value of real part to every component of the input\n",
        "        imag_mul = imag * h_imag_ex\n",
        "\n",
        "        # Apply the feature extractor model to real_mul (as an example)\n",
        "        feature_extract_output = self.fe(inputs)\n",
        "\n",
        "        # Concatenate the outputs\n",
        "        output = tf.concat([real_mul, imag_mul, feature_extract_output], axis=1)\n",
        "\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owqWXtdOrRni"
      },
      "outputs": [],
      "source": [
        "small = Model(inputs = autoencoder_model[0].get_layer('Input').input, outputs = autoencoder_model[0].get_layer('stc').output)\n",
        "enc = small(test_dataset[:13*12])\n",
        "out_sd = SD()\n",
        "out = out_sd(enc)\n",
        "print(out.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFKFE4MqdMor"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "class SD(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, l=6, n=4, r=4, **kwargs):\n",
        "        super(SD, self).__init__(**kwargs)  # Corrected class name\n",
        "        self.l = l\n",
        "        self.n = n\n",
        "        self.r = r\n",
        "        self.feature_extractor = self.fe()\n",
        "        self.phase_estimator = self.pe()\n",
        "\n",
        "    def fe(self):\n",
        "        fe = Sequential(\n",
        "            [\n",
        "                Dense(256, activation='relu', name='initial'),\n",
        "                Dense(8, activation='linear', name='feature_extractor')\n",
        "            ]\n",
        "        )\n",
        "        return fe\n",
        "\n",
        "    def pe(self):\n",
        "        pe = Sequential(\n",
        "            [\n",
        "                Dense(256, activation='relu', name='initial'),\n",
        "                Dense(2, activation='linear', name='phase_estimator')\n",
        "            ]\n",
        "        )\n",
        "        return pe\n",
        "\n",
        "    def mini_slicer(self, inputs):\n",
        "        in_dim = tf.shape(inputs)[1]\n",
        "        N_msg = self.r * self.n\n",
        "        l1 = 1 + (self.l - 1) * N_msg - self.r\n",
        "        l2 = self.l * N_msg + self.r\n",
        "        out_1 = inputs[:, l1 - 1:l2]\n",
        "        out_2 = inputs[:, in_dim // 2 + l1 - 1:in_dim // 2 + l2]\n",
        "        output = tf.concat([out_1, out_2], axis=1)\n",
        "        print('mini slice output shape', output.shape)\n",
        "        return output\n",
        "\n",
        "    def call(self, inputs):\n",
        "        in_dim = inputs.shape[1]\n",
        "\n",
        "        # Call feature extractor and phase estimator on inputs\n",
        "        feature_extract = self.feature_extractor(inputs)  # Corrected to use the model\n",
        "        phase_estimate = self.phase_estimator(inputs)      # Corrected to use the model\n",
        "\n",
        "        h = self.mini_slicer(inputs)\n",
        "        real = inputs[:, :in_dim // 2]\n",
        "        imag = inputs[:, in_dim // 2:]\n",
        "\n",
        "        # Ensure that h is of appropriate shape\n",
        "        real_mul = real * h[:,0]   # Assuming h has 2 columns\n",
        "        imag_mul = imag * h[:1]   # Assuming h has 2 columns\n",
        "\n",
        "        output = tf.concat([real_mul, imag_mul, feature_extract], axis=1)\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfZS_DOym-H8"
      },
      "source": [
        "\n",
        "#CNN based Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Tly0ZUXmNOG"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import datetime\n",
        "from tensorflow.keras.layers import Layer,Input,Conv1D, Dense, Flatten, Embedding, Reshape, Softmax,LayerNormalization, MultiHeadAttention, Add, Dropout,Normalization\n",
        "from tensorflow.keras import Sequential\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import Callback, TensorBoard\n",
        "from IPython.display import clear_output\n",
        "from tensorflow.keras.layers import Dense, LSTM, GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "cZ0wxW4LnXaN",
        "outputId": "8a30c008-299a-416e-94b7-4307134cae8e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - accuracy: 1.0000 - loss: 0.0636 - val_accuracy: 1.0000 - val_loss: 0.8671\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.8516\n",
            "Test Loss: 0.8542, Test Accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# @title Default title text\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "\n",
        "# Dataset Parameters\n",
        "N = 4  # Number of channel uses\n",
        "K = 8  # Block size (log2 of the number of messages)\n",
        "M = 2**K  # Number of possible messages (2^K)\n",
        "batch_size = 6400\n",
        "output = 2**K\n",
        "Eb_No = 15  # Signal-to-Noise ratio in dB\n",
        "\n",
        "# Create Dataset with Integer Labels\n",
        "train_dataset = np.tile(np.arange(M), batch_size // M)\n",
        "test_dataset = np.tile(np.arange(M), batch_size  //(2*M))\n",
        "\n",
        "# Shuffle the dataset\n",
        "np.random.shuffle(train_dataset)\n",
        "np.random.shuffle(test_dataset)\n",
        "\n",
        "# Define split ratios\n",
        "train_ratio = 0.85  # 85% for training\n",
        "val_ratio = 0.15    # 15% for validation\n",
        "\n",
        "# Calculate the number of samples\n",
        "num_train_samples = int(len(train_dataset) * train_ratio)\n",
        "num_val_samples = len(train_dataset) - num_train_samples\n",
        "\n",
        "# Split the datasets\n",
        "train_set = train_dataset[:num_train_samples]\n",
        "val_set = train_dataset[num_train_samples:]\n",
        "\n",
        "# Reshape the datasets if needed\n",
        "train_set = train_set.reshape((-1, 1))\n",
        "val_set = val_set.reshape((-1, 1))\n",
        "test_dataset = test_dataset.reshape((-1, 1))\n",
        "\n",
        "# Print dataset sizes\n",
        "print(f\"Number of train samples: {len(train_set)}\")\n",
        "print(f\"Number of validation samples: {len(val_set)}\")\n",
        "print(f\"Number of test samples: {len(test_dataset)}\")\n",
        "\n",
        "\n",
        "\n",
        "# Custom Noise Layer\n",
        "class CustomNoise(tf.keras.layers.Layer):\n",
        "    def __init__(self, mean=0.0, stddev=10**(-1.0*Eb_No), **kwargs):\n",
        "        super(CustomNoise, self).__init__(**kwargs)\n",
        "        self.mean = mean\n",
        "        self.stddev = stddev\n",
        "\n",
        "    def call(self, inputs):\n",
        "        noise = tf.random.normal(shape=tf.shape(inputs), mean=self.mean, stddev=self.stddev)\n",
        "        return inputs + noise\n",
        "\n",
        "# class Normalization(tf.keras.layers.Layer):\n",
        "#     def __init__(self, **kwargs):\n",
        "#         super(Normalization, self).__init__(**kwargs)\n",
        "\n",
        "#     def call(self, input):\n",
        "#         out = tf.nn.l2_normalize(tf.reshape(input, (-1, 2)), axis=-1, epsilon=1e-6)\n",
        "#         out = tf.reshape(out, (-1, 2*N))\n",
        "#         print(\"normalization layer output shape:\" ,str(out.shape))\n",
        "#         return out\n",
        "#     def get_config(self):\n",
        "#         config = super(Normalization, self).get_config()\n",
        "#         return config\n",
        "\n",
        "\n",
        "class Normalization(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(Normalization, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, input):\n",
        "        # Perform L2 normalization on the last dimension while keeping the overall shape\n",
        "        print(input)\n",
        "        out = tf.nn.l2_normalize(input, axis=-1, epsilon=1e-6)\n",
        "        # print(\"Normalization layer output shape:\", out.shape)\n",
        "        return out\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(Normalization, self).get_config()\n",
        "        return config\n",
        "\n",
        "class PowerConstraintLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(PowerConstraintLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Split real and imaginary parts\n",
        "        real_parts = inputs[:,:, :4]  # First 4 elements\n",
        "        imag_parts = inputs[:,:, 4:]  # Last 4 elements\n",
        "\n",
        "        # Compute magnitudes\n",
        "        magnitudes = tf.sqrt(tf.square(real_parts) + tf.square(imag_parts))\n",
        "\n",
        "        # Find the maximum magnitude\n",
        "        #max_magnitude = tf.reduce_max(magnitudes, axis=1, keepdims=True)\n",
        "\n",
        "        # Scale inputs if max magnitude > 1\n",
        "        # Replace zero values with one\n",
        "        scale_factor = tf.where(tf.less_equal(magnitudes, 1), tf.ones_like(magnitudes), magnitudes)\n",
        "        scale_factor = tf.concat([scale_factor, scale_factor],axis=-1)\n",
        "        scaled_inputs = inputs / scale_factor\n",
        "\n",
        "        return scaled_inputs\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(PowerConstraintLayer, self).get_config()\n",
        "        return config\n",
        "\n",
        "\n",
        "class SD(tf.keras.layers.Layer):\n",
        "    def __init__(self, l=6, n=4, r=4, **kwargs):\n",
        "        super(SD, self).__init__(**kwargs)\n",
        "        self.l = l\n",
        "        self.n = n\n",
        "        self.r = r\n",
        "\n",
        "        with tf.name_scope(\"fe\"):\n",
        "            self.fe = Sequential([\n",
        "                Dense(64, activation='relu', name='initial'),\n",
        "                Dense(8, activation='linear', name='feature_extractor')\n",
        "            ])\n",
        "\n",
        "        with tf.name_scope(\"pe\"):\n",
        "            self.pe = Sequential([\n",
        "                Dense(64, activation='relu', name='initial'),\n",
        "                Dense(2, activation='linear', name='phase_estimator')\n",
        "            ])\n",
        "\n",
        "        with tf.name_scope(\"oe\"):\n",
        "            self.oe = Sequential([\n",
        "                Dense(64, activation='relu', name='initial'),\n",
        "                Dense(64, activation='relu', name='oe_dense1'),\n",
        "                Dense(32, activation='relu', name='oe_dense2'),\n",
        "                Dense(1, activation='linear', name='offset_estimator'),\n",
        "\n",
        "            ])\n",
        "\n",
        "    def mini_slicer(self, inputs):\n",
        "        in_dim = tf.shape(inputs)[1]\n",
        "        N_msg = self.r * self.n\n",
        "        l1 = 1 + (self.l - 1) * N_msg - self.r\n",
        "        l2 = self.l * N_msg + self.r\n",
        "        out_1 = inputs[:, l1-1:l2]\n",
        "        out_2 = inputs[:, in_dim // 2 + l1-1:in_dim // 2 + l2]\n",
        "        output = tf.concat([out_1, out_2], axis=1)\n",
        "        print('mini slice output shape', output.shape)\n",
        "        return output\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Get the input dimension (before slicing)\n",
        "        in_dim = inputs.shape[1]\n",
        "\n",
        "        # Process the inputs using mini_slicer (this changes the shape of inputs)\n",
        "        # inputs = self.mini_slicer(inputs)\n",
        "\n",
        "        # Update real and imag slices based on new input shape (after mini_slicer)\n",
        "        half_dim = tf.shape(inputs)[1] // 2  # Get new half dimension after slicing\n",
        "        real = inputs[:, :half_dim]  # First half of sliced inputs as real part\n",
        "        imag = inputs[:, half_dim:]  # Second half as imaginary part\n",
        "\n",
        "        # Pass the sliced inputs to the phase estimator model to get h\n",
        "        h = self.pe(inputs)  # h has shape (batch_size, 2)\n",
        "        h_real = h[:, 0]  # Extract real part of h\n",
        "        h_imag = h[:, 1]  # Extract imaginary part of h\n",
        "\n",
        "        h_real = tf.expand_dims(h_real, axis=1)\n",
        "        h_imag = tf.expand_dims(h_imag, axis=1)\n",
        "\n",
        "        # # Perform element-wise multiplication\n",
        "        # h_real_ex = tf.tile(h_real, [1, half_dim])\n",
        "        # h_imag_ex = tf.tile(h_imag, [1, half_dim])\n",
        "        # real_mul = real * h_real_ex -imag*h_imag_ex # Multiply same value of real part to every component of the input\n",
        "        # imag_mul = real * h_imag_ex + imag*h_real_ex # Multiply same value of imag part to every component of the input\n",
        "\n",
        "        # Apply the feature extractor model to real_mul (as an example)\n",
        "        feature_extract_output = self.fe(inputs)\n",
        "        offset_estimator_output = self.oe(inputs)\n",
        "\n",
        "        # Concatenate the outputs\n",
        "        output = tf.concat([real, imag,offset_estimator_output,h_real,h_imag, feature_extract_output], axis=1)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class SD_RNN(tf.keras.layers.Layer):\n",
        "    def __init__(self, l=6, n=4, r=4, units=16, **kwargs):\n",
        "        super(SD_RNN, self).__init__(**kwargs)\n",
        "        self.l = l\n",
        "        self.n = n\n",
        "        self.r = r\n",
        "        self.units = units  # RNN units\n",
        "\n",
        "        with tf.name_scope(\"fe\"):\n",
        "            # Use LSTM or GRU for feature extractor\n",
        "            self.fe = Sequential([\n",
        "                Reshape((1, 92)),\n",
        "                LSTM(self.units, return_sequences=True, name='feature_extractor_lstm'),\n",
        "                Flatten(),# or use GRU\n",
        "                Dense(8, activation='linear', name='feature_extractor_output')\n",
        "            ])\n",
        "\n",
        "        with tf.name_scope(\"pe\"):\n",
        "            # Use LSTM or GRU for phase estimator\n",
        "            self.pe = Sequential([\n",
        "                Reshape((1, 92)),\n",
        "                LSTM(self.units, return_sequences=True, name='phase_estimator_lstm'),\n",
        "                Flatten(),# or use GRU\n",
        "                Dense(2, activation='linear', name='phase_estimator_output')\n",
        "            ])\n",
        "\n",
        "        with tf.name_scope(\"oe\"):\n",
        "            self.oe = Sequential([\n",
        "                 Reshape((1, 92)),\n",
        "                LSTM(self.units, return_sequences=True, name='offset_estimator_lstm'),\n",
        "                LSTM(self.units, return_sequences=True, name='offset_estimator_lstm1'),\n",
        "                LSTM(self.units//2, return_sequences=True, name='offset_estimator_lstm2'),\n",
        "                Flatten(),\n",
        "                Dense(1, activation='linear', name='offset_estimator'),\n",
        "\n",
        "            ])\n",
        "\n",
        "\n",
        "\n",
        "    def mini_slicer(self, inputs):\n",
        "        in_dim = tf.shape(inputs)[1]\n",
        "        N_msg = self.r * self.n\n",
        "        l1 = 1 + (self.l - 1) * N_msg - self.r\n",
        "        l2 = self.l * N_msg + self.r\n",
        "        out_1 = inputs[:, l1-1:l2]\n",
        "        out_2 = inputs[:, in_dim // 2 + l1-1:in_dim // 2 + l2]\n",
        "        output = tf.concat([out_1, out_2], axis=1)\n",
        "        print('mini slice output shape', output.shape)\n",
        "        return output\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Get the input dimension (before slicing)\n",
        "        in_dim = inputs.shape[1]\n",
        "\n",
        "        # Process the inputs using mini_slicer (this changes the shape of inputs)\n",
        "        # inputs = self.mini_slicer(inputs)\n",
        "\n",
        "        # Update real and imag slices based on new input shape (after mini_slicer)\n",
        "        half_dim = tf.shape(inputs)[1] // 2  # Get new half dimension after slicing\n",
        "        real = inputs[:, :half_dim]  # First half of sliced inputs as real part\n",
        "        imag = inputs[:, half_dim:]  # Second half as imaginary part\n",
        "\n",
        "        # Pass the sliced inputs to the phase estimator model to get h\n",
        "        h = self.pe(inputs)  # h has shape (batch_size, 2)\n",
        "        h_real = h[:, 0]  # Extract real part of h\n",
        "        h_imag = h[:, 1]  # Extract imaginary part of h\n",
        "\n",
        "        h_real = tf.expand_dims(h_real, axis=1)\n",
        "        h_imag = tf.expand_dims(h_imag, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "        # # Perform element-wise multiplication\n",
        "        # h_real_ex = tf.tile(h_real, [1, half_dim])\n",
        "        # h_imag_ex = tf.tile(h_imag, [1, half_dim])\n",
        "        # real_mul = real * h_real_ex -imag*h_imag_ex # Multiply same value of real part to every component of the input\n",
        "        # imag_mul = real * h_imag_ex + imag*h_real_ex # Multiply same value of imag part to every component of the input\n",
        "\n",
        "        # Apply the feature extractor model to real_mul (as an example)\n",
        "        feature_extract_output = self.fe(inputs)\n",
        "        offset_estimator_output = self.oe(inputs)\n",
        "\n",
        "        # Concatenate the outputs\n",
        "        output = tf.concat([real, imag,offset_estimator_output,h_real,h_imag, feature_extract_output], axis=1)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "\n",
        "class StochasticChannelv3(tf.keras.layers.Layer):\n",
        "    def __init__(self, roll_off=0.35, num_taps=31, time_delay=0, r=4, ts=1, **kwargs):\n",
        "        super(StochasticChannelv3, self).__init__(**kwargs)\n",
        "        self.num_taps = num_taps\n",
        "        self.time_delay = time_delay\n",
        "        self.r = r  # Upsampling factor\n",
        "        self.roll_off = roll_off  # Roll-off factor\n",
        "        self.ts = ts  # Sampling period (default is 1)\n",
        "\n",
        "    def upsampling(self, inp):\n",
        "        com_reshape = tf.reshape(inp, [-1, 1])\n",
        "        padding = tf.constant([[0, 0], [0, self.r - 1]])  # Access self.r\n",
        "        upsampled = tf.pad(com_reshape, padding, mode=\"CONSTANT\")\n",
        "        upsampled = tf.reshape(upsampled, [-1])  # Flatten back to 1D\n",
        "        return upsampled\n",
        "\n",
        "    def upsample_iq(self, inp):\n",
        "        real = inp[:, 0]  # Real part\n",
        "        imag = inp[:, 1]  # Imaginary part\n",
        "\n",
        "        real_up = self.upsampling(real)\n",
        "        imag_up = self.upsampling(imag)\n",
        "\n",
        "        upsampled = tf.stack([real_up, imag_up], axis=1)\n",
        "        return upsampled\n",
        "\n",
        "    def rrc_filter(self):\n",
        "        t = np.linspace(-self.num_taps // 2, self.num_taps // 2 + 1, self.num_taps) - self.time_offset()\n",
        "        rrc = np.zeros_like(t)\n",
        "\n",
        "        for i in range(len(t)):\n",
        "            if t[i] == 0.0:\n",
        "                rrc[i] = (1.0 - self.roll_off + 4 * self.roll_off / np.pi) / self.ts\n",
        "            elif np.abs(t[i]) == self.ts / (4 * self.roll_off):\n",
        "                rrc[i] = (self.roll_off / (np.sqrt(2) * self.ts)) * \\\n",
        "                         ((1 + 2 / np.pi) * np.sin(np.pi / (4 * self.roll_off)) +\n",
        "                          (1 - 2 / np.pi) * np.cos(np.pi / (4 * self.roll_off)))\n",
        "            else:\n",
        "                rrc[i] = (np.sin(np.pi * (t[i] / self.ts) * (1 - self.roll_off)) +\n",
        "                          4 * self.roll_off * (t[i] / self.ts) * np.cos(np.pi * (t[i] / self.ts) * (1 + self.roll_off))) / \\\n",
        "                         (np.pi * t[i] * (1 - (4 * self.roll_off * (t[i] / self.ts)) ** 2))\n",
        "\n",
        "        rrc = rrc / np.sqrt(np.sum(rrc ** 2))\n",
        "        rrc = tf.constant(rrc, dtype=tf.float32)\n",
        "        return rrc\n",
        "\n",
        "    def phase_offset(self):\n",
        "        phase_offset = np.random.uniform(0, (2) * np.pi)\n",
        "        return phase_offset\n",
        "\n",
        "    def upsample_and_filter(self, signal):\n",
        "        upsampled_signal = self.upsample_iq(signal)\n",
        "        rrc = self.rrc_filter()\n",
        "\n",
        "        upsampled_signal = tf.expand_dims(upsampled_signal, axis=0)  # Shape: (1, length, 2)\n",
        "        rrc = tf.reshape(rrc, [-1, 1, 1])  # Shape: (filter_length, 1, 1)\n",
        "\n",
        "        padding_size = self.num_taps // 2\n",
        "        paddings = tf.constant([[0, 0], [padding_size, padding_size], [0, 0]])\n",
        "        padded_real = tf.pad(upsampled_signal[:, :, 0:1], paddings, \"CONSTANT\")\n",
        "        padded_imag = tf.pad(upsampled_signal[:, :, 1:2], paddings, \"CONSTANT\")\n",
        "        upsampled_signal = tf.concat([padded_real, padded_imag], axis=2)\n",
        "\n",
        "        real_filtered = tf.nn.conv1d(upsampled_signal[:, :, 0:1], rrc, stride=1, padding='SAME')\n",
        "        imag_filtered = tf.nn.conv1d(upsampled_signal[:, :, 1:2], rrc, stride=1, padding='SAME')\n",
        "\n",
        "\n",
        "        real_filtered = real_filtered * tf.math.cos(self.phase_offset())-imag_filtered * tf.math.sin(self.phase_offset())\n",
        "        imag_filtered = imag_filtered * tf.math.sin(self.phase_offset())+real_filtered * tf.math.cos(self.phase_offset())\n",
        "\n",
        "        filtered_signal = tf.concat([real_filtered, imag_filtered], axis=2)\n",
        "        filtered_signal = tf.squeeze(filtered_signal, axis=0)  # Remove the batch dimension\n",
        "        return filtered_signal\n",
        "\n",
        "    def time_offset(self, sampling_time=0.5e-6):\n",
        "        t_offset = np.random.uniform(-sampling_time , sampling_time )\n",
        "        return t_offset\n",
        "\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        f = inputs.shape[1] // 2\n",
        "\n",
        "        # Reshape to pairs of real and imaginary parts\n",
        "        inputs = tf.reshape(inputs, [batch_size, -1, 2])  # Shape: (batch_size, num_pairs, 2) adjacent pairs are couples as real imaginary\n",
        "        print(inputs.shape)\n",
        "        # Define a function to process each sample\n",
        "        def process_sample(sample):\n",
        "            filtered_signal = self.upsample_and_filter(sample)  # Process each sample\n",
        "            return filtered_signal\n",
        "\n",
        "        # Apply the function to each sample in the batch\n",
        "        output = tf.map_fn(process_sample, inputs, dtype=tf.float32)  # Shape: (batch_size, num_filtered_samples, 2)\n",
        "\n",
        "        # Reshape back to original shape if necessary\n",
        "        output = tf.reshape(output, [batch_size, -1])\n",
        "\n",
        "        return output\n",
        "\n",
        "# Autoencoder Class with Convolutional Layers\n",
        "class AE:\n",
        "    def __init__(self, train_data, val_data, test_data, input_dim=K, enc_dim=N, act_fun='relu'):\n",
        "        self.train_data = train_data\n",
        "        self.val_data = val_data\n",
        "        self.test_data = test_data\n",
        "        self.input_dim = input_dim\n",
        "        self.enc_dim = enc_dim\n",
        "        self.act_fun = act_fun\n",
        "\n",
        "\n",
        "    def AE_implement(self):\n",
        "        autoencoder = Sequential([\n",
        "            Input(shape=(1,),batch_size = batch_size),  # Add this input layer\n",
        "            # Embedding Layer (Input: message indices)\n",
        "            Embedding(input_dim=M, output_dim=256, input_length=1, name=\"Embedding\"),\n",
        "            Flatten(),  # Flatten output to feed into Conv1D layers\n",
        "\n",
        "            # Encoder (Multiple Conv1D layers)\n",
        "            Reshape((1, 256)),  # Reshape for Conv1D\n",
        "            Conv1D(256, kernel_size=1, activation='elu', name=\"Conv1D_1\"),\n",
        "            Conv1D(128, kernel_size=1, activation='elu', name=\"Conv1D_2\"),\n",
        "            Conv1D(64, kernel_size=1, activation='elu', name=\"Conv1D_3\"),\n",
        "            Conv1D(2*N, kernel_size=1, activation='linear', name=\"Conv1D_4\"),\n",
        "\n",
        "            # # Power Normalization Layer (L2 normalization over 2N dimensions)\n",
        "            # tf.keras.layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=-1)),\n",
        "            # PowerConstraintLayer(input_shape=(1, 8),name= \"power\"),\n",
        "            Normalization(input_shape=(1, 8),name= \"normal\"),\n",
        "            # Custom Noise Layer (Simulating the channel)\n",
        "            StochasticChannelv3(name=\"StochasticChannel\"),\n",
        "            CustomNoise(name=\"NoiseLayer\"),\n",
        "            SD_RNN(name=\"SD\"),\n",
        "\n",
        "            Reshape((1, 103)),  # Reshape for Conv1D_dec1\n",
        "            # Decoder (Conv1D layers to reconstruct the input)\n",
        "            Conv1D(64, kernel_size=1, activation='elu', name=\"Conv1D_Dec1\"),\n",
        "            Conv1D(128, kernel_size=1, activation='elu', name=\"Conv1D_Dec2\"),\n",
        "            Conv1D(256, kernel_size=1, activation='elu', name=\"Conv1D_Dec3\"),\n",
        "\n",
        "            # Output Layer with Softmax to predict the message index\n",
        "            Flatten(),\n",
        "            Dense(output, activation='softmax', name=\"Output\")\n",
        "        ],name=\"Autoencoder_Model\",)\n",
        "\n",
        "        # Compile the model\n",
        "        autoencoder.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,beta_1=0.9, beta_2=0.999,epsilon=1e-07),\n",
        "                            loss='sparse_categorical_crossentropy',\n",
        "                            metrics=['accuracy'])\n",
        "        return autoencoder\n",
        "\n",
        "\n",
        "        # Training Class with Early Stopping and Plotting\n",
        "    def train(self, epochs=40, batch_size=32):\n",
        "        autoencoder = self.AE_implement()\n",
        "\n",
        "        log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "        tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "        history = autoencoder.fit(self.train_data, self.train_data,\n",
        "                                  epochs=epochs, batch_size=batch_size,\n",
        "                                  validation_data=(self.val_data, self.val_data),\n",
        "                                  callbacks=[PlottingCallback(), tensorboard_callback])\n",
        "        return autoencoder, history\n",
        "\n",
        "\n",
        "# Custom Callback for Real-time Plotting\n",
        "class PlottingCallback(Callback):\n",
        "    def __init__(self):\n",
        "        super(PlottingCallback, self).__init__()\n",
        "        self.history = {'accuracy': [], 'val_accuracy': [], 'loss': [], 'val_loss': []}\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.history['accuracy'].append(logs.get('accuracy'))\n",
        "        self.history['val_accuracy'].append(logs.get('val_accuracy'))\n",
        "        self.history['loss'].append(logs.get('loss'))\n",
        "        self.history['val_loss'].append(logs.get('val_loss'))\n",
        "\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        plt.figure(figsize=(12, 5))\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(self.history['accuracy'], label='Training Accuracy')\n",
        "        plt.plot(self.history['val_accuracy'], label='Validation Accuracy')\n",
        "        plt.title('Accuracy over Epochs')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(self.history['loss'], label='Training Loss')\n",
        "        plt.plot(self.history['val_loss'], label='Validation Loss')\n",
        "        plt.title('Loss over Epochs')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Instantiate and Train\n",
        "ae = AE(train_data=train_set, val_data=val_set, test_data=test_dataset, input_dim=K, enc_dim=N, act_fun='tanh')\n",
        "autoencoder_model, history = ae.train(epochs=80, batch_size=batch_size)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = autoencoder_model.evaluate(test_dataset, test_dataset)\n",
        "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxFrLcW22ayQ"
      },
      "outputs": [],
      "source": [
        "# Save the model for MATLAB\n",
        "autoencoder_model.save('my_model.keras')  # Save in HDF5 format\n",
        "#autoencoder_model.save('autoencoder_model.tf')  # Save in SavedModel format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XX4d2GFIqiK_",
        "outputId": "f3947dab-d5b3-494d-8139-5ebc17777cb0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "autoencoder_model.save('my_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OabxgNH26bJC",
        "outputId": "23f089fc-f0d0-4aae-e0fe-675ee91af1b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        },
        "id": "VJ8Uc-EYoMqm",
        "outputId": "7037cc38-1ab4-4ae5-d656-a295aece94d7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Autoencoder_Model\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"Autoencoder_Model\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ Embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,536</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ power (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PowerConstraintLayer</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ normal (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ StochasticChannel                    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">92</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">StochasticChannelv3</span>)                │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ NoiseLayer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CustomNoise</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">92</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ SD (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SD_RNN</span>)                          │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,019</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_Dec1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,656</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_Dec2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_Dec3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ Embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │          \u001b[38;5;34m65,536\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)                    │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_1 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │          \u001b[38;5;34m65,792\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_2 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │          \u001b[38;5;34m32,896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_3 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_4 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)                │             \u001b[38;5;34m520\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ power (\u001b[38;5;33mPowerConstraintLayer\u001b[0m)         │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ normal (\u001b[38;5;33mNormalization\u001b[0m)               │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ StochasticChannel                    │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m92\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mStochasticChannelv3\u001b[0m)                │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ NoiseLayer (\u001b[38;5;33mCustomNoise\u001b[0m)             │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m92\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ SD (\u001b[38;5;33mSD_RNN\u001b[0m)                          │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m103\u001b[0m)                 │          \u001b[38;5;34m24,019\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape_4 (\u001b[38;5;33mReshape\u001b[0m)                  │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m103\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_Dec1 (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │           \u001b[38;5;34m6,656\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_Dec2 (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │           \u001b[38;5;34m8,320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_Dec3 (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │          \u001b[38;5;34m33,024\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Output (\u001b[38;5;33mDense\u001b[0m)                       │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │          \u001b[38;5;34m65,792\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">932,435</span> (3.56 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m932,435\u001b[0m (3.56 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">310,811</span> (1.19 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m310,811\u001b[0m (1.19 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">621,624</span> (2.37 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m621,624\u001b[0m (2.37 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "autoencoder_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "rJtxL_ZKvJm7",
        "outputId": "9ce39531-a46b-4036-d9df-861dc1b606b2"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "The layer Autoencoder_Model has never been called and thus has no defined input.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-7effb82d3829>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Create a new model from the input to the Normalization layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0msub_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautoencoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msub_model_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0msub_model_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautoencoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msub_model_output_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36minput\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mInput\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0minput\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \"\"\"\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_node_attribute_at_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input_tensors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36m_get_node_attribute_at_index\u001b[0;34m(self, node_index, attr, attr_name)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \"\"\"\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    286\u001b[0m                 \u001b[0;34mf\"The layer {self.name} has never been called \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m                 \u001b[0;34mf\"and thus has no defined {attr_name}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The layer Autoencoder_Model has never been called and thus has no defined input."
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Get the output of the Normalization layer\n",
        "sub_model_output = autoencoder_model.get_layer(\"normal\").output\n",
        "sub_model_output_p = autoencoder_model.get_layer(\"power\").output\n",
        "\n",
        "# Create a new model from the input to the Normalization layer\n",
        "sub_model = Model(inputs=autoencoder_model.input, outputs=sub_model_output)\n",
        "sub_model_p = Model(inputs=autoencoder_model.input, outputs=sub_model_output_p)\n",
        "\n",
        "# Display the summary of the sub-model\n",
        "sub_model.summary()\n",
        "sub_model_p.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jK3L9dy7p7SF"
      },
      "source": [
        "# Save encoder output as a .mat file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3a5ayi5EPWFn"
      },
      "outputs": [],
      "source": [
        "from scipy.io import savemat\n",
        "\n",
        "sub_model_output_values = sub_model.predict(train_dataset)  # Use predict to get NumPy values\n",
        "sub_model_output_values = tf.squeeze(sub_model_output_values, axis=1)\n",
        "\n",
        "sub_model_output_p_values = sub_model_p.predict(train_dataset)  # Use predict to get NumPy values\n",
        "sub_model_output_p_values = tf.squeeze(sub_model_output_p_values, axis=1)\n",
        "\n",
        "# Since eager execution is enabled, you can directly get the tensor values\n",
        "sub_model_output_p_values = sub_model_output_p_values.numpy()\n",
        "sub_model_output_values = sub_model_output_values.numpy()\n",
        "print(sub_model_output_values)\n",
        "\n",
        "# Save the result to a .mat file\n",
        "savemat(\"Tx_out_n4_k8.mat\", {\"data\": sub_model_output_values})\n",
        "savemat(\"Tx_out_n4_k8_p.mat\", {\"data\": sub_model_output_p_values})\n",
        "\n",
        "# Create complex data using NumPy\n",
        "complex_data = sub_model_output_values[:, :4] + 1j * sub_model_output_values[:, 4:]\n",
        "complex_data_p = sub_model_output_p_values[:, :4] + 1j * sub_model_output_p_values[:, 4:]\n",
        "\n",
        "# Save complex data to .mat file\n",
        "savemat(\"Tx_out_complex_n4_k8.mat\", {\"data\": complex_data})\n",
        "savemat(\"Tx_out_complex_n4_k8_p.mat\", {\"data\": complex_data_p})  # Save complex_data_p as well\n",
        "\n",
        "print(\"Saved tensor data as a .mat file.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R66WiQmsox-3"
      },
      "outputs": [],
      "source": [
        "sub_model.save('my_Submodel.keras')\n",
        "sub_model.save('my_Submodel.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G23ZkT4DoNIj"
      },
      "outputs": [],
      "source": [
        "def BLER(test_dataset, frame_size, model):\n",
        "    prediction = model.predict(test_dataset)\n",
        "    total_blocks = prediction.shape[0] // frame_size\n",
        "    print(total_blocks)\n",
        "    print(prediction.shape)\n",
        "    print(test_dataset.shape)\n",
        "    prediction = np.argmax(prediction, axis=1)\n",
        "    test_dataset = test_dataset.ravel()\n",
        "    print(prediction.shape)\n",
        "    print(test_dataset[:frame_size])\n",
        "    print(prediction[0:frame_size])\n",
        "\n",
        "    bler = 0\n",
        "    for i in range(total_blocks):\n",
        "        block_prediction = prediction[i * frame_size : (i + 1) * frame_size]\n",
        "        block_true = test_dataset[i * frame_size : (i + 1) * frame_size]\n",
        "\n",
        "        if not np.array_equal(block_prediction, block_true):  # Corrected comparison\n",
        "            bler += 1\n",
        "\n",
        "    return bler / total_blocks\n",
        "\n",
        "bler = BLER(test_dataset[:20001], 100, autoencoder_model)\n",
        "print(bler)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6B89NXG_Ntq"
      },
      "source": [
        "# CNN Bsed AE for CTS transmission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBwYJJE2D2HH"
      },
      "source": [
        "## Sliding window\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hr7kimTuD2HH",
        "outputId": "698a959e-0149-4af2-b6a8-f7ca932a71d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Matrix Shape: (20, 1, 8)\n",
            "New Matrix Shape: (20, 1, 104)\n"
          ]
        }
      ],
      "source": [
        "class SlidingWindowConcatLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, window_size, **kwargs):\n",
        "        \"\"\"\n",
        "        Initialize the SlidingWindowConcatLayer.\n",
        "\n",
        "        Args:\n",
        "            window_size (int): Number of rows in the sliding window.\n",
        "        \"\"\"\n",
        "        super(SlidingWindowConcatLayer, self).__init__(**kwargs)\n",
        "        self.window_size = window_size\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        Apply the sliding window and concatenation operation to the inputs.\n",
        "\n",
        "        Args:\n",
        "            inputs (tf.Tensor): A 3D tensor of shape (rows, cols, depth).\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: A transformed tensor after sliding window and concatenation.\n",
        "        \"\"\"\n",
        "        # Determine padding size\n",
        "        paddings = [[self.window_size // 2, self.window_size // 2], [0, 0], [0, 0]]\n",
        "\n",
        "        # Pad the input tensor\n",
        "        padded_matrix = tf.pad(inputs, paddings=paddings, mode=\"CONSTANT\", constant_values=0)\n",
        "\n",
        "        # Initialize a list to store the new rows\n",
        "        new_matrix_list = []\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "\n",
        "        # Create sliding windows and concatenate along the depth\n",
        "        for i in range(batch_size):  # Iterate over the original matrix row count\n",
        "            window = padded_matrix[i:i + self.window_size]\n",
        "            concatenated_row = tf.concat(tf.unstack(window, axis=0), axis=-1)\n",
        "            new_matrix_list.append(concatenated_row)\n",
        "\n",
        "        # Stack the resulting rows into a single tensor\n",
        "        output = tf.stack(new_matrix_list)\n",
        "        return output\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"\n",
        "        Returns the configuration of the layer for serialization.\n",
        "        \"\"\"\n",
        "        config = super(SlidingWindowConcatLayer, self).get_config()\n",
        "        config.update({\"window_size\": self.window_size})\n",
        "        return config\n",
        "\n",
        "original_matrix = tf.random.uniform(shape=(20, 1, 8), minval=0, maxval=10, dtype=tf.int32)\n",
        "sliding_window_layer = SlidingWindowConcatLayer(window_size=13)\n",
        "new_matrix = sliding_window_layer(original_matrix)\n",
        "\n",
        "print(\"Original Matrix Shape:\", original_matrix.shape)\n",
        "print(\"New Matrix Shape:\", new_matrix.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMN_ROlwD2HH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7518a14b-96ad-4744-ff74-bc3537d4a047"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Matrix Shape: (20, 1, 8)\n",
            "New Matrix Shape: (20, 1, 104)\n"
          ]
        }
      ],
      "source": [
        "class SlidingWindowConcatLayer1(tf.keras.layers.Layer):\n",
        "    def __init__(self, window_size, **kwargs):\n",
        "        \"\"\"\n",
        "        Initialize the SlidingWindowConcatLayer.\n",
        "\n",
        "        Args:\n",
        "            window_size (int): Number of rows in the sliding window.\n",
        "        \"\"\"\n",
        "        super(SlidingWindowConcatLayer1, self).__init__(**kwargs)\n",
        "        self.window_size = window_size\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        Apply the sliding window and concatenation operation to the inputs.\n",
        "\n",
        "        Args:\n",
        "            inputs (tf.Tensor): A 3D tensor of shape (batch_size, rows, depth).\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: A transformed tensor after sliding window and concatenation.\n",
        "        \"\"\"\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        rows = tf.shape(inputs)[1]\n",
        "        depth = tf.shape(inputs)[2]\n",
        "\n",
        "        # Pad the input tensor\n",
        "        paddings = [[0, 0], [self.window_size // 2, self.window_size // 2], [0, 0]]\n",
        "        padded_matrix = tf.pad(inputs, paddings=paddings, mode=\"CONSTANT\", constant_values=0)\n",
        "\n",
        "        # Create sliding windows\n",
        "        window_slices = [\n",
        "            padded_matrix[:, i:i + rows, :]\n",
        "            for i in range(self.window_size)\n",
        "        ]\n",
        "\n",
        "        # Concatenate windows along the depth dimension\n",
        "        concatenated = tf.concat(window_slices, axis=-1)\n",
        "        return concatenated\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\"\n",
        "        Compute the output shape of the layer.\n",
        "        \"\"\"\n",
        "        batch_size, rows, depth = input_shape\n",
        "        output_depth = depth * self.window_size\n",
        "        return (batch_size, rows, output_depth)\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"\n",
        "        Returns the configuration of the layer for serialization.\n",
        "        \"\"\"\n",
        "        config = super(SlidingWindowConcatLayer1, self).get_config()\n",
        "        config.update({\"window_size\": self.window_size})\n",
        "        return config\n",
        "\n",
        "\n",
        "original_matrix = tf.random.uniform(shape=(20, 1, 8), minval=0, maxval=10, dtype=tf.int32)\n",
        "sliding_window_layer = SlidingWindowConcatLayer1(window_size=13)\n",
        "new_matrix = sliding_window_layer(original_matrix)\n",
        "\n",
        "print(\"Original Matrix Shape:\", original_matrix.shape)\n",
        "print(\"New Matrix Shape:\", new_matrix.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aG8NyGV-D2HI"
      },
      "source": [
        "##Stochastic channel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03w49zXXD2HI"
      },
      "outputs": [],
      "source": [
        "##- taking adjacent as real and imaginary pairs\n",
        "\n",
        "\n",
        "class StochasticChannelv3(tf.keras.layers.Layer):\n",
        "    def __init__(self, roll_off=0.35, num_taps=31, time_delay=0, r=4, ts=1, **kwargs):\n",
        "        super(StochasticChannelv3, self).__init__(**kwargs)\n",
        "        self.num_taps = num_taps\n",
        "        self.time_delay = time_delay\n",
        "        self.r = r  # Upsampling factor\n",
        "        self.roll_off = roll_off  # Roll-off factor\n",
        "        self.ts = ts  # Sampling period (default is 1)\n",
        "\n",
        "    def upsampling(self, inp):\n",
        "        com_reshape = tf.reshape(inp, [-1, 1])\n",
        "        padding = tf.constant([[0, 0], [0, self.r - 1]])  # Access self.r\n",
        "        upsampled = tf.pad(com_reshape, padding, mode=\"CONSTANT\")\n",
        "        upsampled = tf.reshape(upsampled, [-1])  # Flatten back to 1D\n",
        "        return upsampled\n",
        "\n",
        "    def upsample_iq(self, inp):\n",
        "        real = inp[:, 0]  # Real part\n",
        "        imag = inp[:, 1]  # Imaginary part\n",
        "\n",
        "        real_up = self.upsampling(real)\n",
        "        imag_up = self.upsampling(imag)\n",
        "\n",
        "        upsampled = tf.stack([real_up, imag_up], axis=1)\n",
        "        return upsampled\n",
        "\n",
        "    def rrc_filter(self):\n",
        "        t = np.linspace(-self.num_taps // 2, self.num_taps // 2 + 1, self.num_taps) - self.time_offset()\n",
        "        rrc = np.zeros_like(t)\n",
        "\n",
        "        for i in range(len(t)):\n",
        "            if t[i] == 0.0:\n",
        "                rrc[i] = (1.0 - self.roll_off + 4 * self.roll_off / np.pi) / self.ts\n",
        "            elif np.abs(t[i]) == self.ts / (4 * self.roll_off):\n",
        "                rrc[i] = (self.roll_off / (np.sqrt(2) * self.ts)) * \\\n",
        "                         ((1 + 2 / np.pi) * np.sin(np.pi / (4 * self.roll_off)) +\n",
        "                          (1 - 2 / np.pi) * np.cos(np.pi / (4 * self.roll_off)))\n",
        "            else:\n",
        "                rrc[i] = (np.sin(np.pi * (t[i] / self.ts) * (1 - self.roll_off)) +\n",
        "                          4 * self.roll_off * (t[i] / self.ts) * np.cos(np.pi * (t[i] / self.ts) * (1 + self.roll_off))) / \\\n",
        "                         (np.pi * t[i] * (1 - (4 * self.roll_off * (t[i] / self.ts)) ** 2))\n",
        "\n",
        "        rrc = rrc / np.sqrt(np.sum(rrc ** 2))\n",
        "        rrc = tf.constant(rrc, dtype=tf.float32)\n",
        "        return rrc\n",
        "\n",
        "    def phase_offset(self):\n",
        "        phase_offset = np.random.uniform(0, (2) * np.pi)\n",
        "        return phase_offset\n",
        "\n",
        "    def upsample_and_filter(self, signal):\n",
        "        upsampled_signal = self.upsample_iq(signal)\n",
        "        rrc = self.rrc_filter()\n",
        "\n",
        "        upsampled_signal = tf.expand_dims(upsampled_signal, axis=0)  # Shape: (1, length, 2)\n",
        "        rrc = tf.reshape(rrc, [-1, 1, 1])  # Shape: (filter_length, 1, 1)\n",
        "\n",
        "        padding_size = self.num_taps // 2\n",
        "        paddings = tf.constant([[0, 0], [padding_size, padding_size], [0, 0]])\n",
        "        padded_real = tf.pad(upsampled_signal[:, :, 0:1], paddings, \"CONSTANT\")\n",
        "        padded_imag = tf.pad(upsampled_signal[:, :, 1:2], paddings, \"CONSTANT\")\n",
        "        upsampled_signal = tf.concat([padded_real, padded_imag], axis=2)\n",
        "\n",
        "        real_filtered = tf.nn.conv1d(upsampled_signal[:, :, 0:1], rrc, stride=1, padding='SAME')\n",
        "        imag_filtered = tf.nn.conv1d(upsampled_signal[:, :, 1:2], rrc, stride=1, padding='SAME')\n",
        "\n",
        "\n",
        "        real_filtered = real_filtered * tf.math.cos(self.phase_offset())-imag_filtered * tf.math.sin(self.phase_offset())\n",
        "        imag_filtered = imag_filtered * tf.math.sin(self.phase_offset())+real_filtered * tf.math.cos(self.phase_offset())\n",
        "\n",
        "        filtered_signal = tf.concat([real_filtered, imag_filtered], axis=2)\n",
        "        filtered_signal = tf.squeeze(filtered_signal, axis=0)  # Remove the batch dimension\n",
        "        return filtered_signal\n",
        "\n",
        "    def time_offset(self, sampling_time=0.5e-6):\n",
        "        t_offset = np.random.uniform(-sampling_time , sampling_time )\n",
        "        return t_offset\n",
        "\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        f = inputs.shape[1] // 2\n",
        "\n",
        "        # Reshape to pairs of real and imaginary parts\n",
        "        inputs = tf.reshape(inputs, [batch_size, -1, 2])  # Shape: (batch_size, num_pairs, 2)\n",
        "        print(inputs.shape)\n",
        "        # Define a function to process each sample\n",
        "        def process_sample(sample):\n",
        "            filtered_signal = self.upsample_and_filter(sample)  # Process each sample\n",
        "            return filtered_signal\n",
        "\n",
        "        # Apply the function to each sample in the batch\n",
        "        output = tf.map_fn(process_sample, inputs, dtype=tf.float32)  # Shape: (batch_size, num_filtered_samples, 2)\n",
        "\n",
        "        # Reshape back to original shape if necessary\n",
        "        output = tf.reshape(output, [batch_size, -1])\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tlKQ0A5D2HI"
      },
      "source": [
        "##Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97Xi8J9KD2HI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57d3e85c-4086-4680-9ef8-b8b4c6236062"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of train samples: 5440\n",
            "Number of validation samples: 960\n",
            "Number of test samples: 3072\n",
            "Number of train samples padded: 5452\n",
            "Number of validation samples padded: 972\n",
            "Number of test samples padded: 3084\n"
          ]
        }
      ],
      "source": [
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "\n",
        "# Dataset Parameters\n",
        "N = 4  # Number of channel uses\n",
        "K = 8  # Block size (log2 of the number of messages)\n",
        "M = 2**K  # Number of possible messages (2^K)\n",
        "batch_size = 6400\n",
        "output = 2**K\n",
        "Eb_No = 15  # Signal-to-Noise ratio in dB\n",
        "\n",
        "# Create Dataset with Integer Labels\n",
        "train_dataset = np.tile(np.arange(M), batch_size // M)\n",
        "test_dataset = np.tile(np.arange(M), batch_size  //(2*M))\n",
        "\n",
        "# Shuffle the dataset\n",
        "np.random.shuffle(train_dataset)\n",
        "np.random.shuffle(test_dataset)\n",
        "\n",
        "# Define split ratios\n",
        "train_ratio = 0.85  # 85% for training\n",
        "val_ratio = 0.15    # 15% for validation\n",
        "\n",
        "# Calculate the number of samples\n",
        "num_train_samples = int(len(train_dataset) * train_ratio)\n",
        "num_val_samples = len(train_dataset) - num_train_samples\n",
        "\n",
        "# Split the datasets\n",
        "train_set = train_dataset[:num_train_samples]\n",
        "val_set = train_dataset[num_train_samples:]\n",
        "\n",
        "# Reshape the datasets if needed\n",
        "train_set = train_set.reshape((-1, 1))\n",
        "val_set = val_set.reshape((-1, 1))\n",
        "test_dataset = test_dataset.reshape((-1, 1))\n",
        "\n",
        "# Pad the test dataset with 6 zeros before and after\n",
        "padding = np.zeros((6, 1), dtype=int)\n",
        "train_set_padded = np.vstack([padding, train_set, padding])\n",
        "val_set_padded = np.vstack([padding, val_set, padding])\n",
        "test_dataset_padded = np.vstack([padding, test_dataset, padding])\n",
        "\n",
        "# Print dataset sizes\n",
        "print(f\"Number of train samples: {len(train_set)}\")\n",
        "print(f\"Number of validation samples: {len(val_set)}\")\n",
        "print(f\"Number of test samples: {len(test_dataset)}\")\n",
        "print(f\"Number of train samples padded: {len(train_set_padded)}\")\n",
        "print(f\"Number of validation samples padded: {len(val_set_padded)}\")\n",
        "print(f\"Number of test samples padded: {len(test_dataset_padded)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA0q0y0RD2HI"
      },
      "source": [
        "##Custom Noise, Normalization layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGfeHPY8D2HI"
      },
      "outputs": [],
      "source": [
        "# Custom Noise Layer\n",
        "class CustomNoise(tf.keras.layers.Layer):\n",
        "    def __init__(self, mean=0.0, stddev=10**(-1.0*Eb_No), **kwargs):\n",
        "        super(CustomNoise, self).__init__(**kwargs)\n",
        "        self.mean = mean\n",
        "        self.stddev = stddev\n",
        "\n",
        "    def call(self, inputs):\n",
        "        noise = tf.random.normal(shape=tf.shape(inputs), mean=self.mean, stddev=self.stddev)\n",
        "        return inputs + noise\n",
        "\n",
        "# class Normalization(tf.keras.layers.Layer):\n",
        "#     def __init__(self, **kwargs):\n",
        "#         super(Normalization, self).__init__(**kwargs)\n",
        "\n",
        "#     def call(self, input):\n",
        "#         out = tf.nn.l2_normalize(tf.reshape(input, (-1, 2)), axis=-1, epsilon=1e-6)\n",
        "#         out = tf.reshape(out, (-1, 2*N))\n",
        "#         print(\"normalization layer output shape:\" ,str(out.shape))\n",
        "#         return out\n",
        "#     def get_config(self):\n",
        "#         config = super(Normalization, self).get_config()\n",
        "#         return config\n",
        "\n",
        "\n",
        "class Normalization(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(Normalization, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, input):\n",
        "        # Perform L2 normalization on the last dimension while keeping the overall shape\n",
        "        out = tf.nn.l2_normalize(input, axis=-1, epsilon=1e-6)\n",
        "        # print(\"Normalization layer output shape:\", out.shape)\n",
        "        return out\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(Normalization, self).get_config()\n",
        "        return config\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zORpoJ4D2HJ"
      },
      "source": [
        "##Sequence Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3CRAArgD2HJ"
      },
      "outputs": [],
      "source": [
        "class SD(tf.keras.layers.Layer):\n",
        "    def __init__(self, l=6, n=4, r=4, **kwargs):\n",
        "        super(SD, self).__init__(**kwargs)\n",
        "        self.l = l\n",
        "        self.n = n\n",
        "        self.r = r\n",
        "\n",
        "        with tf.name_scope(\"fe\"):\n",
        "            self.fe = Sequential([\n",
        "                Dense(256, activation='relu', name='initial'),\n",
        "                Dense(8, activation='linear', name='feature_extractor')\n",
        "            ])\n",
        "\n",
        "        with tf.name_scope(\"pe\"):\n",
        "            self.pe = Sequential([\n",
        "                Dense(256, activation='relu', name='initial'),\n",
        "                Dense(128, activation='relu', name='phase_estimator_dense1'),\n",
        "                Dense(2, activation='linear', name='phase_estimator')\n",
        "            ])\n",
        "\n",
        "        with tf.name_scope(\"oe\"):\n",
        "            self.oe = Sequential([\n",
        "                Dense(256, activation='relu', name='initial'),\n",
        "                Dense(128, activation='relu', name='oe_dense1'),\n",
        "                Dense(32, activation='relu', name='oe_dense2'),\n",
        "                Dense(16, activation='softmax', name='offset_estimator'),\n",
        "\n",
        "            ])\n",
        "\n",
        "    def mini_slicer(self, inputs):\n",
        "        # in_dim = tf.shape(inputs)[1]\n",
        "        N_msg = self.r * self.n\n",
        "        l1 = 30 + (self.l) *2* N_msg #- self.r,   here 30 is number of paddings, since num_taps=31 (num_taps//2)*2\n",
        "        l2 = 30 + (self.l+1) *2* N_msg\n",
        "        # out_1 = inputs[:, l1-1:l2]\n",
        "        # out_2 = inputs[:, in_dim // 2 + l1-1:in_dim // 2 + l2]\n",
        "        # output = tf.concat([out_1, out_2], axis=1)\n",
        "        output = inputs[:, l1:l2]\n",
        "        print('mini slice output shape', output.shape)\n",
        "        return output\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Get the input dimension (before slicing)\n",
        "        bs = inputs.shape[0]\n",
        "\n",
        "        # inputs = tf.reshape(inputs,[bs,-1,2])\n",
        "        # real = inputs[:, :, 0]  # Real part\n",
        "        # imag = inputs[:, :, 1]  # Imaginary part\n",
        "\n",
        "        # Process the inputs using mini_slicer (this changes the shape of inputs)\n",
        "\n",
        "        # # Update real and imag slices based on new input shape (after mini_slicer)\n",
        "        # half_dim = tf.shape(inputs)[1] // 2  # Get new half dimension after slicing\n",
        "        # real = inputs[:, :half_dim]  # First half of sliced inputs as real part\n",
        "        # imag = inputs[:, half_dim:]  # Second half as imaginary part\n",
        "\n",
        "        # Pass the sliced inputs to the phase estimator model to get h\n",
        "        h = self.pe(inputs)  # h has shape (batch_size, 2)\n",
        "        h_real = h[:, 0]  # Extract real part of h\n",
        "        h_imag = h[:, 1]  # Extract imaginary part of h\n",
        "\n",
        "        h_real = tf.expand_dims(h_real, axis=1)\n",
        "        h_imag = tf.expand_dims(h_imag, axis=1)\n",
        "\n",
        "        # # Perform element-wise multiplication\n",
        "        # h_real_ex = tf.tile(h_real, [1, half_dim])\n",
        "        # h_imag_ex = tf.tile(h_imag, [1, half_dim])\n",
        "        # real_mul = real * h_real_ex -imag*h_imag_ex # Multiply same value of real part to every component of the input\n",
        "        # imag_mul = real * h_imag_ex + imag*h_real_ex # Multiply same value of imag part to every component of the input\n",
        "\n",
        "        # Apply the feature extractor model to real_mul (as an example)\n",
        "        feature_extract_output = self.fe(inputs)\n",
        "        offset_estimator_output = self.oe(inputs)\n",
        "        mini_inputs = self.mini_slicer(inputs)\n",
        "\n",
        "        # Concatenate the outputs\n",
        "        output = tf.concat([mini_inputs,h, feature_extract_output,offset_estimator_output], axis=1)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class SD_RNN(tf.keras.layers.Layer):\n",
        "    def __init__(self, l=6, n=4, r=4, units=16, **kwargs):\n",
        "        super(SD_RNN, self).__init__(**kwargs)\n",
        "        self.l = l\n",
        "        self.n = n\n",
        "        self.r = r\n",
        "        self.units = units  # RNN units\n",
        "\n",
        "        with tf.name_scope(\"fe\"):\n",
        "            # Use LSTM or GRU for feature extractor\n",
        "            self.fe = Sequential([\n",
        "                Reshape((1, 92)),\n",
        "                LSTM(self.units, return_sequences=True, name='feature_extractor_lstm'),\n",
        "                Flatten(),# or use GRU\n",
        "                Dense(8, activation='linear', name='feature_extractor_output')\n",
        "            ])\n",
        "\n",
        "        with tf.name_scope(\"pe\"):\n",
        "            # Use LSTM or GRU for phase estimator\n",
        "            self.pe = Sequential([\n",
        "                Reshape((1, 92)),\n",
        "                LSTM(self.units, return_sequences=True, name='phase_estimator_lstm'),\n",
        "                Flatten(),# or use GRU\n",
        "                Dense(2, activation='linear', name='phase_estimator_output')\n",
        "            ])\n",
        "\n",
        "        with tf.name_scope(\"oe\"):\n",
        "            self.oe = Sequential([\n",
        "                 Reshape((1, 92)),\n",
        "                LSTM(self.units, return_sequences=True, name='offset_estimator_lstm'),\n",
        "                LSTM(self.units, return_sequences=True, name='offset_estimator_lstm1'),\n",
        "                LSTM(self.units//2, return_sequences=True, name='offset_estimator_lstm2'),\n",
        "                Flatten(),\n",
        "                Dense(1, activation='linear', name='offset_estimator'),\n",
        "\n",
        "            ])\n",
        "\n",
        "\n",
        "\n",
        "    def mini_slicer(self, inputs):\n",
        "        in_dim = tf.shape(inputs)[1]\n",
        "        N_msg = self.r * self.n\n",
        "        l1 = 1 + (self.l + 1) * N_msg - self.r\n",
        "        l2 = self.l * N_msg + self.r\n",
        "        out_1 = inputs[:, l1-1:l2]\n",
        "        out_2 = inputs[:, in_dim // 2 + l1-1:in_dim // 2 + l2]\n",
        "        output = tf.concat([out_1, out_2], axis=1)\n",
        "        print('mini slice output shape', output.shape)\n",
        "        return output\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Get the input dimension (before slicing)\n",
        "        in_dim = inputs.shape[1]\n",
        "\n",
        "        # Process the inputs using mini_slicer (this changes the shape of inputs)\n",
        "        # inputs = self.mini_slicer(inputs)\n",
        "\n",
        "        # Update real and imag slices based on new input shape (after mini_slicer)\n",
        "        half_dim = tf.shape(inputs)[1] // 2  # Get new half dimension after slicing\n",
        "        real = inputs[:, :half_dim]  # First half of sliced inputs as real part\n",
        "        imag = inputs[:, half_dim:]  # Second half as imaginary part\n",
        "\n",
        "        # Pass the sliced inputs to the phase estimator model to get h\n",
        "        h = self.pe(inputs)  # h has shape (batch_size, 2)\n",
        "        h_real = h[:, 0]  # Extract real part of h\n",
        "        h_imag = h[:, 1]  # Extract imaginary part of h\n",
        "\n",
        "        h_real = tf.expand_dims(h_real, axis=1)\n",
        "        h_imag = tf.expand_dims(h_imag, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "        # # Perform element-wise multiplication\n",
        "        # h_real_ex = tf.tile(h_real, [1, half_dim])\n",
        "        # h_imag_ex = tf.tile(h_imag, [1, half_dim])\n",
        "        # real_mul = real * h_real_ex -imag*h_imag_ex # Multiply same value of real part to every component of the input\n",
        "        # imag_mul = real * h_imag_ex + imag*h_real_ex # Multiply same value of imag part to every component of the input\n",
        "\n",
        "        # Apply the feature extractor model to real_mul (as an example)\n",
        "        feature_extract_output = self.fe(inputs)\n",
        "        offset_estimator_output = self.oe(inputs)\n",
        "\n",
        "        # Concatenate the outputs\n",
        "        output = tf.concat([real, imag,offset_estimator_output,h_real,h_imag, feature_extract_output], axis=1)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RreOOguRD2HJ"
      },
      "source": [
        "##Autoencoder model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "B5vrynJPD2HJ",
        "outputId": "2ca4b2f7-c1f7-461d-9245-5b719c087ca0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 984ms/step - accuracy: 1.0000 - loss: 0.0715 - val_accuracy: 1.0000 - val_loss: 0.5559\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.5440\n",
            "Test Loss: 0.5448, Test Accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# Autoencoder Class with Convolutional Layers\n",
        "class AE:\n",
        "    def __init__(self, train_data, val_data, test_data, input_dim=K, enc_dim=N, act_fun='relu'):\n",
        "        self.train_data = train_data\n",
        "        self.val_data = val_data\n",
        "        self.test_data = test_data\n",
        "        self.input_dim = input_dim\n",
        "        self.enc_dim = enc_dim\n",
        "        self.act_fun = act_fun\n",
        "\n",
        "\n",
        "    def AE_implement(self):\n",
        "        autoencoder = Sequential([\n",
        "            Input(shape=(1,),batch_size = batch_size),  # Add this input layer\n",
        "            # Embedding Layer (Input: message indices)\n",
        "            Embedding(input_dim=M, output_dim=256, input_length=1, name=\"Embedding\"),\n",
        "            Flatten(),  # Flatten output to feed into Conv1D layers\n",
        "\n",
        "            # Encoder (Multiple Conv1D layers)\n",
        "            Reshape((1, 256)),  # Reshape for Conv1D\n",
        "            Conv1D(256, kernel_size=1, activation='elu', name=\"Conv1D_1\"),\n",
        "            Conv1D(128, kernel_size=1, activation='elu', name=\"Conv1D_2\"),\n",
        "            Conv1D(64, kernel_size=1, activation='elu', name=\"Conv1D_3\"),\n",
        "            Conv1D(2*N, kernel_size=1, activation='linear', name=\"Conv1D_4\"),\n",
        "\n",
        "            # # Power Normalization Layer (L2 normalization over 2N dimensions)\n",
        "            # tf.keras.layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=-1)),\n",
        "\n",
        "            Normalization(input_shape=(1, 8),name= \"normal\"),\n",
        "            # Custom Noise Layer (Simulating the channel)\n",
        "            SlidingWindowConcatLayer1(window_size=13,name=\"sliding_window\"),\n",
        "            StochasticChannelv3(name=\"StochasticChannel\"),\n",
        "            CustomNoise(name=\"NoiseLayer\"),\n",
        "            SD(name=\"SD\"),\n",
        "\n",
        "            Reshape((1, 58)),  # Reshape for Conv1D_dec1\n",
        "            # Decoder (Conv1D layers to reconstruct the input)\n",
        "            Conv1D(64, kernel_size=1, activation='elu', name=\"Conv1D_Dec1\"),\n",
        "            Conv1D(128, kernel_size=1, activation='elu', name=\"Conv1D_Dec2\"),\n",
        "            Conv1D(256, kernel_size=1, activation='elu', name=\"Conv1D_Dec3\"),\n",
        "\n",
        "            # Output Layer with Softmax to predict the message index\n",
        "            Flatten(),\n",
        "            Dense(output, activation='softmax', name=\"Output\")\n",
        "        ])\n",
        "\n",
        "        # Compile the model\n",
        "        autoencoder.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005,beta_1=0.9, beta_2=0.999,epsilon=1e-07),\n",
        "                            loss='sparse_categorical_crossentropy',\n",
        "                            metrics=['accuracy'])\n",
        "        return autoencoder\n",
        "\n",
        "\n",
        "        # Training Class with Early Stopping and Plotting\n",
        "    def train(self, epochs=40, batch_size=32):\n",
        "        autoencoder = self.AE_implement()\n",
        "\n",
        "        log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "        tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "        history = autoencoder.fit(self.train_data, self.train_data,\n",
        "                                  epochs=epochs, batch_size=batch_size,\n",
        "                                  validation_data=(self.val_data, self.val_data),\n",
        "                                  callbacks=[PlottingCallback(), tensorboard_callback])\n",
        "        return autoencoder, history\n",
        "\n",
        "\n",
        "# Custom Callback for Real-time Plotting\n",
        "class PlottingCallback(Callback):\n",
        "    def __init__(self):\n",
        "        super(PlottingCallback, self).__init__()\n",
        "        self.history = {'accuracy': [], 'val_accuracy': [], 'loss': [], 'val_loss': []}\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.history['accuracy'].append(logs.get('accuracy'))\n",
        "        self.history['val_accuracy'].append(logs.get('val_accuracy'))\n",
        "        self.history['loss'].append(logs.get('loss'))\n",
        "        self.history['val_loss'].append(logs.get('val_loss'))\n",
        "\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        plt.figure(figsize=(12, 5))\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(self.history['accuracy'], label='Training Accuracy')\n",
        "        plt.plot(self.history['val_accuracy'], label='Validation Accuracy')\n",
        "        plt.title('Accuracy over Epochs')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(self.history['loss'], label='Training Loss')\n",
        "        plt.plot(self.history['val_loss'], label='Validation Loss')\n",
        "        plt.title('Loss over Epochs')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Instantiate and Train\n",
        "ae = AE(train_data=train_set, val_data=val_set, test_data=test_dataset, input_dim=K, enc_dim=N, act_fun='tanh')\n",
        "autoencoder_model, history = ae.train(epochs=100, batch_size=batch_size)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = autoencoder_model.evaluate(test_dataset, test_dataset)\n",
        "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784
        },
        "id": "k3cuhYlTD2HJ",
        "outputId": "b74cdd2c-38d5-4390-f408-5d6b12b125fb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ Embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │          \u001b[38;5;34m65,536\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)                    │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_1 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │          \u001b[38;5;34m65,792\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_2 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │          \u001b[38;5;34m32,896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_3 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_4 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)                │             \u001b[38;5;34m520\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ normal (\u001b[38;5;33mNormalization\u001b[0m)               │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ sliding_window                       │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m104\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mSlidingWindowConcatLayer1\u001b[0m)          │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ StochasticChannel                    │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m476\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mStochasticChannelv3\u001b[0m)                │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ NoiseLayer (\u001b[38;5;33mCustomNoise\u001b[0m)             │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m476\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ SD (\u001b[38;5;33mSD\u001b[0m)                              │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m58\u001b[0m)                  │         \u001b[38;5;34m439,098\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m)                  │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m58\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_Dec1 (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │           \u001b[38;5;34m3,776\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_Dec2 (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │           \u001b[38;5;34m8,320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_Dec3 (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │          \u001b[38;5;34m33,024\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Output (\u001b[38;5;33mDense\u001b[0m)                       │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │          \u001b[38;5;34m65,792\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ Embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,536</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ normal (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ sliding_window                       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SlidingWindowConcatLayer1</span>)          │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ StochasticChannel                    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">476</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">StochasticChannelv3</span>)                │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ NoiseLayer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CustomNoise</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">476</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ SD (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SD</span>)                              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">439,098</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_Dec1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,776</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_Dec2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_Dec3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,169,032\u001b[0m (8.27 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,169,032</span> (8.27 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m723,010\u001b[0m (2.76 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">723,010</span> (2.76 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,446,022\u001b[0m (5.52 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,446,022</span> (5.52 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "autoencoder_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uj9Gk-9LQJap",
        "outputId": "ceb20187-1004-459b-beb4-6af290d421be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tf_keras in /usr/local/lib/python3.11/dist-packages (2.17.0)\n",
            "Requirement already satisfied: tensorflow<2.18,>=2.17 in /usr/local/lib/python3.11/dist-packages (from tf_keras) (2.17.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (24.12.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (1.69.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow<2.18,>=2.17->tf_keras) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf_keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf_keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf_keras) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf_keras) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf_keras) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf_keras) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf_keras) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf_keras) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf_keras) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf_keras) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf_keras) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf_keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf_keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf_keras) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install tf_keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oB0P4zAwQErR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
        "import tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5tP782iQPzQ"
      },
      "outputs": [],
      "source": [
        "import tf_keras as keras\n",
        "from tf_keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJZkYd-vQfee"
      },
      "outputs": [],
      "source": [
        "autoencoder_model.save(\"myModelTF.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYng43bUtz0t",
        "outputId": "60e306a8-afea-451f-cd2d-189a499d5dc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "autoencoder_model.save('autoencoder_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6TWT_tYKhQE"
      },
      "source": [
        "### Encoder and Decoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "zYDPH2028gkZ",
        "outputId": "b3d9852a-dee0-4ba3-ae97-e36f5d371bed"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │          \u001b[38;5;34m65,536\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)                    │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_1 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │          \u001b[38;5;34m65,792\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_2 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │          \u001b[38;5;34m32,896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_3 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_4 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)                │             \u001b[38;5;34m520\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ normal (\u001b[38;5;33mNormalization\u001b[0m)               │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ sliding_window                       │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m104\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mSlidingWindowConcatLayer1\u001b[0m)          │                             │                 │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,536</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ normal (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ sliding_window                       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SlidingWindowConcatLayer1</span>)          │                             │                 │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m173,000\u001b[0m (675.78 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">173,000</span> (675.78 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m173,000\u001b[0m (675.78 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">173,000</span> (675.78 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "encode_output = autoencoder_model.get_layer('sliding_window').output\n",
        "input_tensor = autoencoder_model.get_layer(name='Embedding').input\n",
        "Encoder = tf.keras.Model(inputs=input_tensor, outputs=encode_output)\n",
        "Encoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "tXEuVU459ZQ2",
        "outputId": "929133ea-a605-4607-938b-770d827270e8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ keras_tensor_11CLONE (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m476\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ SD (\u001b[38;5;33mSD\u001b[0m)                              │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m58\u001b[0m)                  │         \u001b[38;5;34m439,098\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m)                  │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m58\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_Dec1 (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │           \u001b[38;5;34m3,776\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_Dec2 (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │           \u001b[38;5;34m8,320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_Dec3 (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │          \u001b[38;5;34m33,024\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Output (\u001b[38;5;33mDense\u001b[0m)                       │ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │          \u001b[38;5;34m65,792\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ keras_tensor_11CLONE (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">476</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ SD (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SD</span>)                              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">439,098</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_Dec1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,776</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_Dec2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Conv1D_Dec3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m550,010\u001b[0m (2.10 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">550,010</span> (2.10 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m550,010\u001b[0m (2.10 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">550,010</span> (2.10 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "decoder_input = autoencoder_model.get_layer('SD').input\n",
        "output_tensor = autoencoder_model.get_layer(name='Output').output\n",
        "Decoder = tf.keras.Model(inputs=decoder_input, outputs=output_tensor)\n",
        "Decoder.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLhxRjiAEf6Y"
      },
      "source": [
        "## Encoded msgs of Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUaB5JzM85_e",
        "outputId": "fa0f586e-ba19-4b0e-95a3-3489dc656180"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "(5440, 104)\n",
            "(960, 104)\n",
            "(3072, 104)\n"
          ]
        }
      ],
      "source": [
        "from scipy.io import savemat\n",
        "\n",
        "Encoder_train_set = Encoder.predict(train_set)\n",
        "Encoder_train_set = tf.squeeze(Encoder_train_set, axis=1)\n",
        "Encoder_train_set = Encoder_train_set.numpy()\n",
        "\n",
        "Encoder_Val_set = Encoder.predict(val_set)\n",
        "Encoder_Val_set = tf.squeeze(Encoder_Val_set, axis=1)\n",
        "Encoder_Val_set = Encoder_Val_set.numpy()\n",
        "\n",
        "Encoder_Test_set = Encoder.predict(test_dataset)\n",
        "Encoder_Test_set = tf.squeeze(Encoder_Test_set, axis=1)\n",
        "Encoder_Test_set = Encoder_Test_set.numpy()\n",
        "\n",
        "savemat('Encoder_Train_set.mat', {'Encoder_Train_set': Encoder_train_set})\n",
        "savemat('Encoder_Val_set.mat', {'Encoder_Val_set': Encoder_Val_set})\n",
        "savemat('Encoder_Test_set.mat', {'Encoder_Test_set': Encoder_Test_set})\n",
        "\n",
        "print(Encoder_train_set.shape)\n",
        "print(Encoder_Val_set.shape)\n",
        "print(Encoder_Test_set.shape)\n",
        "# savemat('Encoder_Train_set.mat', {'Encoder_Train_set': Encoder_Train_set})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irZm83pgEt-L"
      },
      "source": [
        "## Alphabet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "177NFYTrEwfV",
        "outputId": "e132157e-8b13-4d11-eec6-98663aec08d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3328, 1)\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n"
          ]
        }
      ],
      "source": [
        "alphabet = np.tile(np.arange(M),13)\n",
        "alphabet = alphabet.reshape(-1,1)\n",
        "print(alphabet.shape)\n",
        "pad = np.zeros((6,1),dtype=int)\n",
        "alphabet = np.vstack([pad,alphabet,pad])\n",
        "alphabet = Encoder.predict(alphabet)\n",
        "alphabet = tf.squeeze(alphabet, axis=1)\n",
        "\n",
        "alphabet = alphabet.numpy()\n",
        "\n",
        "savemat('alphabet.mat', {'alphabet': alphabet})\n",
        "\n",
        "# print(alphabet+1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}