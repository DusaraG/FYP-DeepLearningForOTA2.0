{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d1t9MwKcF0L"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xCUL62ObyvP"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam,SGD\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tensorflow.keras.metrics import MeanSquaredError\n",
        "from tensorflow.keras.callbacks import Callback, TensorBoard, EarlyStopping\n",
        "from IPython.display import clear_output\n",
        "import datetime\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import convolve\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "from tensorflow.keras.layers import Input,Conv1D, Dense, Flatten, Embedding, Reshape, Softmax,LayerNormalization, MultiHeadAttention, Add, Dropout,Normalization\n",
        "from tensorflow.keras import Sequential\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import Callback, TensorBoard\n",
        "from IPython.display import clear_output\n",
        "from tensorflow.keras.layers import Dense, LSTM, GRU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctyb2PyyUKUB"
      },
      "source": [
        "# Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTlEUj8iUBAJ"
      },
      "outputs": [],
      "source": [
        "Number_channel_uses = 1 # it defines the number of symbols per messages. at a time one symbol can be transmitted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjYVqighRYIx"
      },
      "outputs": [],
      "source": [
        "Eb_No = 10  # This should be a variable so that it can be used in the dictionary\n",
        "from scipy.stats import truncnorm\n",
        "from scipy.stats import uniform\n",
        "channel_parameters = {\n",
        "    \"r\"        : 4,                # For upsampling -> number of complex samples per symbol\n",
        "    \"Eb_No\"    : Eb_No,            # Energy per bit to noise power spectral density ratio\n",
        "    \"roll_off\" : 0.35,             # Roll off factor\n",
        "    \"num_taps\" : 31,               # L -> Number of taps (odd) for RRC filter\n",
        "    \"f_s\"      : 25e4,             # Sampling frequency\n",
        "    \"T_bound\"  : 1/25e4,           # 1/f_s (symbol duration in seconds)\n",
        "    \"time_delay\" : np.random.uniform(-1,1),  # Random time delay in the range [-1, 1]\n",
        "    \"CFO\"      : 5e3,              # Carrier Frequency Offset in Hz\n",
        "    \"CFO_std\"  : 5e3/25e4,         # Normalized Carrier Frequency Offset\n",
        "    \"noise_std\": 10**(-1.0 * Eb_No / 10),  # Noise standard deviation, calculated from Eb_No\n",
        "    \"phase_off\": uniform.rvs(scale=2*np.pi)  # Random phase offset in the range [0, 2Ï€]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cfFtgnPRtdZ"
      },
      "source": [
        "# Real to complex conversion and pulse shaping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-P18yQa9jLc0"
      },
      "outputs": [],
      "source": [
        "# upsampling\n",
        "\n",
        "# Function to perform upsampling by a factor of r\n",
        "def upsampling(inp, r):\n",
        "    com_reshape = tf.reshape(inp, [-1, 1])\n",
        "    padding = tf.constant([[0, 0], [0, r - 1]])\n",
        "    upsampled = tf.pad(com_reshape, padding, mode=\"CONSTANT\")\n",
        "    upsampled = tf.reshape(upsampled, [-1])  # Flatten back to 1D\n",
        "    return upsampled\n",
        "\n",
        "# Function to perform upsampling on IQ signals\n",
        "def upsample_iq(inp, r):\n",
        "    real = inp[:, 0]  # Real part\n",
        "    imag = inp[:, 1]  # Imaginary part\n",
        "\n",
        "    # Upsample both real and imaginary parts\n",
        "    real_up = upsampling(real, r)\n",
        "    imag_up = upsampling(imag, r)\n",
        "\n",
        "    # Combine the upsampled real and imaginary parts\n",
        "    upsampled = tf.stack([real_up, imag_up], axis=1)\n",
        "    return upsampled\n",
        "\n",
        "# Function to do pulse shaping with NRRC code\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from scipy.signal import lfilter\n",
        "\n",
        "# Function to create a normalized RRC filter\n",
        "def rrc_filter(alpha, sps, num_taps, ts = 1):\n",
        "    \"\"\"\n",
        "    Create a root-raised cosine (RRC) filter.\n",
        "\n",
        "    Args:\n",
        "        ts: Sampling period (default is 1).\n",
        "        alpha: Roll-off factor (0 <= alpha <= 1).\n",
        "        sps: Samples per symbol (upsampling factor).\n",
        "        num_taps: Number of filter taps (should be odd).\n",
        "\n",
        "    Returns:\n",
        "        RRC filter coefficients.\n",
        "    \"\"\"\n",
        "    t = np.linspace(-num_taps//2, num_taps//2 + 1,num_taps) - 2\n",
        "    rrc = np.zeros_like(t)\n",
        "\n",
        "    for i in range(len(t)):\n",
        "        if t[i] == 0.0:\n",
        "            rrc[i] = (1.0 - alpha + 4 * alpha / np.pi)/ts\n",
        "        elif np.abs(t[i]) == ts / (4 * alpha):\n",
        "            rrc[i] = (alpha /( np.sqrt(2)*ts)) * \\\n",
        "                     ((1 + 2/np.pi) * np.sin(np.pi / (4 * alpha)) +\n",
        "                      (1 - 2/np.pi) * np.cos(np.pi / (4 * alpha)))\n",
        "        else:\n",
        "            rrc[i] = (np.sin(np.pi * (t[i]/ts) * (1 - alpha)) +\n",
        "                      4 * alpha * (t[i]/ts) * np.cos(np.pi * (t[i]/ts) * (1 + alpha))) / \\\n",
        "                     (np.pi * t[i] * (1 - (4 * alpha * (t[i]/ts))**2))\n",
        "\n",
        "    # Normalize filter coefficients to ensure unit energy\n",
        "    rrc = rrc / np.sqrt(np.sum(rrc**2))\n",
        "    rrc = tf.constant(rrc, dtype=tf.float32)\n",
        "    # plt.stem(t,rrc)  # Plot for visualization\n",
        "    # plt.title(f\"Time_delay = {10}\")\n",
        "    return rrc\n",
        "\n",
        "\n",
        "# Function to apply upsampling and filtering using conv1d\n",
        "def upsample_and_filter(signal, r, alpha, num_taps):\n",
        "    # Upsample the signal\n",
        "    upsampled_signal = upsample_iq(signal, r)\n",
        "\n",
        "    # Create the RRC filter\n",
        "    rrc = rrc_filter(alpha, r, num_taps)\n",
        "\n",
        "    # Add a batch and channel dimension for conv1d\n",
        "    upsampled_signal = tf.expand_dims(upsampled_signal, axis=0)  # Shape: (1, length, 2)\n",
        "    rrc = tf.reshape(rrc, [-1, 1, 1])  # Shape: (filter_length, 1, 1)\n",
        "\n",
        "    padding_size = num_taps//2\n",
        "    paddings = tf.constant([[0, 0], [padding_size, padding_size], [0, 0]])\n",
        "    padded_real = tf.pad(upsampled_signal[:, :, 0:1], paddings, \"CONSTANT\")\n",
        "    padded_imag = tf.pad(upsampled_signal[:, :, 1:2], paddings, \"CONSTANT\")\n",
        "    upsampled_signal = tf.concat([padded_real, padded_imag], axis=2)\n",
        "    print('upsampled shape', upsampled_signal.shape)\n",
        "    # Apply the RRC filter using conv1d\n",
        "    real_filtered = tf.nn.conv1d(upsampled_signal[:, :, 0:1], rrc, stride=1, padding='SAME')\n",
        "    imag_filtered = tf.nn.conv1d(upsampled_signal[:, :, 1:2], rrc, stride=1, padding='SAME')\n",
        "\n",
        "    # Combine filtered real and imaginary parts\n",
        "    filtered_signal = tf.concat([real_filtered, imag_filtered], axis=2)\n",
        "    filtered_signal = tf.squeeze(filtered_signal, axis=0)  # Remove the batch dimension\n",
        "\n",
        "    return filtered_signal\n",
        "\n",
        "def time_offset(sampling_time = 10 ):\n",
        "  t_offset = np.random.uniform(-sampling_time//2, sampling_time//2)\n",
        "  return t_offset\n",
        "\n",
        "# def signal_sample(received_signal,fs=1,s_rate = 10,num_taps\n",
        "\n",
        "# def signal_sample(received_signal,fs=1,s_rate = 10,num_taps):\n",
        "#     sampling_rate = s_rate*fs\n",
        "#     signal_sample = received_signal[::sampling_rate]\n",
        "\n",
        "#     x_axis = np.arange(-num_taps//2, num_taps//2 + 1) / s_rate\n",
        "#     plt.stem(x_axis[:len(signal_sample)], signal_sample)  # Plot for visualization\n",
        "#     plt.title(f\"Time_delay = {10}\")\n",
        "#     return signal_sample\n",
        "\n",
        "\n",
        "def pulse_shape_decode(received_signal, fs, alpha, num_taps):\n",
        "    # fs  = sampling frequency\n",
        "    # get the samples from received signal tapping\n",
        "\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "\n",
        "# Define parameters\n",
        "r = 4  # Upsampling factor\n",
        "alpha = 0.35  # Roll-off factor\n",
        "num_taps = 2  # Number of filter taps (should be odd)\n",
        "\n",
        "# # Example input: Complex signal with real and imaginary parts\n",
        "# input_signal = tf.constant([[1.0, -1.0]])\n",
        "\n",
        "# # Apply upsampling and RRC filtering\n",
        "# filtered_signal = upsample_and_filter(input_signal, r, alpha, num_taps)\n",
        "\n",
        "# filtered_signal_real = filtered_signal[:, 0].numpy()\n",
        "# # sampled_signal = signal_sample(filtered_signal_real,fs=1,s_rate = 10)\n",
        "\n",
        "\n",
        "# # Generate x-axis data with matching length\n",
        "# x_axis = np.arange(-num_taps//2, num_taps//2 + 1) / r\n",
        "\n",
        "# plt.stem(x_axis[:len(filtered_signal_real)], filtered_signal_real)  # Plot for visualization\n",
        "# plt.title(f\"Time_delay = {10}\")\n",
        "# print(\"Filtered Signal:\")\n",
        "# print(len(filtered_signal))\n",
        "\n",
        "\n",
        "# Example input: Complex signal with real and imaginary parts\n",
        "input_signal = tf.constant([[1.0, -1.0]])  # Example input signal with 2 samples\n",
        "\n",
        "print(f\"Input signal length: {len(input_signal)}\")\n",
        "\n",
        "# Apply upsampling and RRC filtering\n",
        "filtered_signal = upsample_and_filter(input_signal, r, alpha, num_taps)\n",
        "\n",
        "# Print lengths\n",
        "upsampled_signal_length = len(upsample_iq(input_signal, r))\n",
        "expected_output_length = upsampled_signal_length + num_taps - 1\n",
        "print(f\"Upsampled signal length: {upsampled_signal_length}\")\n",
        "print(f\"Expected output length: {expected_output_length}\")\n",
        "print(f\"Actual filtered signal length: {len(filtered_signal)}\")\n",
        "\n",
        "# Visualize the filtered signal\n",
        "filtered_signal_real = filtered_signal[:, 0].numpy()\n",
        "\n",
        "# Generate x-axis data with matching length\n",
        "x_axis = np.arange(len(filtered_signal_real))\n",
        "\n",
        "plt.stem(x_axis, filtered_signal_real)  # Plot for visualization\n",
        "plt.title(f\"Filtered Signal with Time_delay = {10}\")\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puZ_hL-rjBPL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import lfilter\n",
        "\n",
        "# function to create the complex values\n",
        "def real_to_complex_tensor(inp_tensor):\n",
        "  inp_tensor = tf.reshape(inp_tensor, [-1, 2])\n",
        "  real_part = inp_tensor[:, 0]\n",
        "  imag_part = inp_tensor[:, 1]\n",
        "  complex_tensor = tf.complex(real_part, imag_part)\n",
        "  return complex_tensor\n",
        "\n",
        "def complex_to_real_tensor(inp_tensor):\n",
        "   real_part , imag_part = tf.math.real(inp_tensor), tf.math.imag(inp_tensor)\n",
        "   real_part = tf.reshape(real_part,[-1,1])\n",
        "   imag_part = tf.reshape(imag_part,[-1,1])\n",
        "   return tf.reshape(tf.concat([real_part,imag_part],1),[-1])\n",
        "\n",
        "# RRC Filter Design\n",
        "class NRRC_filter(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self,beta,span,sps,input):\n",
        "    super(NRRC_filter, self).__init__(**kwargs)\n",
        "    self.beta = beta\n",
        "    self.span = span\n",
        "    self.sps = sps\n",
        "    self.input = input\n",
        "\n",
        "  def build(self,beta, span, sps):\n",
        "        \"\"\"\n",
        "        Create a Root Raised Cosine (RRC) filter (FIR) impulse response.\n",
        "\n",
        "        Parameters:\n",
        "        beta : Roll-off factor (0 <= beta <= 1)\n",
        "        span : Filter span in symbols\n",
        "        sps : Samples per symbol\n",
        "\n",
        "        Returns:\n",
        "        h_rrc : RRC filter coefficients (impulse response)\n",
        "        \"\"\"\n",
        "        t = np.linspace(-span / 2, span / 2, span * sps + 1)\n",
        "        h_rrc = np.zeros_like(t)\n",
        "\n",
        "        for i in range(len(t)):\n",
        "            if t[i] == 0.0:\n",
        "                h_rrc[i] = 1.0 - beta + (4 * beta / np.pi)\n",
        "            elif abs(t[i]) == 1 / (4 * beta):\n",
        "                h_rrc[i] = (beta / np.sqrt(2)) * (((1 + 2 / np.pi) * np.sin(np.pi / (4 * beta))) +\n",
        "                                                  ((1 - 2 / np.pi) * np.cos(np.pi / (4 * beta))))\n",
        "            else:\n",
        "                h_rrc[i] = (np.sin(np.pi * t[i] * (1 - beta)) +\n",
        "                            4 * beta * t[i] * np.cos(np.pi * t[i] * (1 + beta))) / \\\n",
        "                          (np.pi * t[i] * (1 - (4 * beta * t[i]) ** 2))\n",
        "\n",
        "        # Normalize filter energy to 1\n",
        "        h_rrc = h_rrc / np.sqrt(np.sum(h_rrc ** 2))\n",
        "        return h_rrc\n",
        "\n",
        "  def call(self, input):\n",
        "\n",
        "      \"\"\"\n",
        "      Apply pulse shaping to a bitstream using a given filter.\n",
        "\n",
        "      Parameters:\n",
        "      bitstream : Input bitstream (BPSK symbols)\n",
        "      h_rrc : RRC filter coefficients\n",
        "      sps : Samples per symbol\n",
        "\n",
        "      Returns:\n",
        "      shaped_signal : Pulse-shaped signal\n",
        "      \"\"\"\n",
        "      # Upsample the bitstream (insert zeros between symbols)\n",
        "      upsampled = np.zeros(len(input) * sps)\n",
        "      upsampled[::sps] = input\n",
        "\n",
        "      # Convolve with the RRC filter\n",
        "      shaped_signal = lfilter(h_rrc, 1.0, input)\n",
        "      return shaped_signal\n",
        "\n",
        "  def get_config(self):\n",
        "      config = super(NRRC_filter, self).get_config()\n",
        "      config.update({'beta': self.beta, 'span': self.span, 'sps': self.sps})\n",
        "      return config\n",
        "# Pulse Shaping\n",
        "def pulse_shaping(bitstream, h_rrc, sps):\n",
        "    \"\"\"\n",
        "    Apply pulse shaping to a bitstream using a given filter.\n",
        "\n",
        "    Parameters:\n",
        "    bitstream : Input bitstream (BPSK symbols)\n",
        "    h_rrc : RRC filter coefficients\n",
        "    sps : Samples per symbol\n",
        "\n",
        "    Returns:\n",
        "    shaped_signal : Pulse-shaped signal\n",
        "    \"\"\"\n",
        "    # Upsample the bitstream (insert zeros between symbols)\n",
        "    upsampled = np.zeros(len(bitstream) * sps)\n",
        "    upsampled[::sps] = bitstream\n",
        "\n",
        "    # Convolve with the RRC filter\n",
        "    shaped_signal = lfilter(h_rrc, 1.0, bitstream)\n",
        "    return shaped_signal\n",
        "\n",
        "# Parameters\n",
        "beta = 0.35  # Roll-off factor\n",
        "span = 31    # Filter span (in symbols)\n",
        "sps = 4      # Samples per symbol\n",
        "num_bits = 100  # Number of bits\n",
        "\n",
        "# Generate a random bitstream (BPSK symbols: -1, 1)\n",
        "bitstream = 2 * np.random.randint(0, 2, num_bits) - 1\n",
        "\n",
        "# Create the RRC filter\n",
        "h_rrc = rrc_filter(beta, span, sps)\n",
        "\n",
        "# Perform pulse shaping\n",
        "shaped_signal = pulse_shaping(bitstream, h_rrc, sps)\n",
        "\n",
        "# Normalize the shaped signal\n",
        "shaped_signal /= np.max(np.abs(shaped_signal))\n",
        "\n",
        "# Plot the original bitstream and the pulse-shaped signal\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "#plt.stem(np.arange(len(bitstream)), bitstream, 'b', markerfmt='bo', basefmt=\" \", use_line_collection=True) to resolve error\n",
        "plt.stem(np.arange(len(bitstream)), bitstream, 'b', markerfmt='bo', basefmt=\" \")\n",
        "plt.title('Original Bitstream')\n",
        "plt.xlabel('Bit Index')\n",
        "plt.ylabel('Amplitude')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(shaped_signal, 'r')\n",
        "plt.title('Pulse-Shaped Signal (Normalized RRC)')\n",
        "plt.xlabel('Sample Index')\n",
        "plt.ylabel('Amplitude')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVvu_VFTR_J6"
      },
      "source": [
        "# implementation of AE with noise channel working."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "uzN0ljm-PzO_"
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense\n",
        "# import numpy as np\n",
        "# import math\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# Dataset Parameters\n",
        "N = 4  # Number of channel uses\n",
        "M = 16  # Number of total messages that can be transmitted\n",
        "K = int(math.ceil(np.log2(M)))  # Block size\n",
        "l = 6\n",
        "Eb_No = 10\n",
        "batch_size = (2*l+1)*320\n",
        "\n",
        "# Create Dataset in one-hot vector\n",
        "alphabet_size = pow(2, K)\n",
        "alphabet = np.eye(alphabet_size, dtype='float32')\n",
        "\n",
        "train_dataset = np.tile(alphabet, (batch_size, 1))\n",
        "test_dataset = np.tile(alphabet, (batch_size * 10, 1))\n",
        "\n",
        "# Custom Callback for Real-time Plotting\n",
        "class PlottingCallback(Callback):\n",
        "    def __init__(self):\n",
        "        super(PlottingCallback, self).__init__()\n",
        "        self.history = {'accuracy': [], 'val_accuracy': [], 'loss': [], 'val_loss': []}\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Update history\n",
        "        self.history['accuracy'].append(logs.get('accuracy'))\n",
        "        self.history['val_accuracy'].append(logs.get('val_accuracy'))\n",
        "        self.history['loss'].append(logs.get('loss'))\n",
        "        self.history['val_loss'].append(logs.get('val_loss'))\n",
        "\n",
        "        # Clear previous output\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        # Plot training and validation accuracy\n",
        "        plt.figure(figsize=(12, 5))\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(self.history['accuracy'], label='Training Accuracy')\n",
        "        plt.plot(self.history['val_accuracy'], label='Validation Accuracy')\n",
        "        plt.title('Accuracy over Epochs')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "\n",
        "        # Plot training and validation loss\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(self.history['loss'], label='Training Loss')\n",
        "        plt.plot(self.history['val_loss'], label='Validation Loss')\n",
        "        plt.title('Loss over Epochs')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "# Normalization Layer\n",
        "class Normalization(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(Normalization, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, input):\n",
        "        shape = tf.shape(input)\n",
        "        out = tf.nn.l2_normalize(tf.reshape(input, (-1, 2)), axis=-1, epsilon=1e-5)\n",
        "        # out = tf.nn.l2_normalize(tf.reshape(input, (-1, 2*N)), axis=-1, epsilon=1e-5)                                # to normalize the power of symbol\n",
        "        # out = tf.nn.l2_normalize(tf.reshape(input, (-1, shape[-1])), axis=-1, epsilon=1e-5)  # to normalize the power of all the signal\n",
        "        out = tf.reshape(out, (-1,2*N))\n",
        "        print(\" Normalize each input power to 1,shape \",out.shape)\n",
        "        return out\n",
        "\n",
        "    def get_config(self):\n",
        "        return super(Normalization, self).get_config()\n",
        "\n",
        "# Custom Noise Layer\n",
        "class CustomNoise(tf.keras.layers.Layer):\n",
        "    def __init__(self, mean=0.0, stddev=10**(-1.0*Eb_No), **kwargs):\n",
        "        super(CustomNoise, self).__init__(**kwargs)\n",
        "        self.mean = mean\n",
        "        self.stddev = stddev\n",
        "\n",
        "    def call(self, inputs):\n",
        "        noise = tf.random.normal(shape=tf.shape(inputs), mean=self.mean, stddev=self.stddev)\n",
        "        return inputs + noise\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "# class RealToComplexPair(tf.keras.layers.Layer):\n",
        "#     def __init__(self, **kwargs):\n",
        "#         super(RealToComplexPair, self).__init__(**kwargs)\n",
        "\n",
        "#     def call(self, inputs):\n",
        "#         # Get the inner dimension size\n",
        "#         inner_dimension = inputs.shape[-1] // 2  # Assuming the last dimension is even\n",
        "\n",
        "#         # Create indices for real and imaginary parts\n",
        "#         real_indices = tf.range(0, 2 * inner_dimension, 2)\n",
        "#         imag_indices = tf.range(1, 2 * inner_dimension, 2)\n",
        "\n",
        "#         # Extract real and imaginary parts using the indices\n",
        "#         real_part = tf.gather(inputs, real_indices, axis=-1)\n",
        "#         imag_part = tf.gather(inputs, imag_indices, axis=-1)\n",
        "\n",
        "#         # Combine the real and imaginary parts into a complex tensor\n",
        "#         complex_tensor = tf.complex(real_part, imag_part)\n",
        "#         return complex_tensor\n",
        "\n",
        "#     def compute_output_shape(self, input_shape):\n",
        "#         # Output shape will have half the last dimension (as complex numbers)\n",
        "#         return input_shape[:-1] + (input_shape[-1] // 2,)\n",
        "\n",
        "#     def get_config(self):\n",
        "#         config = super(RealToComplexPair, self).get_config()\n",
        "#         return config\n",
        "\n",
        "\n",
        "\n",
        "class AE:\n",
        "    def __init__(self, train_data=train_dataset, test_data=test_dataset, input_dim=K, enc_dim=N, act_fun='tanh'):\n",
        "        self.train_data = train_data\n",
        "        self.test_data = test_data\n",
        "        self.input_dim = input_dim\n",
        "        self.enc_dim = enc_dim\n",
        "        self.act_fun = act_fun\n",
        "\n",
        "    def AE_implement(self):\n",
        "        autoencoder = Sequential([\n",
        "            Dense(2**(self.input_dim), activation=self.act_fun, name=\"Input\"),\n",
        "            Dense(2**(self.input_dim), activation=self.act_fun, name=\"encoder\"),\n",
        "            Dense(2**(self.input_dim), activation=self.act_fun, name=\"middle1\"),\n",
        "            Dense(self.enc_dim * 2, activation=self.act_fun, name='middle2'),\n",
        "\n",
        "            # Convert to complex tensor\n",
        "            # RealToComplexPair(name = 'real2complex'),\n",
        "\n",
        "            # Normalization Layer\n",
        "            Normalization(name = 'normalization'),\n",
        "\n",
        "            # Channel Layer\n",
        "            StochasticChannelv3_cts_tr(name = 'stc'),\n",
        "            # NormalizedRRCFilterLayer( ),\n",
        "            CustomNoise(name = 'noise'),\n",
        "            SD(name = 'sd'),\n",
        "            # CustomNoise(\n",
        "\n",
        "            # Decoder layers\n",
        "            Dense(self.enc_dim * 4, activation=self.act_fun, name=\"decoder1\"),\n",
        "            Dense(2**(self.input_dim), activation=self.act_fun, name='decoder2'),\n",
        "            Dense(2**(self.input_dim), activation='softmax', name='Output')\n",
        "        ])\n",
        "\n",
        "        autoencoder.compile(optimizer=Adam(learning_rate=1e-2), loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "        return autoencoder\n",
        "\n",
        "    def train(self, epochs=20, batch_size=64):\n",
        "        autoencoder = self.AE_implement()\n",
        "        # autoencoder.fit(self.train_data, self.train_data,\n",
        "        #                 epochs=epochs, batch_size=batch_size,\n",
        "        #                 validation_data=(self.test_data, self.test_data))\n",
        "        # # return autoencoder\n",
        "\n",
        "        # TensorBoard setup\n",
        "        log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "        tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "        print(self.test_data.shape)\n",
        "\n",
        "        history = autoencoder.fit(self.train_data, self.train_data,\n",
        "                                  epochs=epochs, batch_size=(2*l+1)*16,\n",
        "                                  validation_data=(self.test_data, self.test_data),\n",
        "                                  callbacks=[PlottingCallback(), tensorboard_callback])\n",
        "        return autoencoder, history\n",
        "\n",
        "# Instantiate the AE class and train the model\n",
        "ae = AE(train_data=train_dataset[:], test_data=test_dataset[:16*13], input_dim=K, enc_dim=N, act_fun='relu')\n",
        "autoencoder_model = ae.train(epochs=10, batch_size=(2*l+1))\n",
        "# print(\"This is the sample input dimension \",len(train_dataset[0]))\n",
        "# Evaluate the model on the test data\n",
        "# print(train_dataset.shape)\n",
        "# print(test_dataset)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "C58NhxRBM7fj"
      },
      "outputs": [],
      "source": [
        "%reload_ext tensorboard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs/fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3OZYo4gKKwe"
      },
      "outputs": [],
      "source": [
        "enc = tf.constant([[1,1,1,1,0,0,1,0,1,0,1,1,0,1,0,1],\n",
        "                    [0,1,0,1,0,0,0,1,0,1,1,1,0,1,1,0]],\n",
        "                   dtype=tf.float32) # enc has been redefined with the correct shape\n",
        "print(enc.shape)\n",
        "# Instantiate the layer\n",
        "output = autoencoder_model[0](test_dataset[:12*13])\n",
        "\n",
        "# Apply the layer to the input\n",
        "# output = channel_layer(enc)\n",
        "\n",
        "# Print the shapes and output\n",
        "print(output.shape)\n",
        "\n",
        "print(output)\n",
        "# accuracy = autoencoder_model[0].evaluate(enc,enc, batch_size = 2)\n",
        "# print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRsgdzptvm4o"
      },
      "source": [
        "## plot the outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGpZ0TnUsPa2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have your input and output from the autoencoder\n",
        "# Example:\n",
        "# input_data = your_input_data   # Shape (156, 16)\n",
        "# output_data = autoencoder.predict(your_input_data)  # Shape (156, 16)\n",
        "\n",
        "def plot_autoencoder_performance(input_data, output_data, num_samples=5):\n",
        "    # Ensure the number of samples to plot does not exceed the number of available samples\n",
        "    num_samples = min(num_samples, input_data.shape[0])\n",
        "\n",
        "    # Create subplots\n",
        "    fig, axs = plt.subplots(num_samples, 2, figsize=(10, num_samples * 3))\n",
        "    fig.suptitle('Autoencoder Input vs Output', fontsize=16)\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        # Plot input data (original data)\n",
        "        axs[i, 0].plot(input_data[i], color='blue')\n",
        "        axs[i, 0].set_title(f\"Input {i+1}\")\n",
        "\n",
        "        # Plot output data (reconstructed data)\n",
        "        axs[i, 1].plot(output_data[i], color='red')\n",
        "        axs[i, 1].set_title(f\"Output {i+1}\")\n",
        "\n",
        "        # Adding labels\n",
        "        axs[i, 0].set_ylabel('Amplitude')\n",
        "        axs[i, 1].set_ylabel('Amplitude')\n",
        "\n",
        "    # Adding x-axis labels\n",
        "    axs[-1, 0].set_xlabel('Feature Index')\n",
        "    axs[-1, 1].set_xlabel('Feature Index')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.93)  # Adjust for title\n",
        "    plt.show()\n",
        "\n",
        "# Call the plotting function with input and output data\n",
        "plot_autoencoder_performance(test_dataset[:12*13], output, num_samples=5)  # Adjust num_samples as needed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrS89pPetyio"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have your input and output from the autoencoder\n",
        "# Example:\n",
        "# input_data = your_input_data   # Shape (156, 16)\n",
        "# output_data = autoencoder.predict(your_input_data)  # Shape (156, 16)\n",
        "\n",
        "def plot_constellation(input_data, output_data, num_samples=5):\n",
        "    # Ensure the number of samples to plot does not exceed the number of available samples\n",
        "    num_samples = min(num_samples, input_data.shape[0])\n",
        "\n",
        "    # Create subplots for constellation\n",
        "    fig, axs = plt.subplots(num_samples, 2, figsize=(10, num_samples * 5))\n",
        "    fig.suptitle('Autoencoder Input vs Output Constellation', fontsize=16)\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        # Extract real and imaginary parts for input and output\n",
        "        input_real = input_data[i, ::2]   # Real parts from even indices\n",
        "        input_imag = input_data[i, 1::2]  # Imaginary parts from odd indices\n",
        "        output_real = output_data[i, ::2]  # Real parts from even indices\n",
        "        output_imag = output_data[i, 1::2]  # Imaginary parts from odd indices\n",
        "\n",
        "        # Plot input constellation\n",
        "        axs[i, 0].scatter(input_real, input_imag, color='blue', s=50, label='Input')\n",
        "        axs[i, 0].set_title(f\"Input Constellation {i+1}\")\n",
        "        axs[i, 0].set_xlabel('Real')\n",
        "        axs[i, 0].set_ylabel('Imaginary')\n",
        "        axs[i, 0].grid(True)\n",
        "\n",
        "        # Plot output constellation\n",
        "        axs[i, 1].scatter(output_real, output_imag, color='red', s=50, label='Output')\n",
        "        axs[i, 1].set_title(f\"Output Constellation {i+1}\")\n",
        "        axs[i, 1].set_xlabel('Real')\n",
        "        axs[i, 1].set_ylabel('Imaginary')\n",
        "        axs[i, 1].grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.93)  # Adjust for title\n",
        "    plt.show()\n",
        "\n",
        "# Call the plotting function with input and output data\n",
        "plot_constellation(test_dataset[:12*13], output, num_samples=5)  # Adjust num_samples as needed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Bi-wtO_zO7bW"
      },
      "outputs": [],
      "source": [
        "autoencoder_model[0].summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iX7xG947h8xQ"
      },
      "source": [
        "# Stochastic Channel layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmI_Dqtzh8xR"
      },
      "outputs": [],
      "source": [
        "# Custom Noise Layer\n",
        "class CustomNoise(tf.keras.layers.Layer):\n",
        "    def __init__(self, mean=0.0, stddev=10**(-1.0*Eb_No), **kwargs):\n",
        "        super(CustomNoise, self).__init__(**kwargs)\n",
        "        self.mean = mean\n",
        "        self.stddev = stddev\n",
        "\n",
        "    def call(self, inputs):\n",
        "        noise = tf.random.normal(shape=tf.shape(inputs), mean=self.mean, stddev=self.stddev)\n",
        "        return inputs + noise\n",
        "\n",
        "class StochasticChannel(tf.keras.layers.Layer):\n",
        "    def __init__(self, roll_off=0.35, num_taps=101, time_delay=0, rate=1, **kwargs):\n",
        "        super(StochasticChannel, self).__init__(**kwargs)\n",
        "        self.num_taps = num_taps\n",
        "        self.time_delay = time_delay\n",
        "        self.rate = rate\n",
        "        self.roll_off = roll_off\n",
        "        # self.Noise_layer  = CustomNoise(mean=0.0,stddev=channel_parameters['noise_std'])\n",
        "\n",
        "    def upsampling(self, input):\n",
        "        input = tf.reshape(input, [-1, 1])\n",
        "        padding = tf.constant([[0, 0], [0, self.rate - 1]])\n",
        "        upsampled = tf.pad(input, padding, \"CONSTANT\")\n",
        "        print(\"shape after upsamping:\", input.shape)\n",
        "        return tf.reshape(upsampled, [-1])\n",
        "\n",
        "    def upsample_iq(self, input):\n",
        "        inner_dimension = ( input.shape[1])\n",
        "        N = inner_dimension//2\n",
        "        Real, Imag = [],[]\n",
        "        for i in range(N):\n",
        "          real_t,imag_t = input[:,2*i],input[:,2*i+1]\n",
        "          Real.extend(real_t)\n",
        "          Imag.extend(imag_t)\n",
        "        input = tf.stack([Real, Imag], axis=1)\n",
        "\n",
        "\n",
        "        # Create indices for real and imaginary parts\n",
        "        real_indices = tf.range(0, inner_dimension-1, 2)\n",
        "        imag_indices = tf.range(1, inner_dimension, 2)\n",
        "\n",
        "        # # Extract real and imaginary parts using the indices\n",
        "        # real_part = tf.gather(input[:], real_indices, axis=-1)\n",
        "        # imag_part = tf.gather(input[:], imag_indices, axis=-1)\n",
        "\n",
        "        # Convert indices to numpy for slicing\n",
        "        real_indices = real_indices.numpy()\n",
        "        imag_indices = imag_indices.numpy()\n",
        "\n",
        "        real = input[:, real_indices]\n",
        "        imag = input[:, imag_indices]\n",
        "        print(\"input dimension:\", input.shape)\n",
        "        real_up = self.upsampling(real)\n",
        "        imag_up = self.upsampling(imag)\n",
        "        return tf.stack([real_up, imag_up], axis=1)\n",
        "\n",
        "    def rrc_filter(self):\n",
        "        \"\"\"\n",
        "        Create a root-raised cosine (RRC) filter.\n",
        "\n",
        "        Returns:\n",
        "            RRC filter coefficients.\n",
        "        \"\"\"\n",
        "        t = np.linspace(-self.num_taps // 2, self.num_taps // 2, self.num_taps)\n",
        "        rrc = np.zeros_like(t)\n",
        "\n",
        "        for i in range(len(t)):\n",
        "            if t[i] == 0.0:\n",
        "                rrc[i] = (1.0 - self.roll_off + 4 * self.roll_off / np.pi)\n",
        "            elif np.abs(t[i]) == 1 / (4 * self.roll_off):\n",
        "                rrc[i] = (self.roll_off / (np.sqrt(2))) * \\\n",
        "                         ((1 + 2 / np.pi) * np.sin(np.pi / (4 * self.roll_off)) +\n",
        "                          (1 - 2 / np.pi) * np.cos(np.pi / (4 * self.roll_off)))\n",
        "            else:\n",
        "                rrc[i] = (np.sin(np.pi * (t[i]) * (1 - self.roll_off)) +\n",
        "                          4 * self.roll_off * (t[i]) * np.cos(np.pi * (t[i]) * (1 + self.roll_off))) / \\\n",
        "                         (np.pi * t[i] * (1 - (4 * self.roll_off * (t[i])) ** 2))\n",
        "\n",
        "        # Normalize filter coefficients to ensure unit energy\n",
        "        rrc = rrc / np.sqrt(np.sum(rrc ** 2))\n",
        "        rrc = tf.constant(rrc, dtype=tf.float32)\n",
        "        return rrc\n",
        "\n",
        "    def upsample_and_filter(self, input):\n",
        "        # Reshape the input dimension\n",
        "        # input = tf.reshape(input, [-1, 2])\n",
        "\n",
        "        # Upsample the signal\n",
        "        upsampled_signal = self.upsample_iq(input)\n",
        "\n",
        "        # Create the RRC filter\n",
        "        rrc = self.rrc_filter()\n",
        "\n",
        "        # Add a batch and channel dimension for conv1d\n",
        "        upsampled_signal = tf.expand_dims(upsampled_signal, axis=0)  # Shape: (1, length, 2)\n",
        "        rrc = tf.reshape(rrc, [-1, 1, 1])  # Shape: (filter_length, 1, 1)\n",
        "\n",
        "        padding_size = self.num_taps // 2\n",
        "        paddings = tf.constant([[0, 0], [padding_size, padding_size], [0, 0]])\n",
        "        padded_real = tf.pad(upsampled_signal[:, :, 0:1], paddings, \"CONSTANT\")\n",
        "        padded_imag = tf.pad(upsampled_signal[:, :, 1:2], paddings, \"CONSTANT\")\n",
        "        padded_signal = tf.concat([padded_real, padded_imag], axis=2)\n",
        "\n",
        "        # Apply the RRC filter using conv1d\n",
        "        real_filtered = tf.nn.conv1d(padded_signal[:, :, 0:1], rrc, stride=1, padding='VALID')\n",
        "        imag_filtered = tf.nn.conv1d(padded_signal[:, :, 1:2], rrc, stride=1, padding='VALID')\n",
        "\n",
        "        # Combine filtered real and imaginary parts\n",
        "        filtered_signal = tf.concat([real_filtered, imag_filtered], axis=2)\n",
        "        print(\"input shape; \",input.shape)\n",
        "        print(\"shape after filtering:\", filtered_signal.shape)\n",
        "        filtered_signal = tf.squeeze(filtered_signal, axis=0)  # Remove the batch dimension\n",
        "        print(\"shape after squeeze:\", filtered_signal[0])\n",
        "\n",
        "        return filtered_signal\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Apply upsampling and RRC filtering\n",
        "        filtered_signal = self.upsample_and_filter(inputs)\n",
        "\n",
        "        # Log the filtered signal for TensorBoard visualization\n",
        "        with tf.summary.create_file_writer('logs/stochastic_channel').as_default():\n",
        "            tf.summary.histogram(\"Filtered Signal\", filtered_signal, step=0)\n",
        "\n",
        "        return filtered_signal\n",
        "\n",
        "y = StochasticChannel()(train_dataset)\n",
        "print(train_dataset.shape)\n",
        "print(\"-------------------------------------------------------------\")\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zvfb4uPEVLA"
      },
      "source": [
        "# partially working stochastic channel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Egt3C_dlklw-"
      },
      "outputs": [],
      "source": [
        "# input_layer = autoencoder_model[0].get_layer('Input')\n",
        "# before_channel = Model(inputs=input_layer.input,  # Use KerasTensor as input\n",
        "#                        outputs=autoencoder_model[0].get_layer('normalization').output)\n",
        "# enc = before_channel(train_dataset)\n",
        "# tf.Tensor(\n",
        "# [1.        0.        0.        1.        0.7818562 0.6234588 0.\n",
        "# 0.       ], shape=(8,), dtype=float32)\n",
        "\n",
        "\n",
        "# Function to create a normalized RRC filter\n",
        "# def rrc_filter(alpha=.35, sps=1, num_taps=15, ts = 1):\n",
        "#     \"\"\"\n",
        "#     Create a root-raised cosine (RRC) filter.\n",
        "\n",
        "#     Args:\n",
        "#         ts: Sampling period (default is 1).\n",
        "#         alpha: Roll-off factor (0 <= alpha <= 1).\n",
        "#         sps: Samples per symbol (upsampling factor).\n",
        "#         num_taps: Number of filter taps (should be odd).\n",
        "\n",
        "#     Returns:\n",
        "#         RRC filter coefficients.\n",
        "#     \"\"\"\n",
        "#     t = np.linspace(-num_taps//2, num_taps//2 + 1,num_taps)\n",
        "#     rrc = np.zeros_like(t)\n",
        "\n",
        "#     for i in range(len(t)):\n",
        "#         if t[i] == 0.0:\n",
        "#             rrc[i] = (1.0 - alpha + 4 * alpha / np.pi)/ts\n",
        "#         elif np.abs(t[i]) == ts / (4 * alpha):\n",
        "#             rrc[i] = (alpha /( np.sqrt(2)*ts)) * \\\n",
        "#                      ((1 + 2/np.pi) * np.sin(np.pi / (4 * alpha)) +\n",
        "#                       (1 - 2/np.pi) * np.cos(np.pi / (4 * alpha)))\n",
        "#         else:\n",
        "#             rrc[i] = (np.sin(np.pi * (t[i]/ts) * (1 - alpha)) +\n",
        "#                       4 * alpha * (t[i]/ts) * np.cos(np.pi * (t[i]/ts) * (1 + alpha))) / \\\n",
        "#                      (np.pi * t[i] * (1 - (4 * alpha * (t[i]/ts))**2))\n",
        "\n",
        "#     # Normalize filter coefficients to ensure unit energy\n",
        "#     rrc = rrc / np.sqrt(np.sum(rrc**2))\n",
        "#     rrc = tf.constant(rrc, dtype=tf.float32)\n",
        "#     # plt.stem(t,rrc)  # Plot for visualization\n",
        "#     # plt.title(f\"Time_delay = {10}\")\n",
        "#     return rrc\n",
        "\n",
        "# # print(enc[0])\n",
        "\n",
        "# def real_to_complex_tensor(inp_tensor):\n",
        "#     # Reshape the tensor to group adjacent real and imaginary parts\n",
        "#     batch_size = inp_tensor.shape[0]   # Number of batches\n",
        "#     inner_dim = inp_tensor.shape[1]    # Inner dimension size\n",
        "\n",
        "#     # Debugging: Print the input shape\n",
        "#     print(f\"Input tensor shape: {inp_tensor.shape}\")\n",
        "#     print(f\"Batch size: {batch_size}, Inner dimension: {inner_dim}\")\n",
        "#     print(\"-------------------------------------------------------------\")\n",
        "\n",
        "#     # If inner_dim is odd, pad the input\n",
        "#     if inner_dim % 2 != 0:\n",
        "#         inp_tensor = tf.pad(inp_tensor, [[0, 0], [0, 1]])\n",
        "#         inner_dim += 1  # Adjust the inner_dim to account for padding\n",
        "#     # Ensure that the inner dimension is even (for real and imaginary pairs)\n",
        "#     assert inner_dim % 2 == 0, \"Inner dimension must be even for real and imaginary pairs.\"\n",
        "\n",
        "#     # Reshape the tensor to separate real and imaginary parts\n",
        "#     reshaped_tensor = tf.reshape(inp_tensor, [batch_size, inner_dim // 2, 2])\n",
        "\n",
        "#     rrc = rrc_filter()\n",
        "#     rrc = tf.reshape(rrc, [-1, 1, 1])  # Shape: (filter_length, 1, 1) for conv1d\n",
        "\n",
        "#     # Extract real and imaginary parts\n",
        "#     real_part = reshaped_tensor[:, :, 0]\n",
        "#     real_part = upsample(real_part, 4)\n",
        "\n",
        "#     imag_part = reshaped_tensor[:, :, 1]\n",
        "#     imag_part = upsample(imag_part, 4)\n",
        "\n",
        "#     # Add a channel dimension to match conv1d's 3D input requirement\n",
        "#     real_part = tf.expand_dims(real_part, axis=-1)  # Shape: (batch_size, time_length, 1)\n",
        "#     imag_part = tf.expand_dims(imag_part, axis=-1)  # Shape: (batch_size, time_length, 1)\n",
        "\n",
        "#     # Apply the RRC filter using conv1d (expects [batch_size, width, channels])\n",
        "#     real_filtered = tf.nn.conv1d(real_part, rrc, stride=1, padding='VALID')\n",
        "#     imag_filtered = tf.nn.conv1d(imag_part, rrc, stride=1, padding='VALID')\n",
        "\n",
        "#     real_filtered = tf.squeeze(real_filtered, axis=-1)  # Shape: (batch_size, time_length)\n",
        "#     imag_filtered = tf.squeeze(imag_filtered, axis=-1)  # Shape: (batch_size, time_length)\n",
        "\n",
        "#     # Interleave real and imaginary parts\n",
        "#     interleaved = tf.stack([real_filtered, imag_filtered], axis=-1)  # Shape: (batch_size, time_length, 2)\n",
        "#     print(f\"Interleaved shape: {interleaved.shape}\")\n",
        "#     interleaved = tf.reshape(interleaved, [batch_size, -1])  # Flatten to (batch_size, time_length*2)\n",
        "#     print(f\"Flattened shape: {interleaved.shape}\")\n",
        "#     return interleaved\n",
        "# def complex_to_real_tensor(inp_tensor):\n",
        "#     # Debugging: Print the input shape\n",
        "#     print(f\"Input tensor shape: {inp_tensor.shape}\")\n",
        "#     # Ensure that the input tensor is of shape [2, n]\n",
        "#     assert inp_tensor.shape[0] == 2, \"The first dimension must be 2 (real and imaginary parts).\"\n",
        "\n",
        "#     # Get real part (first row) and imaginary part (second row)\n",
        "#     real_part = inp_tensor[0, :]  # Shape: [n]\n",
        "#     imag_part = inp_tensor[1, :]  # Shape: [n]\n",
        "\n",
        "#     # Stack real and imaginary parts together and interleave them\n",
        "#     combined = tf.stack([real_part, imag_part], axis=-1)  # Shape: [n, 2]\n",
        "\n",
        "#     # Reshape to interleave the real and imaginary parts into one dimension\n",
        "#     interleaved = tf.reshape(combined, [-1])  # Shape: [2*n], interleaving real and imaginary\n",
        "\n",
        "#     return interleaved\n",
        "\n",
        "# # Test input tensor (e.g., batch of 2 samples with 4 real values each)\n",
        "# # For example, real values are [1, 2, 3, 4], to be grouped as (1+2j, 3+4j)\n",
        "# # enc = tf.constant([[1, 2, 3, 4], [5, 6, 7, 8]], dtype=tf.float32)\n",
        "# def upsample(input_tensor, r=4):\n",
        "#     \"\"\"\n",
        "#     Function to upsample a tensor by adding r-1 zeros between each element along the last axis.\n",
        "#     \"\"\"\n",
        "#     # Expand dimensions of the input to insert the zeros\n",
        "#     input_shape = tf.shape(input_tensor)\n",
        "#     expanded_input = tf.expand_dims(input_tensor, axis=-1)  # Add an extra dimension\n",
        "\n",
        "#     # Create a tensor of zeros with the same shape as input, but r times the last dimension\n",
        "#     zero_padding = tf.zeros_like(expanded_input)  # Tensor of zeros\n",
        "#     zero_padding = tf.tile(zero_padding, [1, 1, r-1])  # Repeat the zeros r-1 times\n",
        "\n",
        "#     # Concatenate input and zero_padding along the last dimension\n",
        "#     upsampled = tf.concat([expanded_input, zero_padding], axis=-1)\n",
        "\n",
        "#     # Reshape to flatten the added dimension\n",
        "#     new_shape = [input_shape[0], input_shape[1] * r]\n",
        "#     upsampled_flat = tf.reshape(upsampled, new_shape)\n",
        "#     return upsampled_flat\n",
        "\"\"\"-------------------------------------------------------------------------------------------------------------------------------Creating Layer -----------------------\"\"\"\n",
        "class StochasticChannelv2(tf.keras.layers.Layer):\n",
        "    def __init__(self, roll_off=0.35, num_taps=3, time_delay=0, rate=1, ts=1, **kwargs):\n",
        "        super(StochasticChannelv2, self).__init__(**kwargs)\n",
        "        self.num_taps = num_taps\n",
        "        self.time_delay = time_delay\n",
        "        self.rate = rate\n",
        "        self.roll_off = roll_off\n",
        "        self.ts = ts  # Define ts (sampling period) as an instance attribute\n",
        "\n",
        "    def upsample(self, input_tensor):\n",
        "        \"\"\"\n",
        "        Function to upsample a tensor by adding (rate - 1) zeros between each element along the last axis.\n",
        "        \"\"\"\n",
        "        # Expand dimensions of the input to insert the zeros\n",
        "        input_shape = tf.shape(input_tensor)\n",
        "        expanded_input = tf.expand_dims(input_tensor, axis=-1)  # Add an extra dimension\n",
        "\n",
        "        # Create a tensor of zeros with the same shape as input, but rate times the last dimension\n",
        "        zero_padding = tf.zeros_like(expanded_input)  # Tensor of zeros\n",
        "        zero_padding = tf.tile(zero_padding, [1, 1, self.rate - 1])  # Repeat the zeros rate-1 times\n",
        "\n",
        "        # Concatenate input and zero_padding along the last dimension\n",
        "        upsampled = tf.concat([expanded_input, zero_padding], axis=-1)\n",
        "\n",
        "        # Reshape to flatten the added dimension\n",
        "        new_shape = [input_shape[0], input_shape[1] * self.rate]\n",
        "        upsampled_flat = tf.reshape(upsampled, new_shape)\n",
        "        return upsampled_flat\n",
        "\n",
        "    def real_to_complex_tensor(self, inp_tensor):\n",
        "        # Reshape the tensor to group adjacent real and imaginary parts\n",
        "        batch_size = inp_tensor.shape[0]   # Number of batches\n",
        "        inner_dim = inp_tensor.shape[1]    # Inner dimension size\n",
        "\n",
        "        # Ensure that the inner dimension is even (for real and imaginary pairs)\n",
        "        assert inner_dim % 2 == 0, \"Inner dimension must be even for real and imaginary pairs.\"\n",
        "\n",
        "        # Reshape the tensor to separate real and imaginary parts\n",
        "        reshaped_tensor = tf.reshape(inp_tensor, [batch_size, inner_dim // 2, 2])\n",
        "\n",
        "        rrc = self.rrc_filter()\n",
        "        rrc = tf.reshape(rrc, [-1, 1, 1])  # Shape: (filter_length, 1, 1) for conv1d\n",
        "\n",
        "        # Extract real and imaginary parts\n",
        "        real_part = reshaped_tensor[:, :, 0]\n",
        "        real_part = self.upsample(real_part)  # Use self.upsample\n",
        "\n",
        "        imag_part = reshaped_tensor[:, :, 1]\n",
        "        imag_part = self.upsample(imag_part)  # Use self.upsample\n",
        "\n",
        "        # Add a channel dimension to match conv1d's 3D input requirement\n",
        "        real_part = tf.expand_dims(real_part, axis=-1)  # Shape: (batch_size, time_length, 1)\n",
        "        imag_part = tf.expand_dims(imag_part, axis=-1)  # Shape: (batch_size, time_length, 1)\n",
        "\n",
        "        # Apply the RRC filter using conv1d (expects [batch_size, width, channels])\n",
        "        real_filtered = tf.nn.conv1d(real_part, rrc, stride=1, padding='VALID')\n",
        "        imag_filtered = tf.nn.conv1d(imag_part, rrc, stride=1, padding='VALID')\n",
        "\n",
        "        real_filtered = tf.squeeze(real_filtered, axis=-1)  # Shape: (batch_size, time_length)\n",
        "        imag_filtered = tf.squeeze(imag_filtered, axis=-1)  # Shape: (batch_size, time_length)\n",
        "\n",
        "        # Interleave real and imaginary parts\n",
        "        interleaved = tf.stack([real_filtered, imag_filtered], axis=-1)  # Shape: (batch_size, time_length, 2)\n",
        "        interleaved = tf.reshape(interleaved, [batch_size, -1])  # Flatten to (batch_size, time_length*2)\n",
        "\n",
        "        return interleaved\n",
        "\n",
        "    # Function to create a normalized RRC filter\n",
        "    def rrc_filter(self):\n",
        "        \"\"\"\n",
        "        Create a root-raised cosine (RRC) filter.\n",
        "        \"\"\"\n",
        "        t = np.linspace(-self.num_taps // 2, self.num_taps // 2 + 1, self.num_taps)\n",
        "        rrc = np.zeros_like(t)\n",
        "\n",
        "        for i in range(len(t)):\n",
        "            if t[i] == 0.0:\n",
        "                rrc[i] = (1.0 - self.roll_off + 4 * self.roll_off / np.pi) / self.ts\n",
        "            elif np.abs(t[i]) == self.ts / (4 * self.roll_off):\n",
        "                rrc[i] = (self.roll_off / (np.sqrt(2) * self.ts)) * \\\n",
        "                         ((1 + 2 / np.pi) * np.sin(np.pi / (4 * self.roll_off)) +\n",
        "                          (1 - 2 / np.pi) * np.cos(np.pi / (4 * self.roll_off)))\n",
        "            else:\n",
        "                rrc[i] = (np.sin(np.pi * (t[i] / self.ts) * (1 - self.roll_off)) +\n",
        "                          4 * self.roll_off * (t[i] / self.ts) * np.cos(np.pi * (t[i] / self.ts) * (1 + self.roll_off))) / \\\n",
        "                         (np.pi * t[i] * (1 - (4 * self.roll_off * (t[i] / self.ts)) ** 2))\n",
        "\n",
        "        # Normalize filter coefficients to ensure unit energy\n",
        "        rrc = rrc / np.sqrt(np.sum(rrc ** 2))\n",
        "        rrc = tf.constant(rrc, dtype=tf.float32)\n",
        "        return rrc\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Apply upsampling and RRC filtering\n",
        "        batch_size = tf.shape(inputs)[0]  # Batch size\n",
        "        inner_dim = tf.shape(inputs)[1]   # Inner dimension size\n",
        "\n",
        "        reshaped_tensor = tf.reshape(inputs, [batch_size, inner_dim // 2, 2])\n",
        "        upsampled_signal = self.upsample(inputs)\n",
        "        output = self.real_to_complex_tensor(upsampled_signal)  # Use self.real_to_complex_tensor here\n",
        "        return output\n",
        "\n",
        "\n",
        "\n",
        "# Convert real to complex tensor\n",
        "\n",
        "y = StochasticChannelv2()(train_dataset)\n",
        "print(train_dataset.shape)\n",
        "print(\"-------------------------------------------------------------\")\n",
        "print(y.shape)   # this will print the output of single data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SvJzvReoBKI"
      },
      "source": [
        "# Stochastic Channel version 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwhwvvTxmR5W"
      },
      "outputs": [],
      "source": [
        "class StochasticChannelv3(tf.keras.layers.Layer):\n",
        "    def __init__(self, roll_off=0.35, num_taps=31, time_delay=2, r=4, ts=1, **kwargs):\n",
        "        super(StochasticChannelv3, self).__init__(**kwargs)\n",
        "        self.num_taps = num_taps\n",
        "        self.time_delay = time_delay\n",
        "        self.r = r  # Upsampling factor\n",
        "        self.roll_off = roll_off  # Roll-off factor\n",
        "        self.ts = ts  # Sampling period (default is 1)\n",
        "\n",
        "    def upsampling(self, inp):\n",
        "        com_reshape = tf.reshape(inp, [-1, 1])\n",
        "        padding = tf.constant([[0, 0], [0, self.r - 1]])  # Access self.r\n",
        "        upsampled = tf.pad(com_reshape, padding, mode=\"CONSTANT\")\n",
        "        upsampled = tf.reshape(upsampled, [-1])  # Flatten back to 1D\n",
        "        return upsampled\n",
        "\n",
        "    def upsample_iq(self, inp):\n",
        "        real = inp[:, 0]  # Real part\n",
        "        imag = inp[:, 1]  # Imaginary part\n",
        "\n",
        "        real_up = self.upsampling(real)\n",
        "        imag_up = self.upsampling(imag)\n",
        "\n",
        "        upsampled = tf.stack([real_up, imag_up], axis=1)\n",
        "        return upsampled\n",
        "\n",
        "    def rrc_filter(self):\n",
        "        t = np.linspace(-self.num_taps // 2, self.num_taps // 2 + 1, self.num_taps) - self.time_offset()\n",
        "        rrc = np.zeros_like(t)\n",
        "\n",
        "        for i in range(len(t)):\n",
        "            if t[i] == 0.0:\n",
        "                rrc[i] = (1.0 - self.roll_off + 4 * self.roll_off / np.pi) / self.ts\n",
        "            elif np.abs(t[i]) == self.ts / (4 * self.roll_off):\n",
        "                rrc[i] = (self.roll_off / (np.sqrt(2) * self.ts)) * \\\n",
        "                         ((1 + 2 / np.pi) * np.sin(np.pi / (4 * self.roll_off)) +\n",
        "                          (1 - 2 / np.pi) * np.cos(np.pi / (4 * self.roll_off)))\n",
        "            else:\n",
        "                rrc[i] = (np.sin(np.pi * (t[i] / self.ts) * (1 - self.roll_off)) +\n",
        "                          4 * self.roll_off * (t[i] / self.ts) * np.cos(np.pi * (t[i] / self.ts) * (1 + self.roll_off))) / \\\n",
        "                         (np.pi * t[i] * (1 - (4 * self.roll_off * (t[i] / self.ts)) ** 2))\n",
        "\n",
        "        rrc = rrc / np.sqrt(np.sum(rrc ** 2))\n",
        "        rrc = tf.constant(rrc, dtype=tf.float32)\n",
        "        return rrc\n",
        "\n",
        "    def upsample_and_filter(self, signal):\n",
        "        upsampled_signal = self.upsample_iq(signal)\n",
        "        rrc = self.rrc_filter()\n",
        "\n",
        "        upsampled_signal = tf.expand_dims(upsampled_signal, axis=0)  # Shape: (1, length, 2)\n",
        "        rrc = tf.reshape(rrc, [-1, 1, 1])  # Shape: (filter_length, 1, 1)\n",
        "\n",
        "        padding_size = self.num_taps // 2\n",
        "        paddings = tf.constant([[0, 0], [padding_size, padding_size], [0, 0]])\n",
        "        padded_real = tf.pad(upsampled_signal[:, :, 0:1], paddings, \"CONSTANT\")\n",
        "        padded_imag = tf.pad(upsampled_signal[:, :, 1:2], paddings, \"CONSTANT\")\n",
        "        upsampled_signal = tf.concat([padded_real, padded_imag], axis=2)\n",
        "\n",
        "        real_filtered = tf.nn.conv1d(upsampled_signal[:, :, 0:1], rrc, stride=1, padding='SAME')\n",
        "        imag_filtered = tf.nn.conv1d(upsampled_signal[:, :, 1:2], rrc, stride=1, padding='SAME')\n",
        "\n",
        "        filtered_signal = tf.concat([real_filtered, imag_filtered], axis=2)\n",
        "        filtered_signal = tf.squeeze(filtered_signal, axis=0)  # Remove the batch dimension\n",
        "        return filtered_signal\n",
        "\n",
        "    def time_offset(self, sampling_time=10):\n",
        "        # t_offset = np.random.uniform(-sampling_time // 2, sampling_time // 2)\n",
        "        t_offset = 0\n",
        "        # t_offset = 0\n",
        "        return t_offset\n",
        "\n",
        "    # def call(self, inputs):\n",
        "    #     f = inputs.shape[1]//2\n",
        "    #     inputs = tf.reshape(inputs, [-1, 2])  # Reshape to pairs of real and imaginary\n",
        "    #     output = []\n",
        "    #     for i in inputs:\n",
        "    #         i = tf.reshape(i, [-1, 2])  # Reshape input pairs as necessary\n",
        "    #         print(i.shape)\n",
        "    #         filtered_signal = self.upsample_and_filter(i)\n",
        "    #         filtered_signal = tf.reshape(filtered_signal, [2,-1])  # Flatten the filtered signal\n",
        "    #         output.append(filtered_signal)\n",
        "\n",
        "    #     stacked_tensor = tf.stack(output, axis=0)  # Stack the filtered signals\n",
        "    #     stacked_tensor = tf.reshape(stacked_tensor, [stacked_tensor.shape[0]//f, -1])  # Reshape back to original shape\n",
        "    #     return stacked_tensor # here each data have real part and then follow by complex part. eg [real components , imaginary parts]\n",
        "\n",
        "    # def call(self, inputs):\n",
        "    #     batch_size = tf.shape(inputs)[0]\n",
        "    #     f = inputs.shape[1] // 2\n",
        "    #     def slice_sample(sample):\n",
        "    #       array = [tf.reshape(i,[-1,2]) for i in sample ]\n",
        "    #       out = [self.upsample_and_filter(j) for j in array]\n",
        "    #       return tf.stack(out, axis=0)\n",
        "    #     # Reshape to pairs of real and imaginary parts\n",
        "    #     inputs = tf.reshape(inputs, [batch_size, -1, 2])  # Shape: (batch_size, num_pairs, 2)\n",
        "    #     print(inputs.shape)\n",
        "    #     # Define a function to process each sample\n",
        "    #     \"\"\" this below also  working but not able to integrate in model\"\"\"\n",
        "    #     # def process_sample(sample):\n",
        "    #     #     filtered_signal = slice_sample(sample)\n",
        "    #     #     # filtered_signal = self.upsample_and_filter(sample)  # Process each sample\n",
        "    #     #     return filtered_signal\n",
        "    #     def process_sample(sample):\n",
        "    #         a = tf.reshape(sample[0,:],[1,2])\n",
        "    #         b = tf.reshape(sample[1,:],[1,2])\n",
        "    #         c = tf.reshape(sample[2,:],[1,2])\n",
        "    #         d = tf.reshape(sample[3,:],[1,2])\n",
        "    #         fil_a, fil_b, fil_c,fil_d= self.upsample_and_filter(a), self.upsample_and_filter(b), self.upsample_and_filter(c), self.upsample_and_filter(d)\n",
        "    #         filtered_signal = tf.stack([fil_a, fil_b, fil_c, fil_d], axis=0)\n",
        "    #         return filtered_signal\n",
        "\n",
        "    #     # Apply the function to each sample in the batch\n",
        "    #     output = tf.map_fn(process_sample, inputs, dtype=tf.float32)  # Shape: (batch_size, num_filtered_samples, 2)\n",
        "\n",
        "    #     # Reshape back to original shape if necessary\n",
        "    #     output = tf.reshape(output, [batch_size, -1])\n",
        "\n",
        "    #     return output\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        f = inputs.shape[1] // 2\n",
        "\n",
        "        # Reshape to pairs of real and imaginary parts\n",
        "        inputs = tf.reshape(inputs, [batch_size, -1, 2])  # Shape: (batch_size, num_pairs, 2)\n",
        "\n",
        "        # Define a function to process each sample\n",
        "        def process_sample(sample):\n",
        "            filtered_signal = self.upsample_and_filter(sample)  # Process each sample\n",
        "            return filtered_signal\n",
        "\n",
        "        # Apply the function to each sample in the batch\n",
        "        output = tf.map_fn(process_sample, inputs, dtype=tf.float32)  # Shape: (batch_size, num_filtered_samples, 2)\n",
        "\n",
        "        # Reshape back to original shape if necessary\n",
        "        output = tf.reshape(output, [batch_size, -1])\n",
        "\n",
        "        return output\n",
        "\n",
        "small = Model(inputs = autoencoder_model[0].get_layer('Input').input, outputs = autoencoder_model[0].get_layer('normalization').output)\n",
        "p_out = small.predict(train_dataset[:1],batch_size = 1)\n",
        "print(p_out)\n",
        "print(p_out.shape)\n",
        "v_out = StochasticChannelv3()(p_out)\n",
        "print(p_out.shape)\n",
        "print(\"-------------------------------------------------------------\")\n",
        "print(v_out.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mP0F-0iGZymQ"
      },
      "source": [
        "## stochastic channel for one message at a time for rrc filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3puH4JrZyCF"
      },
      "outputs": [],
      "source": [
        "class StochasticChannelv3(tf.keras.layers.Layer):\n",
        "    def __init__(self, roll_off=0.35, num_taps=31, time_delay=2, r=4, ts=.5e-6, **kwargs):\n",
        "        super(StochasticChannelv3, self).__init__(**kwargs)\n",
        "        self.num_taps = num_taps\n",
        "        self.time_delay = time_delay\n",
        "        self.r = r  # Upsampling factor\n",
        "        self.roll_off = roll_off  # Roll-off factor\n",
        "        self.ts = ts  # Sampling period (default is 1)\n",
        "\n",
        "    def upsampling(self, inp):\n",
        "        com_reshape = tf.reshape(inp, [-1, 1])\n",
        "        padding = tf.constant([[0, 0], [0, self.r - 1]])  # Access self.r\n",
        "        upsampled = tf.pad(com_reshape, padding, mode=\"CONSTANT\")\n",
        "        upsampled = tf.reshape(upsampled, [-1])  # Flatten back to 1D\n",
        "        print(upsampled.shape)\n",
        "        return upsampled\n",
        "\n",
        "    def upsample_iq(self, inp):\n",
        "        real = inp[:, 0]  # Real part\n",
        "        imag = inp[:, 1]  # Imaginary part\n",
        "\n",
        "        real_up = self.upsampling(real)\n",
        "        imag_up = self.upsampling(imag)\n",
        "\n",
        "        upsampled = tf.stack([real_up, imag_up], axis=1)\n",
        "        return upsampled\n",
        "\n",
        "    def rrc_filter(self):\n",
        "        t = np.linspace(-self.num_taps // 2, self.num_taps // 2 + 1, self.num_taps) - self.time_offset()\n",
        "        rrc = np.zeros_like(t)\n",
        "\n",
        "        for i in range(len(t)):\n",
        "            if t[i] == 0.0:\n",
        "                rrc[i] = (1.0 - self.roll_off + 4 * self.roll_off / np.pi) / self.ts\n",
        "            elif np.abs(t[i]) == self.ts / (4 * self.roll_off):\n",
        "                rrc[i] = (self.roll_off / (np.sqrt(2) * self.ts)) * \\\n",
        "                         ((1 + 2 / np.pi) * np.sin(np.pi / (4 * self.roll_off)) +\n",
        "                          (1 - 2 / np.pi) * np.cos(np.pi / (4 * self.roll_off)))\n",
        "            else:\n",
        "                rrc[i] = (np.sin(np.pi * (t[i] / self.ts) * (1 - self.roll_off)) +\n",
        "                          4 * self.roll_off * (t[i] / self.ts) * np.cos(np.pi * (t[i] / self.ts) * (1 + self.roll_off))) / \\\n",
        "                         (np.pi * t[i] * (1 - (4 * self.roll_off * (t[i] / self.ts)) ** 2))\n",
        "\n",
        "        rrc = rrc / np.sqrt(np.sum(rrc ** 2))\n",
        "        rrc = tf.constant(rrc, dtype=tf.float32)\n",
        "        return rrc\n",
        "\n",
        "    def upsample_and_filter(self, signal):\n",
        "        upsampled_signal = self.upsample_iq(signal)\n",
        "        rrc = self.rrc_filter()\n",
        "\n",
        "        upsampled_signal = tf.expand_dims(upsampled_signal, axis=0)  # Shape: (1, length, 2)\n",
        "        rrc = tf.reshape(rrc, [-1, 1, 1])  # Shape: (filter_length, 1, 1)\n",
        "\n",
        "        padding_size = self.num_taps // 2\n",
        "        paddings = tf.constant([[0, 0], [padding_size, padding_size], [0, 0]])\n",
        "        padded_real = tf.pad(upsampled_signal[:, :, 0:1], paddings, \"CONSTANT\")\n",
        "        padded_imag = tf.pad(upsampled_signal[:, :, 1:2], paddings, \"CONSTANT\")\n",
        "        upsampled_signal = tf.concat([padded_real, padded_imag], axis=2)\n",
        "        real_filtered = tf.nn.conv1d(upsampled_signal[:, :, 0:1], rrc, stride=1, padding='SAME')\n",
        "        imag_filtered = tf.nn.conv1d(upsampled_signal[:, :, 1:2], rrc, stride=1, padding='SAME')\n",
        "\n",
        "        filtered_signal = tf.concat([real_filtered, imag_filtered], axis=2)\n",
        "        filtered_signal = tf.squeeze(filtered_signal, axis=0)  # Remove the batch dimension\n",
        "        return filtered_signal\n",
        "\n",
        "    def time_offset(self, sampling_time=10):\n",
        "        t_offset = np.random.uniform(-sampling_time // 2, sampling_time // 2)\n",
        "        return t_offset\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        f = inputs.shape[1] // 2\n",
        "\n",
        "        # Reshape to pairs of real and imaginary parts\n",
        "        inputs = tf.reshape(inputs, [batch_size, -1, 2])  # Shape: (batch_size, num_pairs, 2)\n",
        "\n",
        "        # Define a function to process each sample\n",
        "        def process_sample(sample):\n",
        "            filtered_signal = self.upsample_and_filter(sample)  # Process each sample\n",
        "            return filtered_signal\n",
        "\n",
        "        # Apply the function to each sample in the batch\n",
        "        output = tf.map_fn(process_sample, inputs, dtype=tf.float32)  # Shape: (batch_size, num_filtered_samples, 2)\n",
        "\n",
        "        # Reshape back to original shape if necessary\n",
        "        output = tf.reshape(output, [batch_size, -1])\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTUthTyGbFYa"
      },
      "source": [
        "## stochastic channel for continuous transmission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3gDIgDQbJsn"
      },
      "outputs": [],
      "source": [
        "  \"\"\"\n",
        "  When using this make sure that batch size is divisible by 2*l+1\n",
        "  \"\"\"\n",
        "class StochasticChannelv3_cts_tr(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, roll_off=0.35, num_taps=31, time_delay=2, r=4, ts=.5e-6,l = 6, **kwargs):\n",
        "        super(StochasticChannelv3_cts_tr, self).__init__(**kwargs)\n",
        "        self.num_taps = num_taps\n",
        "        self.time_delay = time_delay\n",
        "        self.r = r  # Upsampling factor\n",
        "        self.roll_off = roll_off  # Roll-off factor\n",
        "        self.ts = ts  # Sampling period (default is 1)\n",
        "        self.l = l\n",
        "\n",
        "    def upsampling(self, inp):\n",
        "        com_reshape = tf.reshape(inp, [-1, 1])\n",
        "        padding = tf.constant([[0, 0], [0, self.r - 1]])  # Access self.r\n",
        "        upsampled = tf.pad(com_reshape, padding, mode=\"CONSTANT\")\n",
        "        upsampled = tf.reshape(upsampled, [-1])  # Flatten back to 1D\n",
        "        return upsampled\n",
        "\n",
        "    def upsample_iq(self, inp):\n",
        "        real = inp[:, 0]  # Real part\n",
        "        imag = inp[:, 1]  # Imaginary part\n",
        "\n",
        "        real_up = self.upsampling(real)\n",
        "        imag_up = self.upsampling(imag)\n",
        "        upsampled = tf.stack([real_up, imag_up], axis=1)\n",
        "        return upsampled\n",
        "\n",
        "    def rrc_filter(self):\n",
        "        print(\"time offset for this task\", self.time_offset())\n",
        "        t = np.linspace(-self.num_taps // 2, self.num_taps // 2 + 1, self.num_taps) - self.time_offset()\n",
        "        rrc = np.zeros_like(t)\n",
        "\n",
        "        for i in range(len(t)):\n",
        "            if t[i] == 0.0:\n",
        "                rrc[i] = (1.0 - self.roll_off + 4 * self.roll_off / np.pi) / self.ts\n",
        "            elif np.abs(t[i]) == self.ts / (4 * self.roll_off):\n",
        "                rrc[i] = (self.roll_off / (np.sqrt(2) * self.ts)) * \\\n",
        "                         ((1 + 2 / np.pi) * np.sin(np.pi / (4 * self.roll_off)) +\n",
        "                          (1 - 2 / np.pi) * np.cos(np.pi / (4 * self.roll_off)))\n",
        "            else:\n",
        "                rrc[i] = (np.sin(np.pi * (t[i] / self.ts) * (1 - self.roll_off)) +\n",
        "                          4 * self.roll_off * (t[i] / self.ts) * np.cos(np.pi * (t[i] / self.ts) * (1 + self.roll_off))) / \\\n",
        "                         (np.pi * t[i] * (1 - (4 * self.roll_off * (t[i] / self.ts)) ** 2))\n",
        "\n",
        "        rrc = rrc / np.sqrt(np.sum(rrc ** 2))\n",
        "        rrc = tf.constant(rrc, dtype=tf.float32)\n",
        "        return rrc\n",
        "\n",
        "    def upsample_and_filter(self, signal):\n",
        "        upsampled_signal = self.upsample_iq(signal)\n",
        "        rrc = self.rrc_filter()\n",
        "\n",
        "\n",
        "        upsampled_signal = tf.expand_dims(upsampled_signal, axis=0)  # Shape: (1, length, 2)\n",
        "        rrc = tf.reshape(rrc, [-1, 1, 1])  # Shape: (filter_length, 1, 1)\n",
        "\n",
        "        padding_size = self.num_taps // 2\n",
        "        paddings = tf.constant([[0, 0], [padding_size, padding_size], [0, 0]])\n",
        "        padded_real = tf.pad(upsampled_signal[:, :, 0:1], paddings, \"CONSTANT\")\n",
        "        padded_imag = tf.pad(upsampled_signal[:, :, 1:2], paddings, \"CONSTANT\")\n",
        "        upsampled_signal = tf.concat([padded_real, padded_imag], axis=2)\n",
        "        real_filtered = tf.nn.conv1d(upsampled_signal[:, :, 0:1], rrc, stride=1, padding='SAME')\n",
        "        imag_filtered = tf.nn.conv1d(upsampled_signal[:, :, 1:2], rrc, stride=1, padding='SAME')\n",
        "\n",
        "        filtered_signal = tf.concat([real_filtered, imag_filtered], axis=2)\n",
        "        filtered_signal = tf.squeeze(filtered_signal, axis=0)  # Remove the batch dimension\n",
        "        return filtered_signal\n",
        "\n",
        "    def time_offset(self, sampling_time=10):\n",
        "        t_offset = np.random.uniform(-sampling_time // 2, sampling_time // 2)\n",
        "        return 0\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        f = inputs.shape[1] // 2\n",
        "        beta = batch_size//(2*self.l+1)\n",
        "        out= []\n",
        "        for i in range(beta):\n",
        "          x = inputs[(2*self.l+1)*i:(2*self.l+1)*(i+1)]\n",
        "          # c = tf.concat(tf.unstack(x, axis=1), axis=0)  # Unstack along axis=1 and concatenate\n",
        "          out.append(x)\n",
        "        inputs = tf.stack(out, axis=0)\n",
        "\n",
        "        # Reshape to pairs of real and imaginary parts\n",
        "        inputs = tf.reshape(inputs, [batch_size//(2*self.l+1), -1, 2])  # Shape: (batch_size, num_pairs, 2)\n",
        "\n",
        "\n",
        "        # Define a function to process each sample\n",
        "        def process_sample(sample):\n",
        "            filtered_signal = self.upsample_and_filter(sample)  # Process each sample\n",
        "            return filtered_signal\n",
        "\n",
        "        # Apply the function to each sample in the batch\n",
        "        output = tf.map_fn(process_sample, inputs, dtype=tf.float32)  # Shape: (batch_size, num_filtered_samples, 2)\n",
        "\n",
        "        # Reshape back to original shape if necessary\n",
        "        output = tf.reshape(output, [batch_size//(2*self.l+1), -1])\n",
        "\n",
        "        return output\n",
        "\n",
        "    # def call(self, inputs):\n",
        "    #     batch_size = tf.shape(inputs)[0]\n",
        "    #     group_size = 2 * self.l + 1  # Define the group size\n",
        "\n",
        "    #     # Reshape inputs into groups of (2 * l + 1)\n",
        "    #     # This creates a tensor of shape (beta, group_size, input_dim)\n",
        "    #     beta = batch_size // group_size\n",
        "    #     # inputs = tf.reshape(inputs, [beta, group_size, -1])  # Reshape without a for loop\n",
        "    #     print('input shape before the sub grpups ',inputs.shape)\n",
        "    #     # Reshape to pairs of real and imaginary parts\n",
        "    #     inputs = tf.reshape(inputs, [beta, -1, 2])  # Shape: (batch_size, num_pairs, 2)\n",
        "\n",
        "    #     # need to create the window\n",
        "\n",
        "    #     # Define a function to process each sample\n",
        "    #     def process_sample(sample):\n",
        "    #         filtered_signal = self.upsample_and_filter(sample)  # Process each sample\n",
        "    #         return filtered_signal\n",
        "\n",
        "    #     # Apply the function to each sample in the batch using tf.map_fn\n",
        "    #     output = tf.map_fn(process_sample, inputs, dtype=tf.float32)\n",
        "\n",
        "\n",
        "    #     # Reshape back to original shape if necessary\n",
        "    #     output = tf.reshape(output, [beta, -1])\n",
        "    #     print('output shape after do the sub group', output.shape)\n",
        "\n",
        "    #     # # include slidcer to the model\n",
        "    #     # k1 = self.r * 4 + (self.num_taps + 1) // 2\n",
        "    #     # k2 = 2 * self.l * self.r * 4 + (self.num_taps - 1) // 2\n",
        "    #     # seq_len = k2 - k1 + 1\n",
        "    #     # print(f\"k1: {k1}, k2: {k2}, seq_len: {seq_len}\")\n",
        "    #     # output = output[:, k1:(k2+1)]\n",
        "    #     # print(output.shape)\n",
        "\n",
        "    #     return output\n",
        "\n",
        "    def call(self, inputs,return_offset=False):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        input_dim = tf.shape(inputs)[1]\n",
        "\n",
        "        # Ensure group_size divides batch_size evenly\n",
        "        group_size = 2 * self.l + 1  # e.g., 13\n",
        "        # if batch_size % group_size != 0:\n",
        "        #     raise ValueError(f\"Batch size ({batch_size}) must be divisible by group size ({group_size}).\")\n",
        "\n",
        "        # Reshape inputs into groups without changing the batch size\n",
        "        num_groups = batch_size // group_size\n",
        "        inputs = tf.reshape(inputs, [num_groups, group_size, input_dim])\n",
        "\n",
        "        # Merge group_size into the features dimension\n",
        "        inputs = tf.reshape(inputs, [batch_size // group_size, group_size * input_dim])\n",
        "\n",
        "        # Reshape to pairs of real and imaginary parts\n",
        "        inputs = tf.reshape(inputs, [batch_size // group_size, -1, 2])\n",
        "\n",
        "        # Define a function to process each sample\n",
        "        def process_sample(sample):\n",
        "            filtered_signal = self.upsample_and_filter(sample)\n",
        "            return filtered_signal\n",
        "\n",
        "        # Apply the function to each sample in the batch using tf.map_fn\n",
        "        output = tf.map_fn(process_sample, inputs, dtype=tf.float32)\n",
        "\n",
        "        # Reshape back to original batch size\n",
        "        output = tf.reshape(output, [batch_size // group_size, -1])\n",
        "\n",
        "        # Expand the output to match the original batch size\n",
        "        output = tf.tile(output, [group_size, 1])\n",
        "        print(output.shape)\n",
        "        batch_time_offset = self.time_offset()\n",
        "        # include slidcer to the model\n",
        "        k1 = self.r * 4 + (self.num_taps + 1) // 2\n",
        "        k2 = 2 * self.l * self.r * 4 + (self.num_taps - 1) // 2\n",
        "        seq_len = k2 - k1 + 1\n",
        "        print(f\"k1: {k1}, k2: {k2}, seq_len: {seq_len}\")\n",
        "        in_dim = output.shape[1]\n",
        "\n",
        "        output_1 = output[:, k1-1:k2]\n",
        "        output_2 = output[:, in_dim//2+k1-1:in_dim//2+k2]\n",
        "        print(output_1.shape)\n",
        "        print(output_2.shape)\n",
        "        output = tf.concat([output_1, output_2],axis = 1)\n",
        "        print(output.shape)\n",
        "        if return_offset:\n",
        "            # If we need to return the time offset (for training the offset estimator)\n",
        "            return output, batch_time_offset\n",
        "        else:\n",
        "            # If we're just passing through the autoencoder\n",
        "            return output\n",
        "        return output\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAZwtBRvdElo"
      },
      "source": [
        "## testing purpose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3krlFhrfdHgD"
      },
      "outputs": [],
      "source": [
        "small = Model(inputs = autoencoder_model[0].get_layer('Input').input, outputs = autoencoder_model[0].get_layer('normalization').output)\n",
        "test_1 = small.predict(train_dataset[:13*21],batch_size = 1)\n",
        "print(test_1.shape)\n",
        "print(\"-------------------------------------------------------------\")\n",
        "out_test = StochasticChannelv3_cts_tr(num_taps = 31,l=0)(test_1)\n",
        "print(out_test.shape)\n",
        "\n",
        "rx_model = Model(inputs = autoencoder_model[0].get_layer('noise').input, outputs = autoencoder_model[0].get_layer('Output').output)\n",
        "rx_model.summary()\n",
        "\n",
        "\n",
        "# out_test_reshaped = tf.reshape(out_test, [-1, 92])  # Adjust shape as needed\n",
        "# test_2 = rx_model.predict(out_test_reshaped, batch_size=1)\n",
        "# print(test_2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1ktXY7sE33-"
      },
      "outputs": [],
      "source": [
        "class rx:\n",
        "    def __init__(self, train_data=train_dataset, test_data=test_dataset, input_dim=K, enc_dim=N, act_fun='tanh'):\n",
        "        self.train_data = train_data\n",
        "        self.test_data = test_data\n",
        "        self.input_dim = input_dim\n",
        "        self.enc_dim = enc_dim\n",
        "        self.act_fun = act_fun\n",
        "\n",
        "    def AE_implement(self):\n",
        "        autoencoder = Sequential([\n",
        "\n",
        "            # NormalizedRRCFilterLayer( ),\n",
        "            CustomNoise(name = 'noise'),\n",
        "\n",
        "            # Decoder layers\n",
        "            Dense(self.enc_dim * 4, activation=self.act_fun, name=\"decoder1\"),\n",
        "            Dense(2**(self.input_dim), activation=self.act_fun, name='decoder2'),\n",
        "            Dense(2**(self.input_dim), activation='softmax', name='Output')\n",
        "        ])\n",
        "\n",
        "        autoencoder.compile(optimizer=Adam(learning_rate=1e-2), loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "        return autoencoder\n",
        "\n",
        "    def train(self, epochs=20, batch_size=64):\n",
        "        autoencoder = self.AE_implement()\n",
        "        # autoencoder.fit(self.train_data, self.train_data,\n",
        "        #                 epochs=epochs, batch_size=batch_size,\n",
        "        #                 validation_data=(self.test_data, self.test_data))\n",
        "        # # return autoencoder\n",
        "\n",
        "        # TensorBoard setup\n",
        "        log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "        tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "        print(self.test_data.shape)\n",
        "\n",
        "        history = autoencoder.fit(self.train_data, self.train_data,\n",
        "                                  epochs=epochs, batch_size=1*13,\n",
        "                                  validation_data=(self.test_data, self.test_data),\n",
        "                                  callbacks=[PlottingCallback(), tensorboard_callback])\n",
        "        return autoencoder, history\n",
        "\n",
        "rx_model = rx(train_data=out_test, test_data=test_dataset[:13*13], input_dim=K, enc_dim=N, act_fun='relu')\n",
        "rxc,_ = rx_model.train(epochs=5, batch_size=13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fw7MO6Mkp3xZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Example tensors (1D tensors with d elements)\n",
        "tensor1 = tf.constant([1.0, 2.0, 3.0, 4.0])\n",
        "tensor2 = tf.constant([5.0, 6.0, 7.0, 8.0])\n",
        "\n",
        "# Concatenate along the last axis to get a 1D tensor with size 2d\n",
        "concatenated_tensor = tf.concat([tensor1, tensor2], axis=0)\n",
        "\n",
        "# Reshape to a 1x(2d) tensor\n",
        "concatenated_tensor_reshaped = tf.reshape(concatenated_tensor, [1, -1])\n",
        "\n",
        "print(\"Concatenated 1x(2d) tensor:\")\n",
        "print(concatenated_tensor_reshaped)\n",
        "print(f\"Shape of concatenated tensor: {concatenated_tensor_reshaped.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZJqa7ji7qo0"
      },
      "outputs": [],
      "source": [
        "print(type(v_out[0]))\n",
        "v = tf.reshape(v_out[0], [-1, 2])\n",
        "print(v.shape)\n",
        "# Assuming v_out is a NumPy array or a Tensor that can be converted to a NumPy array\n",
        "# Convert TensorFlow tensor to NumPy array if necessary\n",
        "v_out_np = v.numpy() if isinstance(v, tf.Tensor) else v\n",
        "\n",
        "# Plot the signal\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# If v_out[0] has both real and imaginary parts, plot them separately\n",
        "if v_out_np.ndim == 2 and v_out_np.shape[1] == 2:  # Shape (num_samples, 2)\n",
        "    plt.plot(v_out_np[:, 0], label='Real Part')\n",
        "    plt.plot(v_out_np[:, 1], label='Imaginary Part')\n",
        "    plt.legend()\n",
        "else:\n",
        "    # If it's 1D, just plot the signal\n",
        "    plt.plot(v_out_np)\n",
        "\n",
        "plt.title(\"Plot of v_out[0]\")\n",
        "plt.xlabel(\"Sample Index\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6ZEdfDsI6gI"
      },
      "source": [
        "# slicer operation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyqLgn-JwBwr"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class Slicer(tf.keras.layers.Layer):\n",
        "    def __init__(self, output_dim=12, l=6, rate=4, n=4, L=31):\n",
        "        super(Slicer, self).__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.l = l\n",
        "        self.rate = rate\n",
        "        self.n = n\n",
        "        self.L = L  # number of taps\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Ensure inputs are complex or structured in real-imaginary pairs\n",
        "        # if tf.is_tensor(inputs):\n",
        "            # Get batch size dynamically\n",
        "            batch_size = tf.shape(inputs)[0]\n",
        "\n",
        "            # Define k1, k2, seq_len based on your parameters\n",
        "            k1 = self.rate * self.n + (self.L + 1) // 2\n",
        "            k2 = 2 * self.l * self.rate * self.n + (self.L - 1) // 2\n",
        "            seq_len = k2 - k1 + 1\n",
        "            print(f\"k1: {k1}, k2: {k2}, seq_len: {seq_len}\")\n",
        "\n",
        "\n",
        "\n",
        "            # Print the shape or value of sliced output for debugging\n",
        "            print(f\"Sliced output shape: {sliced_output.shape}\")\n",
        "            print(f\"Sample sliced output[0]: {sliced_output[0]}\")\n",
        "\n",
        "            return sliced_output\n",
        "\n",
        "\n",
        "v = Slicer(test_dataset)\n",
        "print(v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qR0RdF7zI9Xx"
      },
      "outputs": [],
      "source": [
        "slice_input = v_out\n",
        "slice_input = tf.reshape(slice_input, [slice_input.shape[0], slice_input.shape[2]*2])\n",
        "print(slice_input.shape)\n",
        "rate = 4\n",
        "n = 4\n",
        "L = 31\n",
        "l =  6\n",
        "def slicer(inp):\n",
        "  inp = tf.reshape(inp, [-1, inp.shape[1]*2])\n",
        "  k1 = rate*n + (L+1)//2\n",
        "  k2 = 2*l*rate*n + (L-1)//2\n",
        "  seq_len = k2 - k1 +1\n",
        "  print(k1,k2,seq_len)\n",
        "  print(inp.shape[0])\n",
        "  out = []\n",
        "  for i in range(1,inp.shape[0]//seq_len):\n",
        "    sliced = inp[(i-1)*seq_len:i*seq_len, :]\n",
        "\n",
        "    out.append(sliced)\n",
        "  return out\n",
        "\n",
        "slice_out = slicer(slice_input)\n",
        "tensor_stack = tf.stack(slice_out[1:],axis =0)\n",
        "print(slice_input.shape)\n",
        "print(tensor_stack.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zpkh3cKCxQzL"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class StochasticChannel(tf.keras.layers.Layer):\n",
        "    def __init__(self, roll_off=0.35, num_taps=101, time_delay=0, rate=1, **kwargs):\n",
        "        super(StochasticChannel, self).__init__(**kwargs)\n",
        "        self.num_taps = num_taps\n",
        "        self.time_delay = time_delay\n",
        "        self.rate = rate\n",
        "        self.roll_off = roll_off\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Call the real_to_complex_tensor method and return the result\n",
        "        return self.real_to_complex_tensor(inputs)\n",
        "\n",
        "# Assuming `enc` is your input tensor\n",
        "stochastic_channel = StochasticChannel(rate=2, roll_off=0.35, num_taps=101)\n",
        "y = real_to_complex_tensor(test_dataset)\n",
        "print((y))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rM2qUxDbNTUW"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-commpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCLx5dvYNOKQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from commpy.filters import rrcosfilter\n",
        "from scipy.signal import convolve\n",
        "\n",
        "# Define parameters for the RRC filter\n",
        "alpha = 0.35  # Roll-off factor\n",
        "sps = 8       # Samples per symbol (oversampling factor)\n",
        "num_taps = 101  # Number of filter taps (should be odd)\n",
        "Ts = 1        # Symbol period\n",
        "\n",
        "# Generate the RRC filter\n",
        "taps, t = rrcosfilter(num_taps, alpha, Ts, sps)\n",
        "\n",
        "# Generate a random signal with shape (5120, 8) or use your signal here\n",
        "signal = np.random.randn(5120, 8)  # Example: random signal\n",
        "\n",
        "# Initialize a matrix to hold the filtered signal output\n",
        "filtered_signal = np.zeros((signal.shape[0], signal.shape[1]+ num_taps - 1))\n",
        "\n",
        "# Apply the RRC filter to each column (i.e., each signal channel)\n",
        "for i in range(signal.shape[0]):\n",
        "    filtered_signal[i,:] = convolve(signal[i,:], taps, mode='full')\n",
        "\n",
        "# Check the dimensions of the filtered signal\n",
        "print(f\"Input signal shape: {signal.shape}\")\n",
        "print(f\"Filtered signal shape: {filtered_signal.shape}\")\n",
        "print(f\"Expected shape: {(signal.shape[0] , signal.shape[1]+ len(taps) - 1)}\")\n",
        "\n",
        "# Plotting the first column of the filtered signal for visualization\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(filtered_signal[:,0])\n",
        "plt.title(\"Filtered Signal (Column 1) - Full Convolution with RRC Filter\")\n",
        "plt.xlabel(\"Samples\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWssqDE2aidM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from scipy.signal import convolve\n",
        "from commpy.filters import rrcosfilter\n",
        "\n",
        "import tensorflow as tf\n",
        "from commpy.filters import rrcosfilter\n",
        "\n",
        "class NormalizedRRCFilterLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, alpha=0.35, sps=1, num_taps=101, ts=1, upsample_factor=4):\n",
        "        \"\"\"\n",
        "        Initialize the layer with RRC filter parameters and upsampling factor.\n",
        "\n",
        "        Args:\n",
        "            alpha: Roll-off factor (0 <= alpha <= 1).\n",
        "            sps: Samples per symbol (upsampling factor).\n",
        "            num_taps: Number of filter taps (should be odd).\n",
        "            ts: Sampling period (default is 1).\n",
        "            upsample_factor: The factor by which to upsample the input signals.\n",
        "        \"\"\"\n",
        "        super(NormalizedRRCFilterLayer, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.sps = sps\n",
        "        self.num_taps = num_taps\n",
        "        self.ts = ts\n",
        "        self.upsample_factor = upsample_factor\n",
        "\n",
        "        # Create the RRC filter when the layer is initialized\n",
        "        self.rrc_taps, _ = self.create_rrc_filter()\n",
        "\n",
        "    def create_rrc_filter(self):\n",
        "        \"\"\"Generate the RRC filter coefficients using commpy.\"\"\"\n",
        "        taps, _ = rrcosfilter(self.num_taps, self.alpha, self.ts, self.sps)\n",
        "        taps = tf.convert_to_tensor(taps, dtype=tf.float32)\n",
        "        return taps, _\n",
        "\n",
        "    def upsample(self, input_tensor):\n",
        "        \"\"\"Upsample the input tensor by inserting r-1 zeros between each element.\"\"\"\n",
        "        input_shape = tf.shape(input_tensor)\n",
        "        expanded_input = tf.expand_dims(input_tensor, axis=-1)  # Add an extra dimension\n",
        "\n",
        "        # Create a tensor of zeros with the same shape as input, but r times the last dimension\n",
        "        zero_padding = tf.zeros_like(expanded_input)\n",
        "        zero_padding = tf.tile(zero_padding, [1, 1, self.upsample_factor-1])  # Repeat the zeros r-1 times\n",
        "\n",
        "        # Concatenate input and zero_padding along the last dimension\n",
        "        upsampled = tf.concat([expanded_input, zero_padding], axis=-1)\n",
        "\n",
        "        # Reshape to flatten the added dimension\n",
        "        new_shape = [input_shape[0], input_shape[1] * self.upsample_factor]\n",
        "        upsampled_flat = tf.reshape(upsampled, new_shape)\n",
        "        return upsampled_flat\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"Forward pass for the layer, converting real to complex and applying RRC filter.\"\"\"\n",
        "        batch_size = tf.shape(inputs)[0]  # Batch size\n",
        "        inner_dim = tf.shape(inputs)[1]   # Inner dimension size\n",
        "        print( inner_dim, batch_size)\n",
        "        # Ensure that the inner dimension is even\n",
        "        # assert inner_dim % 2 == 0, \"Inner dimension must be even for real and imaginary pairs.\"\n",
        "\n",
        "        # Reshape the input tensor to separate real and imaginary parts\n",
        "        reshaped_tensor = tf.reshape(inputs, [batch_size, inner_dim // 2, 2])\n",
        "\n",
        "        # Extract real and imaginary parts\n",
        "        real_part = reshaped_tensor[:, :, 0]\n",
        "        imag_part = reshaped_tensor[:, :, 1]\n",
        "\n",
        "        # Upsample real and imaginary parts\n",
        "        real_part = self.upsample(real_part)\n",
        "        imag_part = self.upsample(imag_part)\n",
        "\n",
        "        # Reshape taps for 1D convolution\n",
        "        rrc_taps = tf.reshape(self.rrc_taps, [-1, 1, 1])  # Shape: (filter_length, 1, 1)\n",
        "\n",
        "        # Add an extra dimension to real and imaginary parts for conv1d\n",
        "        real_part = tf.expand_dims(real_part, axis=-1)\n",
        "        imag_part = tf.expand_dims(imag_part, axis=-1)\n",
        "\n",
        "        # Apply the RRC filter using TensorFlow's conv1d\n",
        "        real_filtered = tf.nn.conv1d( rrc_taps,real_part, stride=1, padding='VALID')\n",
        "        imag_filtered = tf.nn.conv1d( rrc_taps,imag_part, stride=1, padding='VALID')\n",
        "\n",
        "        # Remove the extra dimension\n",
        "        real_filtered = tf.squeeze(real_filtered, axis=-1)\n",
        "        imag_filtered = tf.squeeze(imag_filtered, axis=-1)\n",
        "\n",
        "        # Interleave real and imaginary parts\n",
        "        interleaved = tf.stack([real_filtered, imag_filtered], axis=-1)  # Shape: (batch_size, time_length, 2)\n",
        "        interleaved = tf.reshape(interleaved, [batch_size, -1])  # Flatten to (batch_size, time_length*2)\n",
        "\n",
        "        return interleaved\n",
        "\n",
        "\n",
        "class NormalizedRRCFilterLayer_v2(tf.keras.layers.Layer):\n",
        "    def __init__(self, alpha=0.35, sps=1, num_taps=101, ts=1, upsample_factor=4):\n",
        "        \"\"\"\n",
        "        Initialize the layer with RRC filter parameters and upsampling factor.\n",
        "\n",
        "        Args:\n",
        "            alpha: Roll-off factor (0 <= alpha <= 1).\n",
        "            sps: Samples per symbol (upsampling factor).\n",
        "            num_taps: Number of filter taps (should be odd).\n",
        "            ts: Sampling period (default is 1).\n",
        "            upsample_factor: The factor by which to upsample the input signals.\n",
        "        \"\"\"\n",
        "        super(NormalizedRRCFilterLayer_v2, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.sps = sps\n",
        "        self.num_taps = num_taps\n",
        "        self.ts = ts\n",
        "        self.upsample_factor = upsample_factor\n",
        "\n",
        "        # Create the RRC filter when the layer is initialized\n",
        "        self.rrc_taps, _ = self.create_rrc_filter()\n",
        "\n",
        "    def create_rrc_filter(self):\n",
        "        \"\"\"Generate the RRC filter coefficients using commpy.\"\"\"\n",
        "        taps, _ = rrcosfilter(self.num_taps, self.alpha, self.ts, self.sps)\n",
        "        return taps, _\n",
        "\n",
        "    def upsample(self, input_tensor):\n",
        "        \"\"\"Upsample the input tensor by inserting r-1 zeros between each element.\"\"\"\n",
        "        input_shape = tf.shape(input_tensor)\n",
        "        expanded_input = tf.expand_dims(input_tensor, axis=-1)  # Add an extra dimension\n",
        "\n",
        "        # Create a tensor of zeros with the same shape as input, but r times the last dimension\n",
        "        zero_padding = tf.zeros_like(expanded_input)\n",
        "        zero_padding = tf.tile(zero_padding, [1, 1, self.upsample_factor-1])  # Repeat the zeros r-1 times\n",
        "\n",
        "        # Concatenate input and zero_padding along the last dimension\n",
        "        upsampled = tf.concat([expanded_input, zero_padding], axis=-1)\n",
        "\n",
        "        # Reshape to flatten the added dimension\n",
        "        new_shape = [input_shape[0], input_shape[1] * self.upsample_factor]\n",
        "        upsampled_flat = tf.reshape(upsampled, new_shape)\n",
        "        return upsampled_flat\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"Forward pass for the layer, converting real to complex and applying RRC filter.\"\"\"\n",
        "        batch_size = tf.shape(inputs)[0]  # Batch size\n",
        "        inner_dim = tf.shape(inputs)[1]   # Inner dimension size\n",
        "        print( inner_dim, batch_size)\n",
        "        # Ensure that the inner dimension is even\n",
        "        # assert inner_dim % 2 == 0, \"Inner dimension must be even for real and imaginary pairs.\"\n",
        "\n",
        "        # Reshape the input tensor to separate real and imaginary parts\n",
        "        reshaped_tensor = tf.reshape(inputs, [batch_size, inner_dim // 2, 2])\n",
        "\n",
        "        # Extract real and imaginary parts\n",
        "        real_part = reshaped_tensor[:, :, 0]\n",
        "        imag_part = reshaped_tensor[:, :, 1]\n",
        "\n",
        "        # Upsample real and imaginary parts\n",
        "        real_part = self.upsample(real_part)\n",
        "        imag_part = self.upsample(imag_part)\n",
        "\n",
        "        # Convert tensors to NumPy arrays for filtering\n",
        "        real_part_np = real_part.numpy()\n",
        "        imag_part_np = imag_part.numpy()\n",
        "\n",
        "        # Apply the RRC filter using scipy's convolve\n",
        "        real_filtered_np = np.array([convolve(real_part_np[i], self.rrc_taps, mode='full') for i in range(real_part_np.shape[0])])\n",
        "        imag_filtered_np = np.array([convolve(imag_part_np[i], self.rrc_taps, mode='full') for i in range(imag_part_np.shape[0])])\n",
        "\n",
        "        # Convert the filtered signals back to TensorFlow tensors\n",
        "        real_filtered = tf.convert_to_tensor(real_filtered_np, dtype=tf.float32)\n",
        "        imag_filtered = tf.convert_to_tensor(imag_filtered_np, dtype=tf.float32)\n",
        "\n",
        "        # Interleave real and imaginary parts\n",
        "        interleaved = tf.stack([real_filtered, imag_filtered], axis=-1)  # Shape: (batch_size, time_length, 2)\n",
        "        interleaved = tf.reshape(interleaved, [batch_size, -1])  # Flatten to (batch_size, time_length*2)\n",
        "\n",
        "        return interleaved\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUBOznL2kLi8"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Initialize the RRC filter layer\n",
        "normalized_rrc_layer = NormalizedRRCFilterLayer_v2()\n",
        "enc = before_channel(train_dataset)\n",
        "# Apply the layer to the test input\n",
        "output = normalized_rrc_layer(enc)\n",
        "\n",
        "# Check the output shape and print it\n",
        "print(\"Output shape:\", output.shape)\n",
        "# Plotting the first column of the filtered signal for visualization\n",
        "plt.figure(figsize=(6, 2))\n",
        "plt.plot(enc[10,:])\n",
        "plt.title(\"Input Signal\")\n",
        "plt.xlabel(\"Samples\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "# Plotting the first column of the filtered signal for visualization\n",
        "plt.figure(figsize=(6, 2))\n",
        "plt.plot(output[10,:])\n",
        "plt.title(\"Filtered Signal (Column 1) - Full Convolution with RRC Filter\")\n",
        "plt.xlabel(\"Samples\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awqTKieORLvu"
      },
      "source": [
        "# offset estimation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePgBiBPkUGH-"
      },
      "outputs": [],
      "source": [
        "# Initializing parameters\n",
        "k = 8\n",
        "NUM_CHANNEL_USES = 4\n",
        "\n",
        "sampling_factor = 4 # r\n",
        "N_msg = 2*NUM_CHANNEL_USES*sampling_factor  # complex numbers converted into real\n",
        "l = 6\n",
        "N_seq =(2*l-1)*N_msg\n",
        "frame_size = 100*N_msg\n",
        "q = 1   # strides = 1 (considered all values as real -> moving half of a complex number)\n",
        "\n",
        "block_size = 32    # num of messages for frames we use, out of this, we use 1/4 as pilots and 3/4 as messages\n",
        "n_blocks_train = 10**4  ################\n",
        "n_blocks_val = 10**3\n",
        "\n",
        "n_train = block_size * n_blocks_train\n",
        "n_val   = block_size * n_blocks_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fskqoITUJc1"
      },
      "outputs": [],
      "source": [
        "def create_2d_array(arr, window_size, stride):\n",
        "    num_windows = (len(arr) - window_size) // stride + 1\n",
        "    shape = (num_windows, window_size)\n",
        "    strides = (arr.strides[0] * stride, arr.strides[0])\n",
        "    return np.lib.stride_tricks.as_strided(arr, shape=shape, strides=strides)\n",
        "\n",
        "arr = np.array([1,2,3,4,5,6,7,8,9,10])\n",
        "window_size = 7\n",
        "stride = 1\n",
        "\n",
        "result = create_2d_array(arr, window_size, stride)\n",
        "print(result)\n",
        "\n",
        "def create_2d_array_tf(arr, window_size, stride):\n",
        "    num_windows = (arr.shape[0] - window_size) // stride + 1\n",
        "    windows = []\n",
        "    for i in range(num_windows):\n",
        "        window = arr[i * stride:i * stride + window_size]\n",
        "        windows.append(window)\n",
        "    return tf.stack(windows)\n",
        "\n",
        "arr = tf.constant([1,2,3,4,5,6,7,8,9,10], dtype=tf.int32)\n",
        "window_size = 7\n",
        "stride = 1\n",
        "\n",
        "result = create_2d_array_tf(arr, window_size, stride)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYVK7gU7L0lK"
      },
      "source": [
        "## possible ways of training\n",
        "end to end training for OE.\n",
        "\n",
        "training OE in isolated fashion:input will be output of transmitter of autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1EISZr4L_Wm"
      },
      "outputs": [],
      "source": [
        "out = autoencoder_model[0].get_layer('stc').output\n",
        "oe = OE_model.train()\n",
        "print(out.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pap1uh3kSaIm"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras import metrics\n",
        "\n",
        "class OffsetEstimator(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.OE = Sequential([\n",
        "            Input(shape=(N_seq,), name='OE_input'),\n",
        "            Dense(256, activation='relu', name='dense_layer_1'),\n",
        "            Dense(256, activation='relu', name='dense_layer_2'),\n",
        "            Dense(256, activation='relu', name='dense_layer_3'),\n",
        "            Dense(N_msg, activation='softmax', name='dense_layer_4'),\n",
        "        ])\n",
        "        self.loss_tracker = metrics.Mean(name=\"loss\")\n",
        "        self.mae_metric = metrics.MeanAbsoluteError(name=\"mae\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        tau_vec_matrix = self.OE(inputs, training=False)\n",
        "        print(tau_vec_matrix)\n",
        "        tau_sum_vec = tf.reduce_sum(circular_shift(tau_vec_matrix), axis=0) / tf.cast(tf.shape(tau_vec_matrix)[0], tf.float32)\n",
        "        print(tau_sum_vec)\n",
        "        r = tf.math.argmax(tau_sum_vec, axis=0)\n",
        "        i = tf.cast(r, tf.float32) - 1 - N_msg*(tf.math.floor((tf.cast(r, tf.float32) - 1) / (N_msg / 2)))\n",
        "        return i\n",
        "\n",
        "    def compile(self, optimizer):\n",
        "        super().compile()\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "    def train_step(self, data):\n",
        "        inputs, frame_offset = data\n",
        "        with tf.GradientTape() as tape:\n",
        "            tau_vec_matrix = self.OE(inputs, training=True)\n",
        "            tau_sum_vec = tf.reduce_sum(circular_shift(tau_vec_matrix), axis=0) / tf.cast(tf.shape(tau_vec_matrix)[0], tf.float32)\n",
        "            r = tf.math.argmax(tau_sum_vec, axis=0)\n",
        "            i = tf.cast(r, tf.float32) - 1 - tf.math.floor((tf.cast(r, tf.float32) - 1) / (N_msg / 2))\n",
        "            # Convert frame_offset to float32 for consistency\n",
        "            frame_offset = tf.cast(frame_offset, tf.float32)\n",
        "            loss = tf.keras.losses.mean_squared_error(frame_offset, i)\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        self.mae_metric.update_state(i, frame_offset)\n",
        "        return {\"loss\": self.loss_tracker.result(), \"mae\": self.mae_metric.result()}\n",
        "\n",
        "    # def test_step(self, data):\n",
        "    #     inputs, frame_offset = data\n",
        "    #     tau_vec_matrix = self.OE(inputs, training=False)\n",
        "    #     tau_sum_vec = tf.reduce_sum(circular_shift(tau_vec_matrix), axis=0) / tf.cast(tf.shape(tau_vec_matrix)[0], tf.float32)\n",
        "    #     r = tf.math.argmax(tau_sum_vec, axis=0)\n",
        "    #     i = tf.cast(r, tf.float32) - 1 - tf.math.floor((tf.cast(r, tf.float32) - 1) / (N_msg / 2))\n",
        "    #     frame_offset = tf.cast(frame_offset, tf.float32)\n",
        "    #     loss = tf.keras.losses.mean_squared_error(frame_offset, i)\n",
        "    #     self.loss_tracker.update_state(loss)\n",
        "    #     self.mae_metric.update_state(i, frame_offset)\n",
        "    #     return {\"loss\": self.loss_tracker.result(), \"mae\": self.mae_metric.result()}\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.loss_tracker, self.mae_metric]\n",
        "\n",
        "# Define the circular_shift function\n",
        "def circular_shift(tensor):\n",
        "    shape = tensor.shape\n",
        "    rows = shape[0]\n",
        "    shifted_tensor = tf.stack([tf.roll(tensor[i, :], shift=i, axis=0) for i in range(rows)])\n",
        "    return shifted_tensor\n",
        "\n",
        "# Initialize the OffsetEstimator model\n",
        "OE_model = OffsetEstimator()\n",
        "OE_model.compile(optimizer=tf.keras.optimizers.Adam())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "6v0fprAabUXe"
      },
      "outputs": [],
      "source": [
        "def get_frame_offset(frame):\n",
        "    frame = np.array(frame, dtype=np.float32)  # Ensure data type consistency\n",
        "    seq_matrix = create_2d_array(frame, N_seq, q)\n",
        "    seq_matrix_tf = tf.constant(seq_matrix, dtype=tf.float32)\n",
        "    i_b = OE_model(seq_matrix_tf)  # Frame offset index value\n",
        "    return i_b\n",
        "\n",
        "# Example frame (replace with actual data)\n",
        "frame = np.random.rand(frame_size).astype(np.float32)  # Ensure data type consistency\n",
        "\n",
        "# Get the frame offset\n",
        "i_b = get_frame_offset(frame)\n",
        "\n",
        "print(\"Estimated Frame Offset:\", i_b.numpy())  # Convert tensor to numpy for printing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0z_eeHuOUtRJ"
      },
      "outputs": [],
      "source": [
        "class FE_PE(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Feature Extractor: Takes an input of size (N_msg * N_seq)\n",
        "        self.feature_extractor = Sequential([\n",
        "            Input(shape=(N_msg * N_seq,), name='feature_extractor_input'),\n",
        "            Dense(8, activation='linear', name='feature_extract')\n",
        "        ])\n",
        "\n",
        "        # Phase Estimator: Takes the same input, but could eventually use the extracted features\n",
        "        self.phase_estimator = Sequential([\n",
        "            Input(shape=(N_msg * N_seq,), name='phase_estimator_input'),\n",
        "            Dense(2, activation='linear', name='phase_estimator')\n",
        "        ])\n",
        "\n",
        "        # Define loss tracker and MAE for metrics\n",
        "        self.loss_tracker = metrics.Mean(name=\"loss\")\n",
        "        self.mae_metric = metrics.MeanAbsoluteError(name=\"mae\")\n",
        "    def complex_to_real_tensor(inp_tensor):\n",
        "        # Debugging: Print the input shape\n",
        "        print(f\"Input tensor shape: {inp_tensor.shape}\")\n",
        "        # Ensure that the input tensor is of shape [2, n]\n",
        "        assert inp_tensor.shape[0] == 2, \"The first dimension must be 2 (real and imaginary parts).\"\n",
        "\n",
        "        # Get real part (first row) and imaginary part (second row)\n",
        "        real_part = inp_tensor[0, :]  # Shape: [n]\n",
        "        imag_part = inp_tensor[1, :]  # Shape: [n]\n",
        "\n",
        "        # Stack real and imaginary parts together and interleave them\n",
        "        combined = tf.stack([real_part, imag_part], axis=-1)  # Shape: [n, 2]\n",
        "\n",
        "        # Reshape to interleave the real and imaginary parts into one dimension\n",
        "        interleaved = tf.reshape(combined, [-1])  # Shape: [2*n], interleaving real and imaginary\n",
        "\n",
        "        return interleaved\n",
        "    def call(self, inputs):\n",
        "        # Forward pass: First extract features, then estimate phase\n",
        "        # inputs = complex_to_real_tensor(inputs)\n",
        "        features = self.feature_extractor(inputs)\n",
        "        # features = real_to_complex_tensor(features)\n",
        "        phase_estimation = self.phase_estimator(inputs)\n",
        "        # phase_estimation = real_to_complex_tensor(phase_estimation)\n",
        "        return features, phase_estimation\n",
        "\n",
        "    def compile(self, optimizer):\n",
        "        super().compile()\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # Custom training loop: inputs, true phase values\n",
        "        inputs, true_phase = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass\n",
        "            features, predicted_phase = self(inputs)\n",
        "\n",
        "            # Calculate loss (using Mean Squared Error for phase estimation)\n",
        "            true_phase = tf.cast(true_phase, tf.float32)\n",
        "            loss = tf.keras.losses.mean_squared_error(true_phase, predicted_phase)\n",
        "\n",
        "        # Compute gradients and apply them\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "\n",
        "        # Update loss and MAE metrics\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        self.mae_metric.update_state(predicted_phase, true_phase)\n",
        "\n",
        "        return {\"loss\": self.loss_tracker.result(), \"mae\": self.mae_metric.result()}\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        # Return the metrics for tracking\n",
        "        return [self.loss_tracker, self.mae_metric]\n",
        "\n",
        "# Initialize model\n",
        "FE_PE_model = FE_PE()\n",
        "FE_PE_model.compile(optimizer=tf.keras.optimizers.Adam())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyyTaRAzFEr3"
      },
      "outputs": [],
      "source": [
        "autoencoder_model[0].summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "VogvmitwGQWU"
      },
      "outputs": [],
      "source": [
        "input_layer = autoencoder_model[0].get_layer('Input')\n",
        "before_channel = Model(inputs=input_layer.input,  # Use KerasTensor as input\n",
        "                       outputs=autoencoder_model[0].get_layer('stc').output)\n",
        "enc = before_channel(test_dataset)\n",
        "print(enc.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WlyGvxcObA2"
      },
      "source": [
        "# phase and feature extractor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mldrE9BHOg_7"
      },
      "outputs": [],
      "source": [
        "class SD(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self,l=6,n=4,r=4,**kwargs):\n",
        "       super(SD, self).__init__(**kwargs)\n",
        "       self.l = l\n",
        "       self.n = n\n",
        "       self.r = r\n",
        "       with tf.name_scope(\" fe\"):\n",
        "          self.fe = Sequential([\n",
        "              Dense(256, activation='relu', name='initial'),\n",
        "              Dense(8, activation='linear', name='feature extractor')\n",
        "          ]\n",
        "        )\n",
        "       with tf.name_scope(\" pe\"):\n",
        "          self.pe = Sequential([\n",
        "              Dense(256, activation='relu', name='initial'),\n",
        "              Dense(2, activation='linear', name='phase_estimator')\n",
        "          ]\n",
        "        )\n",
        "          return pe\n",
        "\n",
        "    # def fe(self):\n",
        "    #   fe = Sequential([\n",
        "    #       Dense(256, activation='relu', name='initial'),\n",
        "    #       Dense(8, activation='linear', name='feature extractor')\n",
        "    #   ]\n",
        "    #   )\n",
        "\n",
        "    #   # fe.compile(optimizer=Adam(learning_rate=1e-2), loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "    #   return fe\n",
        "\n",
        "    # def pe(self):\n",
        "    #   pe = Sequential([\n",
        "    #       Dense(256, activation='relu', name='initial'),\n",
        "    #       Dense(2, activation='linear', name='phase_estimator')\n",
        "    #   ]\n",
        "    #   )\n",
        "\n",
        "      # pe.compile(optimizer=Adam(learning_rate=1e-2), loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "\n",
        "    def mini_slicer(self, inputs):\n",
        "      in_dim = tf.shape(inputs)[1]\n",
        "      N_msg = self.r*self.n\n",
        "      l1 = 1+ (self.l-1)*N_msg - self.r\n",
        "      l2 = self.l*N_msg+self.r\n",
        "      out_1= inputs[:,l1-1:l2]\n",
        "      out_2 = inputs[:,in_dim//2+l1-1:in_dim//2+l2]\n",
        "      output = tf.concat([out_1,out_2], axis = 1)\n",
        "      print('mini slice output shape', output.shape)\n",
        "      return output\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Get the input dimension (before slicing)\n",
        "        in_dim = inputs.shape[1]\n",
        "\n",
        "        # Create feature extractor and phase estimator models\n",
        "        with tf.name_scope(\"fe\"):\n",
        "            feature_extract_model = self.fe()\n",
        "        with tf.name_scope(\"pe\"):\n",
        "            phase_estimate_model = self.pe()\n",
        "\n",
        "        # Process the inputs using mini_slicer (this changes the shape of inputs)\n",
        "        inputs = self.mini_slicer(inputs)\n",
        "\n",
        "        # Update real and imag slices based on new input shape (after mini_slicer)\n",
        "        half_dim = tf.shape(inputs)[1] // 2  # Get new half dimension after slicing\n",
        "        real = inputs[:, :half_dim]  # First half of sliced inputs as real part (batch_size, 48)\n",
        "        imag = inputs[:, half_dim:]  # Second half as imaginary part (batch_size, 48)\n",
        "\n",
        "        # Pass the sliced inputs to the phase estimator model to get h\n",
        "        h = phase_estimate_model(inputs)  # h has shape (batch_size, 2)\n",
        "        h_real = h[:, 0]  # Extract real part of h\n",
        "        h_imag = h[:, 1]  # Extract imaginary part of h\n",
        "\n",
        "        h_real = tf.expand_dims(h_real, axis=1)\n",
        "        h_imag = tf.expand_dims(h_imag, axis=1)\n",
        "        # Perform element-wise multiplication\n",
        "        h_real_ex = tf.tile(h_real, [1, half_dim])\n",
        "        h_imag_ex = tf.tile(h_imag, [1, half_dim])\n",
        "        real_mul = real * h_real_ex   #multiply same value of real part to every component of the input\n",
        "        imag_mul = imag * h_imag_ex\n",
        "        print(h_real_ex[0])\n",
        "        # Apply the feature extractor model to real_mul (as an example)\n",
        "        feature_extract_output = feature_extract_model(inputs)\n",
        "\n",
        "        output = tf.concat([real_mul, imag_mul, feature_extract_output], axis=1)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFG9mTC-_Nn1"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "class SD(tf.keras.layers.Layer):\n",
        "    def __init__(self, l=6, n=4, r=4, **kwargs):\n",
        "        super(SD, self).__init__(**kwargs)\n",
        "        self.l = l\n",
        "        self.n = n\n",
        "        self.r = r\n",
        "\n",
        "        with tf.name_scope(\"fe\"):\n",
        "            self.fe = Sequential([\n",
        "                Dense(256, activation='relu', name='initial'),\n",
        "                Dense(8, activation='linear', name='feature_extractor')\n",
        "            ])\n",
        "\n",
        "        with tf.name_scope(\"pe\"):\n",
        "            self.pe = Sequential([\n",
        "                Dense(256, activation='relu', name='initial'),\n",
        "                Dense(2, activation='linear', name='phase_estimator')\n",
        "            ])\n",
        "\n",
        "    def mini_slicer(self, inputs):\n",
        "        in_dim = tf.shape(inputs)[1]\n",
        "        N_msg = self.r * self.n\n",
        "        l1 = 1 + (self.l - 1) * N_msg - self.r\n",
        "        l2 = self.l * N_msg + self.r\n",
        "        out_1 = inputs[:, l1-1:l2]\n",
        "        out_2 = inputs[:, in_dim // 2 + l1-1:in_dim // 2 + l2]\n",
        "        output = tf.concat([out_1, out_2], axis=1)\n",
        "        print('mini slice output shape', output.shape)\n",
        "        return output\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Get the input dimension (before slicing)\n",
        "        in_dim = inputs.shape[1]\n",
        "\n",
        "        # Process the inputs using mini_slicer (this changes the shape of inputs)\n",
        "        inputs = self.mini_slicer(inputs)\n",
        "\n",
        "        # Update real and imag slices based on new input shape (after mini_slicer)\n",
        "        half_dim = tf.shape(inputs)[1] // 2  # Get new half dimension after slicing\n",
        "        real = inputs[:, :half_dim]  # First half of sliced inputs as real part\n",
        "        imag = inputs[:, half_dim:]  # Second half as imaginary part\n",
        "\n",
        "        # Pass the sliced inputs to the phase estimator model to get h\n",
        "        h = self.pe(inputs)  # h has shape (batch_size, 2)\n",
        "        h_real = h[:, 0]  # Extract real part of h\n",
        "        h_imag = h[:, 1]  # Extract imaginary part of h\n",
        "\n",
        "        h_real = tf.expand_dims(h_real, axis=1)\n",
        "        h_imag = tf.expand_dims(h_imag, axis=1)\n",
        "\n",
        "        # Perform element-wise multiplication\n",
        "        h_real_ex = tf.tile(h_real, [1, half_dim])\n",
        "        h_imag_ex = tf.tile(h_imag, [1, half_dim])\n",
        "        real_mul = real * h_real_ex  # Multiply same value of real part to every component of the input\n",
        "        imag_mul = imag * h_imag_ex\n",
        "\n",
        "        # Apply the feature extractor model to real_mul (as an example)\n",
        "        feature_extract_output = self.fe(inputs)\n",
        "\n",
        "        # Concatenate the outputs\n",
        "        output = tf.concat([real_mul, imag_mul, feature_extract_output], axis=1)\n",
        "\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owqWXtdOrRni"
      },
      "outputs": [],
      "source": [
        "small = Model(inputs = autoencoder_model[0].get_layer('Input').input, outputs = autoencoder_model[0].get_layer('stc').output)\n",
        "enc = small(test_dataset[:13*12])\n",
        "out_sd = SD()\n",
        "out = out_sd(enc)\n",
        "print(out.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFKFE4MqdMor"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "class SD(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, l=6, n=4, r=4, **kwargs):\n",
        "        super(SD, self).__init__(**kwargs)  # Corrected class name\n",
        "        self.l = l\n",
        "        self.n = n\n",
        "        self.r = r\n",
        "        self.feature_extractor = self.fe()\n",
        "        self.phase_estimator = self.pe()\n",
        "\n",
        "    def fe(self):\n",
        "        fe = Sequential(\n",
        "            [\n",
        "                Dense(256, activation='relu', name='initial'),\n",
        "                Dense(8, activation='linear', name='feature_extractor')\n",
        "            ]\n",
        "        )\n",
        "        return fe\n",
        "\n",
        "    def pe(self):\n",
        "        pe = Sequential(\n",
        "            [\n",
        "                Dense(256, activation='relu', name='initial'),\n",
        "                Dense(2, activation='linear', name='phase_estimator')\n",
        "            ]\n",
        "        )\n",
        "        return pe\n",
        "\n",
        "    def mini_slicer(self, inputs):\n",
        "        in_dim = tf.shape(inputs)[1]\n",
        "        N_msg = self.r * self.n\n",
        "        l1 = 1 + (self.l - 1) * N_msg - self.r\n",
        "        l2 = self.l * N_msg + self.r\n",
        "        out_1 = inputs[:, l1 - 1:l2]\n",
        "        out_2 = inputs[:, in_dim // 2 + l1 - 1:in_dim // 2 + l2]\n",
        "        output = tf.concat([out_1, out_2], axis=1)\n",
        "        print('mini slice output shape', output.shape)\n",
        "        return output\n",
        "\n",
        "    def call(self, inputs):\n",
        "        in_dim = inputs.shape[1]\n",
        "\n",
        "        # Call feature extractor and phase estimator on inputs\n",
        "        feature_extract = self.feature_extractor(inputs)  # Corrected to use the model\n",
        "        phase_estimate = self.phase_estimator(inputs)      # Corrected to use the model\n",
        "\n",
        "        h = self.mini_slicer(inputs)\n",
        "        real = inputs[:, :in_dim // 2]\n",
        "        imag = inputs[:, in_dim // 2:]\n",
        "\n",
        "        # Ensure that h is of appropriate shape\n",
        "        real_mul = real * h[:,0]   # Assuming h has 2 columns\n",
        "        imag_mul = imag * h[:1]   # Assuming h has 2 columns\n",
        "\n",
        "        output = tf.concat([real_mul, imag_mul, feature_extract], axis=1)\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfZS_DOym-H8"
      },
      "source": [
        "\n",
        "#CNN based Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Tly0ZUXmNOG"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import datetime\n",
        "from tensorflow.keras.layers import Layer,Input,Conv1D, Dense, Flatten, Embedding, Reshape, Softmax,LayerNormalization, MultiHeadAttention, Add, Dropout,Normalization\n",
        "from tensorflow.keras import Sequential\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import Callback, TensorBoard\n",
        "from IPython.display import clear_output\n",
        "from tensorflow.keras.layers import Dense, LSTM, GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "cZ0wxW4LnXaN",
        "outputId": "8a30c008-299a-416e-94b7-4307134cae8e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - accuracy: 1.0000 - loss: 0.0636 - val_accuracy: 1.0000 - val_loss: 0.8671\n",
            "\u001b[1m96/96\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.8516\n",
            "Test Loss: 0.8542, Test Accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# @title Default title text\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "\n",
        "# Dataset Parameters\n",
        "N = 4  # Number of channel uses\n",
        "K = 8  # Block size (log2 of the number of messages)\n",
        "M = 2**K  # Number of possible messages (2^K)\n",
        "batch_size = 6400\n",
        "output = 2**K\n",
        "Eb_No = 15  # Signal-to-Noise ratio in dB\n",
        "\n",
        "# Create Dataset with Integer Labels\n",
        "train_dataset = np.tile(np.arange(M), batch_size // M)\n",
        "test_dataset = np.tile(np.arange(M), batch_size  //(2*M))\n",
        "\n",
        "# Shuffle the dataset\n",
        "np.random.shuffle(train_dataset)\n",
        "np.random.shuffle(test_dataset)\n",
        "\n",
        "# Define split ratios\n",
        "train_ratio = 0.85  # 85% for training\n",
        "val_ratio = 0.15    # 15% for validation\n",
        "\n",
        "# Calculate the number of samples\n",
        "num_train_samples = int(len(train_dataset) * train_ratio)\n",
        "num_val_samples = len(train_dataset) - num_train_samples\n",
        "\n",
        "# Split the datasets\n",
        "train_set = train_dataset[:num_train_samples]\n",
        "val_set = train_dataset[num_train_samples:]\n",
        "\n",
        "# Reshape the datasets if needed\n",
        "train_set = train_set.reshape((-1, 1))\n",
        "val_set = val_set.reshape((-1, 1))\n",
        "test_dataset = test_dataset.reshape((-1, 1))\n",
        "\n",
        "# Print dataset sizes\n",
        "print(f\"Number of train samples: {len(train_set)}\")\n",
        "print(f\"Number of validation samples: {len(val_set)}\")\n",
        "print(f\"Number of test samples: {len(test_dataset)}\")\n",
        "\n",
        "\n",
        "\n",
        "# Custom Noise Layer\n",
        "class CustomNoise(tf.keras.layers.Layer):\n",
        "    def __init__(self, mean=0.0, stddev=10**(-1.0*Eb_No), **kwargs):\n",
        "        super(CustomNoise, self).__init__(**kwargs)\n",
        "        self.mean = mean\n",
        "        self.stddev = stddev\n",
        "\n",
        "    def call(self, inputs):\n",
        "        noise = tf.random.normal(shape=tf.shape(inputs), mean=self.mean, stddev=self.stddev)\n",
        "        return inputs + noise\n",
        "\n",
        "# class Normalization(tf.keras.layers.Layer):\n",
        "#     def __init__(self, **kwargs):\n",
        "#         super(Normalization, self).__init__(**kwargs)\n",
        "\n",
        "#     def call(self, input):\n",
        "#         out = tf.nn.l2_normalize(tf.reshape(input, (-1, 2)), axis=-1, epsilon=1e-6)\n",
        "#         out = tf.reshape(out, (-1, 2*N))\n",
        "#         print(\"normalization layer output shape:\" ,str(out.shape))\n",
        "#         return out\n",
        "#     def get_config(self):\n",
        "#         config = super(Normalization, self).get_config()\n",
        "#         return config\n",
        "\n",
        "\n",
        "class Normalization(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(Normalization, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, input):\n",
        "        # Perform L2 normalization on the last dimension while keeping the overall shape\n",
        "        print(input)\n",
        "        out = tf.nn.l2_normalize(input, axis=-1, epsilon=1e-6)\n",
        "        # print(\"Normalization layer output shape:\", out.shape)\n",
        "        return out\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(Normalization, self).get_config()\n",
        "        return config\n",
        "\n",
        "class PowerConstraintLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(PowerConstraintLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Split real and imaginary parts\n",
        "        real_parts = inputs[:,:, :4]  # First 4 elements\n",
        "        imag_parts = inputs[:,:, 4:]  # Last 4 elements\n",
        "\n",
        "        # Compute magnitudes\n",
        "        magnitudes = tf.sqrt(tf.square(real_parts) + tf.square(imag_parts))\n",
        "\n",
        "        # Find the maximum magnitude\n",
        "        #max_magnitude = tf.reduce_max(magnitudes, axis=1, keepdims=True)\n",
        "\n",
        "        # Scale inputs if max magnitude > 1\n",
        "        # Replace zero values with one\n",
        "        scale_factor = tf.where(tf.less_equal(magnitudes, 1), tf.ones_like(magnitudes), magnitudes)\n",
        "        scale_factor = tf.concat([scale_factor, scale_factor],axis=-1)\n",
        "        scaled_inputs = inputs / scale_factor\n",
        "\n",
        "        return scaled_inputs\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(PowerConstraintLayer, self).get_config()\n",
        "        return config\n",
        "\n",
        "\n",
        "class SD(tf.keras.layers.Layer):\n",
        "    def __init__(self, l=6, n=4, r=4, **kwargs):\n",
        "        super(SD, self).__init__(**kwargs)\n",
        "        self.l = l\n",
        "        self.n = n\n",
        "        self.r = r\n",
        "\n",
        "        with tf.name_scope(\"fe\"):\n",
        "            self.fe = Sequential([\n",
        "                Dense(64, activation='relu', name='initial'),\n",
        "                Dense(8, activation='linear', name='feature_extractor')\n",
        "            ])\n",
        "\n",
        "        with tf.name_scope(\"pe\"):\n",
        "            self.pe = Sequential([\n",
        "                Dense(64, activation='relu', name='initial'),\n",
        "                Dense(2, activation='linear', name='phase_estimator')\n",
        "            ])\n",
        "\n",
        "        with tf.name_scope(\"oe\"):\n",
        "            self.oe = Sequential([\n",
        "                Dense(64, activation='relu', name='initial'),\n",
        "                Dense(64, activation='relu', name='oe_dense1'),\n",
        "                Dense(32, activation='relu', name='oe_dense2'),\n",
        "                Dense(1, activation='linear', name='offset_estimator'),\n",
        "\n",
        "            ])\n",
        "\n",
        "    def mini_slicer(self, inputs):\n",
        "        in_dim = tf.shape(inputs)[1]\n",
        "        N_msg = self.r * self.n\n",
        "        l1 = 1 + (self.l - 1) * N_msg - self.r\n",
        "        l2 = self.l * N_msg + self.r\n",
        "        out_1 = inputs[:, l1-1:l2]\n",
        "        out_2 = inputs[:, in_dim // 2 + l1-1:in_dim // 2 + l2]\n",
        "        output = tf.concat([out_1, out_2], axis=1)\n",
        "        print('mini slice output shape', output.shape)\n",
        "        return output\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Get the input dimension (before slicing)\n",
        "        in_dim = inputs.shape[1]\n",
        "\n",
        "        # Process the inputs using mini_slicer (this changes the shape of inputs)\n",
        "        # inputs = self.mini_slicer(inputs)\n",
        "\n",
        "        # Update real and imag slices based on new input shape (after mini_slicer)\n",
        "        half_dim = tf.shape(inputs)[1] // 2  # Get new half dimension after slicing\n",
        "        real = inputs[:, :half_dim]  # First half of sliced inputs as real part\n",
        "        imag = inputs[:, half_dim:]  # Second half as imaginary part\n",
        "\n",
        "        # Pass the sliced inputs to the phase estimator model to get h\n",
        "        h = self.pe(inputs)  # h has shape (batch_size, 2)\n",
        "        h_real = h[:, 0]  # Extract real part of h\n",
        "        h_imag = h[:, 1]  # Extract imaginary part of h\n",
        "\n",
        "        h_real = tf.expand_dims(h_real, axis=1)\n",
        "        h_imag = tf.expand_dims(h_imag, axis=1)\n",
        "\n",
        "        # # Perform element-wise multiplication\n",
        "        # h_real_ex = tf.tile(h_real, [1, half_dim])\n",
        "        # h_imag_ex = tf.tile(h_imag, [1, half_dim])\n",
        "        # real_mul = real * h_real_ex -imag*h_imag_ex # Multiply same value of real part to every component of the input\n",
        "        # imag_mul = real * h_imag_ex + imag*h_real_ex # Multiply same value of imag part to every component of the input\n",
        "\n",
        "        # Apply the feature extractor model to real_mul (as an example)\n",
        "        feature_extract_output = self.fe(inputs)\n",
        "        offset_estimator_output = self.oe(inputs)\n",
        "\n",
        "        # Concatenate the outputs\n",
        "        output = tf.concat([real, imag,offset_estimator_output,h_real,h_imag, feature_extract_output], axis=1)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class SD_RNN(tf.keras.layers.Layer):\n",
        "    def __init__(self, l=6, n=4, r=4, units=16, **kwargs):\n",
        "        super(SD_RNN, self).__init__(**kwargs)\n",
        "        self.l = l\n",
        "        self.n = n\n",
        "        self.r = r\n",
        "        self.units = units  # RNN units\n",
        "\n",
        "        with tf.name_scope(\"fe\"):\n",
        "            # Use LSTM or GRU for feature extractor\n",
        "            self.fe = Sequential([\n",
        "                Reshape((1, 92)),\n",
        "                LSTM(self.units, return_sequences=True, name='feature_extractor_lstm'),\n",
        "                Flatten(),# or use GRU\n",
        "                Dense(8, activation='linear', name='feature_extractor_output')\n",
        "            ])\n",
        "\n",
        "        with tf.name_scope(\"pe\"):\n",
        "            # Use LSTM or GRU for phase estimator\n",
        "            self.pe = Sequential([\n",
        "                Reshape((1, 92)),\n",
        "                LSTM(self.units, return_sequences=True, name='phase_estimator_lstm'),\n",
        "                Flatten(),# or use GRU\n",
        "                Dense(2, activation='linear', name='phase_estimator_output')\n",
        "            ])\n",
        "\n",
        "        with tf.name_scope(\"oe\"):\n",
        "            self.oe = Sequential([\n",
        "                 Reshape((1, 92)),\n",
        "                LSTM(self.units, return_sequences=True, name='offset_estimator_lstm'),\n",
        "                LSTM(self.units, return_sequences=True, name='offset_estimator_lstm1'),\n",
        "                LSTM(self.units//2, return_sequences=True, name='offset_estimator_lstm2'),\n",
        "                Flatten(),\n",
        "                Dense(1, activation='linear', name='offset_estimator'),\n",
        "\n",
        "            ])\n",
        "\n",
        "\n",
        "\n",
        "    def mini_slicer(self, inputs):\n",
        "        in_dim = tf.shape(inputs)[1]\n",
        "        N_msg = self.r * self.n\n",
        "        l1 = 1 + (self.l - 1) * N_msg - self.r\n",
        "        l2 = self.l * N_msg + self.r\n",
        "        out_1 = inputs[:, l1-1:l2]\n",
        "        out_2 = inputs[:, in_dim // 2 + l1-1:in_dim // 2 + l2]\n",
        "        output = tf.concat([out_1, out_2], axis=1)\n",
        "        print('mini slice output shape', output.shape)\n",
        "        return output\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Get the input dimension (before slicing)\n",
        "        in_dim = inputs.shape[1]\n",
        "\n",
        "        # Process the inputs using mini_slicer (this changes the shape of inputs)\n",
        "        # inputs = self.mini_slicer(inputs)\n",
        "\n",
        "        # Update real and imag slices based on new input shape (after mini_slicer)\n",
        "        half_dim = tf.shape(inputs)[1] // 2  # Get new half dimension after slicing\n",
        "        real = inputs[:, :half_dim]  # First half of sliced inputs as real part\n",
        "        imag = inputs[:, half_dim:]  # Second half as imaginary part\n",
        "\n",
        "        # Pass the sliced inputs to the phase estimator model to get h\n",
        "        h = self.pe(inputs)  # h has shape (batch_size, 2)\n",
        "        h_real = h[:, 0]  # Extract real part of h\n",
        "        h_imag = h[:, 1]  # Extract imaginary part of h\n",
        "\n",
        "        h_real = tf.expand_dims(h_real, axis=1)\n",
        "        h_imag = tf.expand_dims(h_imag, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "        # # Perform element-wise multiplication\n",
        "        # h_real_ex = tf.tile(h_real, [1, half_dim])\n",
        "        # h_imag_ex = tf.tile(h_imag, [1, half_dim])\n",
        "        # real_mul = real * h_real_ex -imag*h_imag_ex # Multiply same value of real part to every component of the input\n",
        "        # imag_mul = real * h_imag_ex + imag*h_real_ex # Multiply same value of imag part to every component of the input\n",
        "\n",
        "        # Apply the feature extractor model to real_mul (as an example)\n",
        "        feature_extract_output = self.fe(inputs)\n",
        "        offset_estimator_output = self.oe(inputs)\n",
        "\n",
        "        # Concatenate the outputs\n",
        "        output = tf.concat([real, imag,offset_estimator_output,h_real,h_imag, feature_extract_output], axis=1)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "\n",
        "class StochasticChannelv3(tf.keras.layers.Layer):\n",
        "    def __init__(self, roll_off=0.35, num_taps=31, time_delay=0, r=4, ts=1, **kwargs):\n",
        "        super(StochasticChannelv3, self).__init__(**kwargs)\n",
        "        self.num_taps = num_taps\n",
        "        self.time_delay = time_delay\n",
        "        self.r = r  # Upsampling factor\n",
        "        self.roll_off = roll_off  # Roll-off factor\n",
        "        self.ts = ts  # Sampling period (default is 1)\n",
        "\n",
        "    def upsampling(self, inp):\n",
        "        com_reshape = tf.reshape(inp, [-1, 1])\n",
        "        padding = tf.constant([[0, 0], [0, self.r - 1]])  # Access self.r\n",
        "        upsampled = tf.pad(com_reshape, padding, mode=\"CONSTANT\")\n",
        "        upsampled = tf.reshape(upsampled, [-1])  # Flatten back to 1D\n",
        "        return upsampled\n",
        "\n",
        "    def upsample_iq(self, inp):\n",
        "        real = inp[:, 0]  # Real part\n",
        "        imag = inp[:, 1]  # Imaginary part\n",
        "\n",
        "        real_up = self.upsampling(real)\n",
        "        imag_up = self.upsampling(imag)\n",
        "\n",
        "        upsampled = tf.stack([real_up, imag_up], axis=1)\n",
        "        return upsampled\n",
        "\n",
        "    def rrc_filter(self):\n",
        "        t = np.linspace(-self.num_taps // 2, self.num_taps // 2 + 1, self.num_taps) - self.time_offset()\n",
        "        rrc = np.zeros_like(t)\n",
        "\n",
        "        for i in range(len(t)):\n",
        "            if t[i] == 0.0:\n",
        "                rrc[i] = (1.0 - self.roll_off + 4 * self.roll_off / np.pi) / self.ts\n",
        "            elif np.abs(t[i]) == self.ts / (4 * self.roll_off):\n",
        "                rrc[i] = (self.roll_off / (np.sqrt(2) * self.ts)) * \\\n",
        "                         ((1 + 2 / np.pi) * np.sin(np.pi / (4 * self.roll_off)) +\n",
        "                          (1 - 2 / np.pi) * np.cos(np.pi / (4 * self.roll_off)))\n",
        "            else:\n",
        "                rrc[i] = (np.sin(np.pi * (t[i] / self.ts) * (1 - self.roll_off)) +\n",
        "                          4 * self.roll_off * (t[i] / self.ts) * np.cos(np.pi * (t[i] / self.ts) * (1 + self.roll_off))) / \\\n",
        "                         (np.pi * t[i] * (1 - (4 * self.roll_off * (t[i] / self.ts)) ** 2))\n",
        "\n",
        "        rrc = rrc / np.sqrt(np.sum(rrc ** 2))\n",
        "        rrc = tf.constant(rrc, dtype=tf.float32)\n",
        "        return rrc\n",
        "\n",
        "    def phase_offset(self):\n",
        "        phase_offset = np.random.uniform(0, (2) * np.pi)\n",
        "        return phase_offset\n",
        "\n",
        "    def upsample_and_filter(self, signal):\n",
        "        upsampled_signal = self.upsample_iq(signal)\n",
        "        rrc = self.rrc_filter()\n",
        "\n",
        "        upsampled_signal = tf.expand_dims(upsampled_signal, axis=0)  # Shape: (1, length, 2)\n",
        "        rrc = tf.reshape(rrc, [-1, 1, 1])  # Shape: (filter_length, 1, 1)\n",
        "\n",
        "        padding_size = self.num_taps // 2\n",
        "        paddings = tf.constant([[0, 0], [padding_size, padding_size], [0, 0]])\n",
        "        padded_real = tf.pad(upsampled_signal[:, :, 0:1], paddings, \"CONSTANT\")\n",
        "        padded_imag = tf.pad(upsampled_signal[:, :, 1:2], paddings, \"CONSTANT\")\n",
        "        upsampled_signal = tf.concat([padded_real, padded_imag], axis=2)\n",
        "\n",
        "        real_filtered = tf.nn.conv1d(upsampled_signal[:, :, 0:1], rrc, stride=1, padding='SAME')\n",
        "        imag_filtered = tf.nn.conv1d(upsampled_signal[:, :, 1:2], rrc, stride=1, padding='SAME')\n",
        "\n",
        "\n",
        "        real_filtered = real_filtered * tf.math.cos(self.phase_offset())-imag_filtered * tf.math.sin(self.phase_offset())\n",
        "        imag_filtered = imag_filtered * tf.math.sin(self.phase_offset())+real_filtered * tf.math.cos(self.phase_offset())\n",
        "\n",
        "        filtered_signal = tf.concat([real_filtered, imag_filtered], axis=2)\n",
        "        filtered_signal = tf.squeeze(filtered_signal, axis=0)  # Remove the batch dimension\n",
        "        return filtered_signal\n",
        "\n",
        "    def time_offset(self, sampling_time=0.5e-6):\n",
        "        t_offset = np.random.uniform(-sampling_time , sampling_time )\n",
        "        return t_offset\n",
        "\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        f = inputs.shape[1] // 2\n",
        "\n",
        "        # Reshape to pairs of real and imaginary parts\n",
        "        inputs = tf.reshape(inputs, [batch_size, -1, 2])  # Shape: (batch_size, num_pairs, 2) adjacent pairs are couples as real imaginary\n",
        "        print(inputs.shape)\n",
        "        # Define a function to process each sample\n",
        "        def process_sample(sample):\n",
        "            filtered_signal = self.upsample_and_filter(sample)  # Process each sample\n",
        "            return filtered_signal\n",
        "\n",
        "        # Apply the function to each sample in the batch\n",
        "        output = tf.map_fn(process_sample, inputs, dtype=tf.float32)  # Shape: (batch_size, num_filtered_samples, 2)\n",
        "\n",
        "        # Reshape back to original shape if necessary\n",
        "        output = tf.reshape(output, [batch_size, -1])\n",
        "\n",
        "        return output\n",
        "\n",
        "# Autoencoder Class with Convolutional Layers\n",
        "class AE:\n",
        "    def __init__(self, train_data, val_data, test_data, input_dim=K, enc_dim=N, act_fun='relu'):\n",
        "        self.train_data = train_data\n",
        "        self.val_data = val_data\n",
        "        self.test_data = test_data\n",
        "        self.input_dim = input_dim\n",
        "        self.enc_dim = enc_dim\n",
        "        self.act_fun = act_fun\n",
        "\n",
        "\n",
        "    def AE_implement(self):\n",
        "        autoencoder = Sequential([\n",
        "            Input(shape=(1,),batch_size = batch_size),  # Add this input layer\n",
        "            # Embedding Layer (Input: message indices)\n",
        "            Embedding(input_dim=M, output_dim=256, input_length=1, name=\"Embedding\"),\n",
        "            Flatten(),  # Flatten output to feed into Conv1D layers\n",
        "\n",
        "            # Encoder (Multiple Conv1D layers)\n",
        "            Reshape((1, 256)),  # Reshape for Conv1D\n",
        "            Conv1D(256, kernel_size=1, activation='elu', name=\"Conv1D_1\"),\n",
        "            Conv1D(128, kernel_size=1, activation='elu', name=\"Conv1D_2\"),\n",
        "            Conv1D(64, kernel_size=1, activation='elu', name=\"Conv1D_3\"),\n",
        "            Conv1D(2*N, kernel_size=1, activation='linear', name=\"Conv1D_4\"),\n",
        "\n",
        "            # # Power Normalization Layer (L2 normalization over 2N dimensions)\n",
        "            # tf.keras.layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=-1)),\n",
        "            # PowerConstraintLayer(input_shape=(1, 8),name= \"power\"),\n",
        "            Normalization(input_shape=(1, 8),name= \"normal\"),\n",
        "            # Custom Noise Layer (Simulating the channel)\n",
        "            StochasticChannelv3(name=\"StochasticChannel\"),\n",
        "            CustomNoise(name=\"NoiseLayer\"),\n",
        "            SD_RNN(name=\"SD\"),\n",
        "\n",
        "            Reshape((1, 103)),  # Reshape for Conv1D_dec1\n",
        "            # Decoder (Conv1D layers to reconstruct the input)\n",
        "            Conv1D(64, kernel_size=1, activation='elu', name=\"Conv1D_Dec1\"),\n",
        "            Conv1D(128, kernel_size=1, activation='elu', name=\"Conv1D_Dec2\"),\n",
        "            Conv1D(256, kernel_size=1, activation='elu', name=\"Conv1D_Dec3\"),\n",
        "\n",
        "            # Output Layer with Softmax to predict the message index\n",
        "            Flatten(),\n",
        "            Dense(output, activation='softmax', name=\"Output\")\n",
        "        ],name=\"Autoencoder_Model\",)\n",
        "\n",
        "        # Compile the model\n",
        "        autoencoder.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,beta_1=0.9, beta_2=0.999,epsilon=1e-07),\n",
        "                            loss='sparse_categorical_crossentropy',\n",
        "                            metrics=['accuracy'])\n",
        "        return autoencoder\n",
        "\n",
        "\n",
        "        # Training Class with Early Stopping and Plotting\n",
        "    def train(self, epochs=40, batch_size=32):\n",
        "        autoencoder = self.AE_implement()\n",
        "\n",
        "        log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "        tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "        history = autoencoder.fit(self.train_data, self.train_data,\n",
        "                                  epochs=epochs, batch_size=batch_size,\n",
        "                                  validation_data=(self.val_data, self.val_data),\n",
        "                                  callbacks=[PlottingCallback(), tensorboard_callback])\n",
        "        return autoencoder, history\n",
        "\n",
        "\n",
        "# Custom Callback for Real-time Plotting\n",
        "class PlottingCallback(Callback):\n",
        "    def __init__(self):\n",
        "        super(PlottingCallback, self).__init__()\n",
        "        self.history = {'accuracy': [], 'val_accuracy': [], 'loss': [], 'val_loss': []}\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.history['accuracy'].append(logs.get('accuracy'))\n",
        "        self.history['val_accuracy'].append(logs.get('val_accuracy'))\n",
        "        self.history['loss'].append(logs.get('loss'))\n",
        "        self.history['val_loss'].append(logs.get('val_loss'))\n",
        "\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        plt.figure(figsize=(12, 5))\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(self.history['accuracy'], label='Training Accuracy')\n",
        "        plt.plot(self.history['val_accuracy'], label='Validation Accuracy')\n",
        "        plt.title('Accuracy over Epochs')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(self.history['loss'], label='Training Loss')\n",
        "        plt.plot(self.history['val_loss'], label='Validation Loss')\n",
        "        plt.title('Loss over Epochs')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Instantiate and Train\n",
        "ae = AE(train_data=train_set, val_data=val_set, test_data=test_dataset, input_dim=K, enc_dim=N, act_fun='tanh')\n",
        "autoencoder_model, history = ae.train(epochs=80, batch_size=batch_size)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = autoencoder_model.evaluate(test_dataset, test_dataset)\n",
        "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxFrLcW22ayQ"
      },
      "outputs": [],
      "source": [
        "# Save the model for MATLAB\n",
        "autoencoder_model.save('my_model.keras')  # Save in HDF5 format\n",
        "#autoencoder_model.save('autoencoder_model.tf')  # Save in SavedModel format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XX4d2GFIqiK_",
        "outputId": "f3947dab-d5b3-494d-8139-5ebc17777cb0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "autoencoder_model.save('my_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OabxgNH26bJC",
        "outputId": "23f089fc-f0d0-4aae-e0fe-675ee91af1b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        },
        "id": "VJ8Uc-EYoMqm",
        "outputId": "7037cc38-1ab4-4ae5-d656-a295aece94d7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Autoencoder_Model\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"Autoencoder_Model\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                         </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ Embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,536</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                    â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ power (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PowerConstraintLayer</span>)         â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ normal (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)               â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ StochasticChannel                    â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">92</span>)                  â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">StochasticChannelv3</span>)                â”‚                             â”‚                 â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ NoiseLayer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CustomNoise</span>)             â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">92</span>)                  â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ SD (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SD_RNN</span>)                          â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>)                 â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,019</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                  â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>)              â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_Dec1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,656</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_Dec2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_Dec3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ Embedding (\u001b[38;5;33mEmbedding\u001b[0m)                â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)              â”‚          \u001b[38;5;34m65,536\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape (\u001b[38;5;33mReshape\u001b[0m)                    â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)              â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_1 (\u001b[38;5;33mConv1D\u001b[0m)                    â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)              â”‚          \u001b[38;5;34m65,792\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_2 (\u001b[38;5;33mConv1D\u001b[0m)                    â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)              â”‚          \u001b[38;5;34m32,896\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_3 (\u001b[38;5;33mConv1D\u001b[0m)                    â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)               â”‚           \u001b[38;5;34m8,256\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_4 (\u001b[38;5;33mConv1D\u001b[0m)                    â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)                â”‚             \u001b[38;5;34m520\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ power (\u001b[38;5;33mPowerConstraintLayer\u001b[0m)         â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)                â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ normal (\u001b[38;5;33mNormalization\u001b[0m)               â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)                â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ StochasticChannel                    â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m92\u001b[0m)                  â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mStochasticChannelv3\u001b[0m)                â”‚                             â”‚                 â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ NoiseLayer (\u001b[38;5;33mCustomNoise\u001b[0m)             â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m92\u001b[0m)                  â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ SD (\u001b[38;5;33mSD_RNN\u001b[0m)                          â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m103\u001b[0m)                 â”‚          \u001b[38;5;34m24,019\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape_4 (\u001b[38;5;33mReshape\u001b[0m)                  â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m103\u001b[0m)              â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_Dec1 (\u001b[38;5;33mConv1D\u001b[0m)                 â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)               â”‚           \u001b[38;5;34m6,656\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_Dec2 (\u001b[38;5;33mConv1D\u001b[0m)                 â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)              â”‚           \u001b[38;5;34m8,320\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_Dec3 (\u001b[38;5;33mConv1D\u001b[0m)                 â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)              â”‚          \u001b[38;5;34m33,024\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)                  â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Output (\u001b[38;5;33mDense\u001b[0m)                       â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 â”‚          \u001b[38;5;34m65,792\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">932,435</span> (3.56 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m932,435\u001b[0m (3.56 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">310,811</span> (1.19 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m310,811\u001b[0m (1.19 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">621,624</span> (2.37 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m621,624\u001b[0m (2.37 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "autoencoder_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "rJtxL_ZKvJm7",
        "outputId": "9ce39531-a46b-4036-d9df-861dc1b606b2"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "The layer Autoencoder_Model has never been called and thus has no defined input.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-7effb82d3829>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Create a new model from the input to the Normalization layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0msub_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautoencoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msub_model_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0msub_model_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautoencoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msub_model_output_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36minput\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mInput\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0minput\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \"\"\"\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_node_attribute_at_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input_tensors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36m_get_node_attribute_at_index\u001b[0;34m(self, node_index, attr, attr_name)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \"\"\"\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    286\u001b[0m                 \u001b[0;34mf\"The layer {self.name} has never been called \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m                 \u001b[0;34mf\"and thus has no defined {attr_name}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The layer Autoencoder_Model has never been called and thus has no defined input."
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Get the output of the Normalization layer\n",
        "sub_model_output = autoencoder_model.get_layer(\"normal\").output\n",
        "sub_model_output_p = autoencoder_model.get_layer(\"power\").output\n",
        "\n",
        "# Create a new model from the input to the Normalization layer\n",
        "sub_model = Model(inputs=autoencoder_model.input, outputs=sub_model_output)\n",
        "sub_model_p = Model(inputs=autoencoder_model.input, outputs=sub_model_output_p)\n",
        "\n",
        "# Display the summary of the sub-model\n",
        "sub_model.summary()\n",
        "sub_model_p.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jK3L9dy7p7SF"
      },
      "source": [
        "# Save encoder output as a .mat file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3a5ayi5EPWFn"
      },
      "outputs": [],
      "source": [
        "from scipy.io import savemat\n",
        "\n",
        "sub_model_output_values = sub_model.predict(train_dataset)  # Use predict to get NumPy values\n",
        "sub_model_output_values = tf.squeeze(sub_model_output_values, axis=1)\n",
        "\n",
        "sub_model_output_p_values = sub_model_p.predict(train_dataset)  # Use predict to get NumPy values\n",
        "sub_model_output_p_values = tf.squeeze(sub_model_output_p_values, axis=1)\n",
        "\n",
        "# Since eager execution is enabled, you can directly get the tensor values\n",
        "sub_model_output_p_values = sub_model_output_p_values.numpy()\n",
        "sub_model_output_values = sub_model_output_values.numpy()\n",
        "print(sub_model_output_values)\n",
        "\n",
        "# Save the result to a .mat file\n",
        "savemat(\"Tx_out_n4_k8.mat\", {\"data\": sub_model_output_values})\n",
        "savemat(\"Tx_out_n4_k8_p.mat\", {\"data\": sub_model_output_p_values})\n",
        "\n",
        "# Create complex data using NumPy\n",
        "complex_data = sub_model_output_values[:, :4] + 1j * sub_model_output_values[:, 4:]\n",
        "complex_data_p = sub_model_output_p_values[:, :4] + 1j * sub_model_output_p_values[:, 4:]\n",
        "\n",
        "# Save complex data to .mat file\n",
        "savemat(\"Tx_out_complex_n4_k8.mat\", {\"data\": complex_data})\n",
        "savemat(\"Tx_out_complex_n4_k8_p.mat\", {\"data\": complex_data_p})  # Save complex_data_p as well\n",
        "\n",
        "print(\"Saved tensor data as a .mat file.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R66WiQmsox-3"
      },
      "outputs": [],
      "source": [
        "sub_model.save('my_Submodel.keras')\n",
        "sub_model.save('my_Submodel.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G23ZkT4DoNIj"
      },
      "outputs": [],
      "source": [
        "def BLER(test_dataset, frame_size, model):\n",
        "    prediction = model.predict(test_dataset)\n",
        "    total_blocks = prediction.shape[0] // frame_size\n",
        "    print(total_blocks)\n",
        "    print(prediction.shape)\n",
        "    print(test_dataset.shape)\n",
        "    prediction = np.argmax(prediction, axis=1)\n",
        "    test_dataset = test_dataset.ravel()\n",
        "    print(prediction.shape)\n",
        "    print(test_dataset[:frame_size])\n",
        "    print(prediction[0:frame_size])\n",
        "\n",
        "    bler = 0\n",
        "    for i in range(total_blocks):\n",
        "        block_prediction = prediction[i * frame_size : (i + 1) * frame_size]\n",
        "        block_true = test_dataset[i * frame_size : (i + 1) * frame_size]\n",
        "\n",
        "        if not np.array_equal(block_prediction, block_true):  # Corrected comparison\n",
        "            bler += 1\n",
        "\n",
        "    return bler / total_blocks\n",
        "\n",
        "bler = BLER(test_dataset[:20001], 100, autoencoder_model)\n",
        "print(bler)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6B89NXG_Ntq"
      },
      "source": [
        "# CNN Bsed AE for CTS transmission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBwYJJE2D2HH"
      },
      "source": [
        "## Sliding window\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hr7kimTuD2HH",
        "outputId": "698a959e-0149-4af2-b6a8-f7ca932a71d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Matrix Shape: (20, 1, 8)\n",
            "New Matrix Shape: (20, 1, 104)\n"
          ]
        }
      ],
      "source": [
        "class SlidingWindowConcatLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, window_size, **kwargs):\n",
        "        \"\"\"\n",
        "        Initialize the SlidingWindowConcatLayer.\n",
        "\n",
        "        Args:\n",
        "            window_size (int): Number of rows in the sliding window.\n",
        "        \"\"\"\n",
        "        super(SlidingWindowConcatLayer, self).__init__(**kwargs)\n",
        "        self.window_size = window_size\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        Apply the sliding window and concatenation operation to the inputs.\n",
        "\n",
        "        Args:\n",
        "            inputs (tf.Tensor): A 3D tensor of shape (rows, cols, depth).\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: A transformed tensor after sliding window and concatenation.\n",
        "        \"\"\"\n",
        "        # Determine padding size\n",
        "        paddings = [[self.window_size // 2, self.window_size // 2], [0, 0], [0, 0]]\n",
        "\n",
        "        # Pad the input tensor\n",
        "        padded_matrix = tf.pad(inputs, paddings=paddings, mode=\"CONSTANT\", constant_values=0)\n",
        "\n",
        "        # Initialize a list to store the new rows\n",
        "        new_matrix_list = []\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "\n",
        "        # Create sliding windows and concatenate along the depth\n",
        "        for i in range(batch_size):  # Iterate over the original matrix row count\n",
        "            window = padded_matrix[i:i + self.window_size]\n",
        "            concatenated_row = tf.concat(tf.unstack(window, axis=0), axis=-1)\n",
        "            new_matrix_list.append(concatenated_row)\n",
        "\n",
        "        # Stack the resulting rows into a single tensor\n",
        "        output = tf.stack(new_matrix_list)\n",
        "        return output\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"\n",
        "        Returns the configuration of the layer for serialization.\n",
        "        \"\"\"\n",
        "        config = super(SlidingWindowConcatLayer, self).get_config()\n",
        "        config.update({\"window_size\": self.window_size})\n",
        "        return config\n",
        "\n",
        "original_matrix = tf.random.uniform(shape=(20, 1, 8), minval=0, maxval=10, dtype=tf.int32)\n",
        "sliding_window_layer = SlidingWindowConcatLayer(window_size=13)\n",
        "new_matrix = sliding_window_layer(original_matrix)\n",
        "\n",
        "print(\"Original Matrix Shape:\", original_matrix.shape)\n",
        "print(\"New Matrix Shape:\", new_matrix.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMN_ROlwD2HH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7518a14b-96ad-4744-ff74-bc3537d4a047"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Matrix Shape: (20, 1, 8)\n",
            "New Matrix Shape: (20, 1, 104)\n"
          ]
        }
      ],
      "source": [
        "class SlidingWindowConcatLayer1(tf.keras.layers.Layer):\n",
        "    def __init__(self, window_size, **kwargs):\n",
        "        \"\"\"\n",
        "        Initialize the SlidingWindowConcatLayer.\n",
        "\n",
        "        Args:\n",
        "            window_size (int): Number of rows in the sliding window.\n",
        "        \"\"\"\n",
        "        super(SlidingWindowConcatLayer1, self).__init__(**kwargs)\n",
        "        self.window_size = window_size\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        Apply the sliding window and concatenation operation to the inputs.\n",
        "\n",
        "        Args:\n",
        "            inputs (tf.Tensor): A 3D tensor of shape (batch_size, rows, depth).\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: A transformed tensor after sliding window and concatenation.\n",
        "        \"\"\"\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        rows = tf.shape(inputs)[1]\n",
        "        depth = tf.shape(inputs)[2]\n",
        "\n",
        "        # Pad the input tensor\n",
        "        paddings = [[0, 0], [self.window_size // 2, self.window_size // 2], [0, 0]]\n",
        "        padded_matrix = tf.pad(inputs, paddings=paddings, mode=\"CONSTANT\", constant_values=0)\n",
        "\n",
        "        # Create sliding windows\n",
        "        window_slices = [\n",
        "            padded_matrix[:, i:i + rows, :]\n",
        "            for i in range(self.window_size)\n",
        "        ]\n",
        "\n",
        "        # Concatenate windows along the depth dimension\n",
        "        concatenated = tf.concat(window_slices, axis=-1)\n",
        "        return concatenated\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\"\n",
        "        Compute the output shape of the layer.\n",
        "        \"\"\"\n",
        "        batch_size, rows, depth = input_shape\n",
        "        output_depth = depth * self.window_size\n",
        "        return (batch_size, rows, output_depth)\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"\n",
        "        Returns the configuration of the layer for serialization.\n",
        "        \"\"\"\n",
        "        config = super(SlidingWindowConcatLayer1, self).get_config()\n",
        "        config.update({\"window_size\": self.window_size})\n",
        "        return config\n",
        "\n",
        "\n",
        "original_matrix = tf.random.uniform(shape=(20, 1, 8), minval=0, maxval=10, dtype=tf.int32)\n",
        "sliding_window_layer = SlidingWindowConcatLayer1(window_size=13)\n",
        "new_matrix = sliding_window_layer(original_matrix)\n",
        "\n",
        "print(\"Original Matrix Shape:\", original_matrix.shape)\n",
        "print(\"New Matrix Shape:\", new_matrix.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aG8NyGV-D2HI"
      },
      "source": [
        "##Stochastic channel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03w49zXXD2HI"
      },
      "outputs": [],
      "source": [
        "##- taking adjacent as real and imaginary pairs\n",
        "\n",
        "\n",
        "class StochasticChannelv3(tf.keras.layers.Layer):\n",
        "    def __init__(self, roll_off=0.35, num_taps=31, time_delay=0, r=4, ts=1, **kwargs):\n",
        "        super(StochasticChannelv3, self).__init__(**kwargs)\n",
        "        self.num_taps = num_taps\n",
        "        self.time_delay = time_delay\n",
        "        self.r = r  # Upsampling factor\n",
        "        self.roll_off = roll_off  # Roll-off factor\n",
        "        self.ts = ts  # Sampling period (default is 1)\n",
        "\n",
        "    def upsampling(self, inp):\n",
        "        com_reshape = tf.reshape(inp, [-1, 1])\n",
        "        padding = tf.constant([[0, 0], [0, self.r - 1]])  # Access self.r\n",
        "        upsampled = tf.pad(com_reshape, padding, mode=\"CONSTANT\")\n",
        "        upsampled = tf.reshape(upsampled, [-1])  # Flatten back to 1D\n",
        "        return upsampled\n",
        "\n",
        "    def upsample_iq(self, inp):\n",
        "        real = inp[:, 0]  # Real part\n",
        "        imag = inp[:, 1]  # Imaginary part\n",
        "\n",
        "        real_up = self.upsampling(real)\n",
        "        imag_up = self.upsampling(imag)\n",
        "\n",
        "        upsampled = tf.stack([real_up, imag_up], axis=1)\n",
        "        return upsampled\n",
        "\n",
        "    def rrc_filter(self):\n",
        "        t = np.linspace(-self.num_taps // 2, self.num_taps // 2 + 1, self.num_taps) - self.time_offset()\n",
        "        rrc = np.zeros_like(t)\n",
        "\n",
        "        for i in range(len(t)):\n",
        "            if t[i] == 0.0:\n",
        "                rrc[i] = (1.0 - self.roll_off + 4 * self.roll_off / np.pi) / self.ts\n",
        "            elif np.abs(t[i]) == self.ts / (4 * self.roll_off):\n",
        "                rrc[i] = (self.roll_off / (np.sqrt(2) * self.ts)) * \\\n",
        "                         ((1 + 2 / np.pi) * np.sin(np.pi / (4 * self.roll_off)) +\n",
        "                          (1 - 2 / np.pi) * np.cos(np.pi / (4 * self.roll_off)))\n",
        "            else:\n",
        "                rrc[i] = (np.sin(np.pi * (t[i] / self.ts) * (1 - self.roll_off)) +\n",
        "                          4 * self.roll_off * (t[i] / self.ts) * np.cos(np.pi * (t[i] / self.ts) * (1 + self.roll_off))) / \\\n",
        "                         (np.pi * t[i] * (1 - (4 * self.roll_off * (t[i] / self.ts)) ** 2))\n",
        "\n",
        "        rrc = rrc / np.sqrt(np.sum(rrc ** 2))\n",
        "        rrc = tf.constant(rrc, dtype=tf.float32)\n",
        "        return rrc\n",
        "\n",
        "    def phase_offset(self):\n",
        "        phase_offset = np.random.uniform(0, (2) * np.pi)\n",
        "        return phase_offset\n",
        "\n",
        "    def upsample_and_filter(self, signal):\n",
        "        upsampled_signal = self.upsample_iq(signal)\n",
        "        rrc = self.rrc_filter()\n",
        "\n",
        "        upsampled_signal = tf.expand_dims(upsampled_signal, axis=0)  # Shape: (1, length, 2)\n",
        "        rrc = tf.reshape(rrc, [-1, 1, 1])  # Shape: (filter_length, 1, 1)\n",
        "\n",
        "        padding_size = self.num_taps // 2\n",
        "        paddings = tf.constant([[0, 0], [padding_size, padding_size], [0, 0]])\n",
        "        padded_real = tf.pad(upsampled_signal[:, :, 0:1], paddings, \"CONSTANT\")\n",
        "        padded_imag = tf.pad(upsampled_signal[:, :, 1:2], paddings, \"CONSTANT\")\n",
        "        upsampled_signal = tf.concat([padded_real, padded_imag], axis=2)\n",
        "\n",
        "        real_filtered = tf.nn.conv1d(upsampled_signal[:, :, 0:1], rrc, stride=1, padding='SAME')\n",
        "        imag_filtered = tf.nn.conv1d(upsampled_signal[:, :, 1:2], rrc, stride=1, padding='SAME')\n",
        "\n",
        "\n",
        "        real_filtered = real_filtered * tf.math.cos(self.phase_offset())-imag_filtered * tf.math.sin(self.phase_offset())\n",
        "        imag_filtered = imag_filtered * tf.math.sin(self.phase_offset())+real_filtered * tf.math.cos(self.phase_offset())\n",
        "\n",
        "        filtered_signal = tf.concat([real_filtered, imag_filtered], axis=2)\n",
        "        filtered_signal = tf.squeeze(filtered_signal, axis=0)  # Remove the batch dimension\n",
        "        return filtered_signal\n",
        "\n",
        "    def time_offset(self, sampling_time=0.5e-6):\n",
        "        t_offset = np.random.uniform(-sampling_time , sampling_time )\n",
        "        return t_offset\n",
        "\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        f = inputs.shape[1] // 2\n",
        "\n",
        "        # Reshape to pairs of real and imaginary parts\n",
        "        inputs = tf.reshape(inputs, [batch_size, -1, 2])  # Shape: (batch_size, num_pairs, 2)\n",
        "        print(inputs.shape)\n",
        "        # Define a function to process each sample\n",
        "        def process_sample(sample):\n",
        "            filtered_signal = self.upsample_and_filter(sample)  # Process each sample\n",
        "            return filtered_signal\n",
        "\n",
        "        # Apply the function to each sample in the batch\n",
        "        output = tf.map_fn(process_sample, inputs, dtype=tf.float32)  # Shape: (batch_size, num_filtered_samples, 2)\n",
        "\n",
        "        # Reshape back to original shape if necessary\n",
        "        output = tf.reshape(output, [batch_size, -1])\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tlKQ0A5D2HI"
      },
      "source": [
        "##Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97Xi8J9KD2HI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57d3e85c-4086-4680-9ef8-b8b4c6236062"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of train samples: 5440\n",
            "Number of validation samples: 960\n",
            "Number of test samples: 3072\n",
            "Number of train samples padded: 5452\n",
            "Number of validation samples padded: 972\n",
            "Number of test samples padded: 3084\n"
          ]
        }
      ],
      "source": [
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "\n",
        "# Dataset Parameters\n",
        "N = 4  # Number of channel uses\n",
        "K = 8  # Block size (log2 of the number of messages)\n",
        "M = 2**K  # Number of possible messages (2^K)\n",
        "batch_size = 6400\n",
        "output = 2**K\n",
        "Eb_No = 15  # Signal-to-Noise ratio in dB\n",
        "\n",
        "# Create Dataset with Integer Labels\n",
        "train_dataset = np.tile(np.arange(M), batch_size // M)\n",
        "test_dataset = np.tile(np.arange(M), batch_size  //(2*M))\n",
        "\n",
        "# Shuffle the dataset\n",
        "np.random.shuffle(train_dataset)\n",
        "np.random.shuffle(test_dataset)\n",
        "\n",
        "# Define split ratios\n",
        "train_ratio = 0.85  # 85% for training\n",
        "val_ratio = 0.15    # 15% for validation\n",
        "\n",
        "# Calculate the number of samples\n",
        "num_train_samples = int(len(train_dataset) * train_ratio)\n",
        "num_val_samples = len(train_dataset) - num_train_samples\n",
        "\n",
        "# Split the datasets\n",
        "train_set = train_dataset[:num_train_samples]\n",
        "val_set = train_dataset[num_train_samples:]\n",
        "\n",
        "# Reshape the datasets if needed\n",
        "train_set = train_set.reshape((-1, 1))\n",
        "val_set = val_set.reshape((-1, 1))\n",
        "test_dataset = test_dataset.reshape((-1, 1))\n",
        "\n",
        "# Pad the test dataset with 6 zeros before and after\n",
        "padding = np.zeros((6, 1), dtype=int)\n",
        "train_set_padded = np.vstack([padding, train_set, padding])\n",
        "val_set_padded = np.vstack([padding, val_set, padding])\n",
        "test_dataset_padded = np.vstack([padding, test_dataset, padding])\n",
        "\n",
        "# Print dataset sizes\n",
        "print(f\"Number of train samples: {len(train_set)}\")\n",
        "print(f\"Number of validation samples: {len(val_set)}\")\n",
        "print(f\"Number of test samples: {len(test_dataset)}\")\n",
        "print(f\"Number of train samples padded: {len(train_set_padded)}\")\n",
        "print(f\"Number of validation samples padded: {len(val_set_padded)}\")\n",
        "print(f\"Number of test samples padded: {len(test_dataset_padded)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA0q0y0RD2HI"
      },
      "source": [
        "##Custom Noise, Normalization layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGfeHPY8D2HI"
      },
      "outputs": [],
      "source": [
        "# Custom Noise Layer\n",
        "class CustomNoise(tf.keras.layers.Layer):\n",
        "    def __init__(self, mean=0.0, stddev=10**(-1.0*Eb_No), **kwargs):\n",
        "        super(CustomNoise, self).__init__(**kwargs)\n",
        "        self.mean = mean\n",
        "        self.stddev = stddev\n",
        "\n",
        "    def call(self, inputs):\n",
        "        noise = tf.random.normal(shape=tf.shape(inputs), mean=self.mean, stddev=self.stddev)\n",
        "        return inputs + noise\n",
        "\n",
        "# class Normalization(tf.keras.layers.Layer):\n",
        "#     def __init__(self, **kwargs):\n",
        "#         super(Normalization, self).__init__(**kwargs)\n",
        "\n",
        "#     def call(self, input):\n",
        "#         out = tf.nn.l2_normalize(tf.reshape(input, (-1, 2)), axis=-1, epsilon=1e-6)\n",
        "#         out = tf.reshape(out, (-1, 2*N))\n",
        "#         print(\"normalization layer output shape:\" ,str(out.shape))\n",
        "#         return out\n",
        "#     def get_config(self):\n",
        "#         config = super(Normalization, self).get_config()\n",
        "#         return config\n",
        "\n",
        "\n",
        "class Normalization(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(Normalization, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, input):\n",
        "        # Perform L2 normalization on the last dimension while keeping the overall shape\n",
        "        out = tf.nn.l2_normalize(input, axis=-1, epsilon=1e-6)\n",
        "        # print(\"Normalization layer output shape:\", out.shape)\n",
        "        return out\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(Normalization, self).get_config()\n",
        "        return config\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zORpoJ4D2HJ"
      },
      "source": [
        "##Sequence Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3CRAArgD2HJ"
      },
      "outputs": [],
      "source": [
        "class SD(tf.keras.layers.Layer):\n",
        "    def __init__(self, l=6, n=4, r=4, **kwargs):\n",
        "        super(SD, self).__init__(**kwargs)\n",
        "        self.l = l\n",
        "        self.n = n\n",
        "        self.r = r\n",
        "\n",
        "        with tf.name_scope(\"fe\"):\n",
        "            self.fe = Sequential([\n",
        "                Dense(256, activation='relu', name='initial'),\n",
        "                Dense(8, activation='linear', name='feature_extractor')\n",
        "            ])\n",
        "\n",
        "        with tf.name_scope(\"pe\"):\n",
        "            self.pe = Sequential([\n",
        "                Dense(256, activation='relu', name='initial'),\n",
        "                Dense(128, activation='relu', name='phase_estimator_dense1'),\n",
        "                Dense(2, activation='linear', name='phase_estimator')\n",
        "            ])\n",
        "\n",
        "        with tf.name_scope(\"oe\"):\n",
        "            self.oe = Sequential([\n",
        "                Dense(256, activation='relu', name='initial'),\n",
        "                Dense(128, activation='relu', name='oe_dense1'),\n",
        "                Dense(32, activation='relu', name='oe_dense2'),\n",
        "                Dense(16, activation='softmax', name='offset_estimator'),\n",
        "\n",
        "            ])\n",
        "\n",
        "    def mini_slicer(self, inputs):\n",
        "        # in_dim = tf.shape(inputs)[1]\n",
        "        N_msg = self.r * self.n\n",
        "        l1 = 30 + (self.l) *2* N_msg #- self.r,   here 30 is number of paddings, since num_taps=31 (num_taps//2)*2\n",
        "        l2 = 30 + (self.l+1) *2* N_msg\n",
        "        # out_1 = inputs[:, l1-1:l2]\n",
        "        # out_2 = inputs[:, in_dim // 2 + l1-1:in_dim // 2 + l2]\n",
        "        # output = tf.concat([out_1, out_2], axis=1)\n",
        "        output = inputs[:, l1:l2]\n",
        "        print('mini slice output shape', output.shape)\n",
        "        return output\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Get the input dimension (before slicing)\n",
        "        bs = inputs.shape[0]\n",
        "\n",
        "        # inputs = tf.reshape(inputs,[bs,-1,2])\n",
        "        # real = inputs[:, :, 0]  # Real part\n",
        "        # imag = inputs[:, :, 1]  # Imaginary part\n",
        "\n",
        "        # Process the inputs using mini_slicer (this changes the shape of inputs)\n",
        "\n",
        "        # # Update real and imag slices based on new input shape (after mini_slicer)\n",
        "        # half_dim = tf.shape(inputs)[1] // 2  # Get new half dimension after slicing\n",
        "        # real = inputs[:, :half_dim]  # First half of sliced inputs as real part\n",
        "        # imag = inputs[:, half_dim:]  # Second half as imaginary part\n",
        "\n",
        "        # Pass the sliced inputs to the phase estimator model to get h\n",
        "        h = self.pe(inputs)  # h has shape (batch_size, 2)\n",
        "        h_real = h[:, 0]  # Extract real part of h\n",
        "        h_imag = h[:, 1]  # Extract imaginary part of h\n",
        "\n",
        "        h_real = tf.expand_dims(h_real, axis=1)\n",
        "        h_imag = tf.expand_dims(h_imag, axis=1)\n",
        "\n",
        "        # # Perform element-wise multiplication\n",
        "        # h_real_ex = tf.tile(h_real, [1, half_dim])\n",
        "        # h_imag_ex = tf.tile(h_imag, [1, half_dim])\n",
        "        # real_mul = real * h_real_ex -imag*h_imag_ex # Multiply same value of real part to every component of the input\n",
        "        # imag_mul = real * h_imag_ex + imag*h_real_ex # Multiply same value of imag part to every component of the input\n",
        "\n",
        "        # Apply the feature extractor model to real_mul (as an example)\n",
        "        feature_extract_output = self.fe(inputs)\n",
        "        offset_estimator_output = self.oe(inputs)\n",
        "        mini_inputs = self.mini_slicer(inputs)\n",
        "\n",
        "        # Concatenate the outputs\n",
        "        output = tf.concat([mini_inputs,h, feature_extract_output,offset_estimator_output], axis=1)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class SD_RNN(tf.keras.layers.Layer):\n",
        "    def __init__(self, l=6, n=4, r=4, units=16, **kwargs):\n",
        "        super(SD_RNN, self).__init__(**kwargs)\n",
        "        self.l = l\n",
        "        self.n = n\n",
        "        self.r = r\n",
        "        self.units = units  # RNN units\n",
        "\n",
        "        with tf.name_scope(\"fe\"):\n",
        "            # Use LSTM or GRU for feature extractor\n",
        "            self.fe = Sequential([\n",
        "                Reshape((1, 92)),\n",
        "                LSTM(self.units, return_sequences=True, name='feature_extractor_lstm'),\n",
        "                Flatten(),# or use GRU\n",
        "                Dense(8, activation='linear', name='feature_extractor_output')\n",
        "            ])\n",
        "\n",
        "        with tf.name_scope(\"pe\"):\n",
        "            # Use LSTM or GRU for phase estimator\n",
        "            self.pe = Sequential([\n",
        "                Reshape((1, 92)),\n",
        "                LSTM(self.units, return_sequences=True, name='phase_estimator_lstm'),\n",
        "                Flatten(),# or use GRU\n",
        "                Dense(2, activation='linear', name='phase_estimator_output')\n",
        "            ])\n",
        "\n",
        "        with tf.name_scope(\"oe\"):\n",
        "            self.oe = Sequential([\n",
        "                 Reshape((1, 92)),\n",
        "                LSTM(self.units, return_sequences=True, name='offset_estimator_lstm'),\n",
        "                LSTM(self.units, return_sequences=True, name='offset_estimator_lstm1'),\n",
        "                LSTM(self.units//2, return_sequences=True, name='offset_estimator_lstm2'),\n",
        "                Flatten(),\n",
        "                Dense(1, activation='linear', name='offset_estimator'),\n",
        "\n",
        "            ])\n",
        "\n",
        "\n",
        "\n",
        "    def mini_slicer(self, inputs):\n",
        "        in_dim = tf.shape(inputs)[1]\n",
        "        N_msg = self.r * self.n\n",
        "        l1 = 1 + (self.l + 1) * N_msg - self.r\n",
        "        l2 = self.l * N_msg + self.r\n",
        "        out_1 = inputs[:, l1-1:l2]\n",
        "        out_2 = inputs[:, in_dim // 2 + l1-1:in_dim // 2 + l2]\n",
        "        output = tf.concat([out_1, out_2], axis=1)\n",
        "        print('mini slice output shape', output.shape)\n",
        "        return output\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Get the input dimension (before slicing)\n",
        "        in_dim = inputs.shape[1]\n",
        "\n",
        "        # Process the inputs using mini_slicer (this changes the shape of inputs)\n",
        "        # inputs = self.mini_slicer(inputs)\n",
        "\n",
        "        # Update real and imag slices based on new input shape (after mini_slicer)\n",
        "        half_dim = tf.shape(inputs)[1] // 2  # Get new half dimension after slicing\n",
        "        real = inputs[:, :half_dim]  # First half of sliced inputs as real part\n",
        "        imag = inputs[:, half_dim:]  # Second half as imaginary part\n",
        "\n",
        "        # Pass the sliced inputs to the phase estimator model to get h\n",
        "        h = self.pe(inputs)  # h has shape (batch_size, 2)\n",
        "        h_real = h[:, 0]  # Extract real part of h\n",
        "        h_imag = h[:, 1]  # Extract imaginary part of h\n",
        "\n",
        "        h_real = tf.expand_dims(h_real, axis=1)\n",
        "        h_imag = tf.expand_dims(h_imag, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "        # # Perform element-wise multiplication\n",
        "        # h_real_ex = tf.tile(h_real, [1, half_dim])\n",
        "        # h_imag_ex = tf.tile(h_imag, [1, half_dim])\n",
        "        # real_mul = real * h_real_ex -imag*h_imag_ex # Multiply same value of real part to every component of the input\n",
        "        # imag_mul = real * h_imag_ex + imag*h_real_ex # Multiply same value of imag part to every component of the input\n",
        "\n",
        "        # Apply the feature extractor model to real_mul (as an example)\n",
        "        feature_extract_output = self.fe(inputs)\n",
        "        offset_estimator_output = self.oe(inputs)\n",
        "\n",
        "        # Concatenate the outputs\n",
        "        output = tf.concat([real, imag,offset_estimator_output,h_real,h_imag, feature_extract_output], axis=1)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RreOOguRD2HJ"
      },
      "source": [
        "##Autoencoder model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "B5vrynJPD2HJ",
        "outputId": "2ca4b2f7-c1f7-461d-9245-5b719c087ca0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 984ms/step - accuracy: 1.0000 - loss: 0.0715 - val_accuracy: 1.0000 - val_loss: 0.5559\n",
            "\u001b[1m96/96\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.5440\n",
            "Test Loss: 0.5448, Test Accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# Autoencoder Class with Convolutional Layers\n",
        "class AE:\n",
        "    def __init__(self, train_data, val_data, test_data, input_dim=K, enc_dim=N, act_fun='relu'):\n",
        "        self.train_data = train_data\n",
        "        self.val_data = val_data\n",
        "        self.test_data = test_data\n",
        "        self.input_dim = input_dim\n",
        "        self.enc_dim = enc_dim\n",
        "        self.act_fun = act_fun\n",
        "\n",
        "\n",
        "    def AE_implement(self):\n",
        "        autoencoder = Sequential([\n",
        "            Input(shape=(1,),batch_size = batch_size),  # Add this input layer\n",
        "            # Embedding Layer (Input: message indices)\n",
        "            Embedding(input_dim=M, output_dim=256, input_length=1, name=\"Embedding\"),\n",
        "            Flatten(),  # Flatten output to feed into Conv1D layers\n",
        "\n",
        "            # Encoder (Multiple Conv1D layers)\n",
        "            Reshape((1, 256)),  # Reshape for Conv1D\n",
        "            Conv1D(256, kernel_size=1, activation='elu', name=\"Conv1D_1\"),\n",
        "            Conv1D(128, kernel_size=1, activation='elu', name=\"Conv1D_2\"),\n",
        "            Conv1D(64, kernel_size=1, activation='elu', name=\"Conv1D_3\"),\n",
        "            Conv1D(2*N, kernel_size=1, activation='linear', name=\"Conv1D_4\"),\n",
        "\n",
        "            # # Power Normalization Layer (L2 normalization over 2N dimensions)\n",
        "            # tf.keras.layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=-1)),\n",
        "\n",
        "            Normalization(input_shape=(1, 8),name= \"normal\"),\n",
        "            # Custom Noise Layer (Simulating the channel)\n",
        "            SlidingWindowConcatLayer1(window_size=13,name=\"sliding_window\"),\n",
        "            StochasticChannelv3(name=\"StochasticChannel\"),\n",
        "            CustomNoise(name=\"NoiseLayer\"),\n",
        "            SD(name=\"SD\"),\n",
        "\n",
        "            Reshape((1, 58)),  # Reshape for Conv1D_dec1\n",
        "            # Decoder (Conv1D layers to reconstruct the input)\n",
        "            Conv1D(64, kernel_size=1, activation='elu', name=\"Conv1D_Dec1\"),\n",
        "            Conv1D(128, kernel_size=1, activation='elu', name=\"Conv1D_Dec2\"),\n",
        "            Conv1D(256, kernel_size=1, activation='elu', name=\"Conv1D_Dec3\"),\n",
        "\n",
        "            # Output Layer with Softmax to predict the message index\n",
        "            Flatten(),\n",
        "            Dense(output, activation='softmax', name=\"Output\")\n",
        "        ])\n",
        "\n",
        "        # Compile the model\n",
        "        autoencoder.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005,beta_1=0.9, beta_2=0.999,epsilon=1e-07),\n",
        "                            loss='sparse_categorical_crossentropy',\n",
        "                            metrics=['accuracy'])\n",
        "        return autoencoder\n",
        "\n",
        "\n",
        "        # Training Class with Early Stopping and Plotting\n",
        "    def train(self, epochs=40, batch_size=32):\n",
        "        autoencoder = self.AE_implement()\n",
        "\n",
        "        log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "        tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "        history = autoencoder.fit(self.train_data, self.train_data,\n",
        "                                  epochs=epochs, batch_size=batch_size,\n",
        "                                  validation_data=(self.val_data, self.val_data),\n",
        "                                  callbacks=[PlottingCallback(), tensorboard_callback])\n",
        "        return autoencoder, history\n",
        "\n",
        "\n",
        "# Custom Callback for Real-time Plotting\n",
        "class PlottingCallback(Callback):\n",
        "    def __init__(self):\n",
        "        super(PlottingCallback, self).__init__()\n",
        "        self.history = {'accuracy': [], 'val_accuracy': [], 'loss': [], 'val_loss': []}\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.history['accuracy'].append(logs.get('accuracy'))\n",
        "        self.history['val_accuracy'].append(logs.get('val_accuracy'))\n",
        "        self.history['loss'].append(logs.get('loss'))\n",
        "        self.history['val_loss'].append(logs.get('val_loss'))\n",
        "\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        plt.figure(figsize=(12, 5))\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(self.history['accuracy'], label='Training Accuracy')\n",
        "        plt.plot(self.history['val_accuracy'], label='Validation Accuracy')\n",
        "        plt.title('Accuracy over Epochs')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(self.history['loss'], label='Training Loss')\n",
        "        plt.plot(self.history['val_loss'], label='Validation Loss')\n",
        "        plt.title('Loss over Epochs')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Instantiate and Train\n",
        "ae = AE(train_data=train_set, val_data=val_set, test_data=test_dataset, input_dim=K, enc_dim=N, act_fun='tanh')\n",
        "autoencoder_model, history = ae.train(epochs=100, batch_size=batch_size)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = autoencoder_model.evaluate(test_dataset, test_dataset)\n",
        "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784
        },
        "id": "k3cuhYlTD2HJ",
        "outputId": "b74cdd2c-38d5-4390-f408-5d6b12b125fb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ Embedding (\u001b[38;5;33mEmbedding\u001b[0m)                â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)              â”‚          \u001b[38;5;34m65,536\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape (\u001b[38;5;33mReshape\u001b[0m)                    â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)              â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_1 (\u001b[38;5;33mConv1D\u001b[0m)                    â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)              â”‚          \u001b[38;5;34m65,792\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_2 (\u001b[38;5;33mConv1D\u001b[0m)                    â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)              â”‚          \u001b[38;5;34m32,896\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_3 (\u001b[38;5;33mConv1D\u001b[0m)                    â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)               â”‚           \u001b[38;5;34m8,256\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_4 (\u001b[38;5;33mConv1D\u001b[0m)                    â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)                â”‚             \u001b[38;5;34m520\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ normal (\u001b[38;5;33mNormalization\u001b[0m)               â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)                â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sliding_window                       â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m104\u001b[0m)              â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mSlidingWindowConcatLayer1\u001b[0m)          â”‚                             â”‚                 â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ StochasticChannel                    â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m476\u001b[0m)                 â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mStochasticChannelv3\u001b[0m)                â”‚                             â”‚                 â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ NoiseLayer (\u001b[38;5;33mCustomNoise\u001b[0m)             â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m476\u001b[0m)                 â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ SD (\u001b[38;5;33mSD\u001b[0m)                              â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m58\u001b[0m)                  â”‚         \u001b[38;5;34m439,098\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape_1 (\u001b[38;5;33mReshape\u001b[0m)                  â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m58\u001b[0m)               â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_Dec1 (\u001b[38;5;33mConv1D\u001b[0m)                 â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)               â”‚           \u001b[38;5;34m3,776\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_Dec2 (\u001b[38;5;33mConv1D\u001b[0m)                 â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)              â”‚           \u001b[38;5;34m8,320\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_Dec3 (\u001b[38;5;33mConv1D\u001b[0m)                 â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)              â”‚          \u001b[38;5;34m33,024\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Output (\u001b[38;5;33mDense\u001b[0m)                       â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 â”‚          \u001b[38;5;34m65,792\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                         </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ Embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,536</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                    â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ normal (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)               â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sliding_window                       â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span>)              â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SlidingWindowConcatLayer1</span>)          â”‚                             â”‚                 â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ StochasticChannel                    â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">476</span>)                 â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">StochasticChannelv3</span>)                â”‚                             â”‚                 â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ NoiseLayer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CustomNoise</span>)             â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">476</span>)                 â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ SD (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SD</span>)                              â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>)                  â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">439,098</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                  â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>)               â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_Dec1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,776</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_Dec2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_Dec3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,169,032\u001b[0m (8.27 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,169,032</span> (8.27 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m723,010\u001b[0m (2.76 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">723,010</span> (2.76 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,446,022\u001b[0m (5.52 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,446,022</span> (5.52 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "autoencoder_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uj9Gk-9LQJap",
        "outputId": "ceb20187-1004-459b-beb4-6af290d421be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tf_keras in /usr/local/lib/python3.11/dist-packages (2.17.0)\n",
            "Requirement already satisfied: tensorflow<2.18,>=2.17 in /usr/local/lib/python3.11/dist-packages (from tf_keras) (2.17.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (24.12.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (1.69.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow<2.18,>=2.17->tf_keras) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf_keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf_keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf_keras) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf_keras) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf_keras) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf_keras) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf_keras) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf_keras) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf_keras) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf_keras) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf_keras) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf_keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf_keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf_keras) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install tf_keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oB0P4zAwQErR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
        "import tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5tP782iQPzQ"
      },
      "outputs": [],
      "source": [
        "import tf_keras as keras\n",
        "from tf_keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJZkYd-vQfee"
      },
      "outputs": [],
      "source": [
        "autoencoder_model.save(\"myModelTF.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYng43bUtz0t",
        "outputId": "60e306a8-afea-451f-cd2d-189a499d5dc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "autoencoder_model.save('autoencoder_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6TWT_tYKhQE"
      },
      "source": [
        "### Encoder and Decoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "zYDPH2028gkZ",
        "outputId": "b3d9852a-dee0-4ba3-ae97-e36f5d371bed"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Embedding (\u001b[38;5;33mEmbedding\u001b[0m)                â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)              â”‚          \u001b[38;5;34m65,536\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape (\u001b[38;5;33mReshape\u001b[0m)                    â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)              â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_1 (\u001b[38;5;33mConv1D\u001b[0m)                    â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)              â”‚          \u001b[38;5;34m65,792\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_2 (\u001b[38;5;33mConv1D\u001b[0m)                    â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)              â”‚          \u001b[38;5;34m32,896\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_3 (\u001b[38;5;33mConv1D\u001b[0m)                    â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)               â”‚           \u001b[38;5;34m8,256\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_4 (\u001b[38;5;33mConv1D\u001b[0m)                    â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)                â”‚             \u001b[38;5;34m520\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ normal (\u001b[38;5;33mNormalization\u001b[0m)               â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)                â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sliding_window                       â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m104\u001b[0m)              â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mSlidingWindowConcatLayer1\u001b[0m)          â”‚                             â”‚                 â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                         </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,536</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                    â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ normal (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)               â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sliding_window                       â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span>)              â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SlidingWindowConcatLayer1</span>)          â”‚                             â”‚                 â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m173,000\u001b[0m (675.78 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">173,000</span> (675.78 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m173,000\u001b[0m (675.78 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">173,000</span> (675.78 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "encode_output = autoencoder_model.get_layer('sliding_window').output\n",
        "input_tensor = autoencoder_model.get_layer(name='Embedding').input\n",
        "Encoder = tf.keras.Model(inputs=input_tensor, outputs=encode_output)\n",
        "Encoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "tXEuVU459ZQ2",
        "outputId": "929133ea-a605-4607-938b-770d827270e8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ keras_tensor_11CLONE (\u001b[38;5;33mInputLayer\u001b[0m)    â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m476\u001b[0m)                 â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ SD (\u001b[38;5;33mSD\u001b[0m)                              â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m58\u001b[0m)                  â”‚         \u001b[38;5;34m439,098\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape_1 (\u001b[38;5;33mReshape\u001b[0m)                  â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m58\u001b[0m)               â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_Dec1 (\u001b[38;5;33mConv1D\u001b[0m)                 â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)               â”‚           \u001b[38;5;34m3,776\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_Dec2 (\u001b[38;5;33mConv1D\u001b[0m)                 â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)              â”‚           \u001b[38;5;34m8,320\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_Dec3 (\u001b[38;5;33mConv1D\u001b[0m)                 â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)              â”‚          \u001b[38;5;34m33,024\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Output (\u001b[38;5;33mDense\u001b[0m)                       â”‚ (\u001b[38;5;34m6400\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 â”‚          \u001b[38;5;34m65,792\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                         </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ keras_tensor_11CLONE (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">476</span>)                 â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ SD (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SD</span>)                              â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>)                  â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">439,098</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                  â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>)               â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_Dec1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,776</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_Dec2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Conv1D_Dec3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m550,010\u001b[0m (2.10 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">550,010</span> (2.10 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m550,010\u001b[0m (2.10 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">550,010</span> (2.10 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "decoder_input = autoencoder_model.get_layer('SD').input\n",
        "output_tensor = autoencoder_model.get_layer(name='Output').output\n",
        "Decoder = tf.keras.Model(inputs=decoder_input, outputs=output_tensor)\n",
        "Decoder.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLhxRjiAEf6Y"
      },
      "source": [
        "## Encoded msgs of Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUaB5JzM85_e",
        "outputId": "fa0f586e-ba19-4b0e-95a3-3489dc656180"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m170/170\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
            "\u001b[1m96/96\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "(5440, 104)\n",
            "(960, 104)\n",
            "(3072, 104)\n"
          ]
        }
      ],
      "source": [
        "from scipy.io import savemat\n",
        "\n",
        "Encoder_train_set = Encoder.predict(train_set)\n",
        "Encoder_train_set = tf.squeeze(Encoder_train_set, axis=1)\n",
        "Encoder_train_set = Encoder_train_set.numpy()\n",
        "\n",
        "Encoder_Val_set = Encoder.predict(val_set)\n",
        "Encoder_Val_set = tf.squeeze(Encoder_Val_set, axis=1)\n",
        "Encoder_Val_set = Encoder_Val_set.numpy()\n",
        "\n",
        "Encoder_Test_set = Encoder.predict(test_dataset)\n",
        "Encoder_Test_set = tf.squeeze(Encoder_Test_set, axis=1)\n",
        "Encoder_Test_set = Encoder_Test_set.numpy()\n",
        "\n",
        "savemat('Encoder_Train_set.mat', {'Encoder_Train_set': Encoder_train_set})\n",
        "savemat('Encoder_Val_set.mat', {'Encoder_Val_set': Encoder_Val_set})\n",
        "savemat('Encoder_Test_set.mat', {'Encoder_Test_set': Encoder_Test_set})\n",
        "\n",
        "print(Encoder_train_set.shape)\n",
        "print(Encoder_Val_set.shape)\n",
        "print(Encoder_Test_set.shape)\n",
        "# savemat('Encoder_Train_set.mat', {'Encoder_Train_set': Encoder_Train_set})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irZm83pgEt-L"
      },
      "source": [
        "## Alphabet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "177NFYTrEwfV",
        "outputId": "e132157e-8b13-4d11-eec6-98663aec08d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3328, 1)\n",
            "\u001b[1m105/105\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n"
          ]
        }
      ],
      "source": [
        "alphabet = np.tile(np.arange(M),13)\n",
        "alphabet = alphabet.reshape(-1,1)\n",
        "print(alphabet.shape)\n",
        "pad = np.zeros((6,1),dtype=int)\n",
        "alphabet = np.vstack([pad,alphabet,pad])\n",
        "alphabet = Encoder.predict(alphabet)\n",
        "alphabet = tf.squeeze(alphabet, axis=1)\n",
        "\n",
        "alphabet = alphabet.numpy()\n",
        "\n",
        "savemat('alphabet.mat', {'alphabet': alphabet})\n",
        "\n",
        "# print(alphabet+1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}